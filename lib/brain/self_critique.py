"""
Ultimate Brain Architecture - Phase 1: è‡ªå·±æ‰¹åˆ¤ (Self-Critique)

è¨­è¨ˆæ›¸: docs/19_ultimate_brain_architecture.md
ã‚»ã‚¯ã‚·ãƒ§ãƒ³: 3.2 è‡ªå·±æ‰¹åˆ¤ãƒ»æ¨æ•²

å›ç­”ã‚’é€ä¿¡å‰ã«è‡ªå·±è©•ä¾¡ã—ã€å“è³ªã‚’æ‹…ä¿ã™ã‚‹ã€‚
é€”åˆ‡ã‚ŒãŸæ–‡ç« ã€çŸ›ç›¾ã—ãŸå›ç­”ã€ä¸é©åˆ‡ãªãƒˆãƒ¼ãƒ³ã‚’é˜²ãã€‚
"""

import re
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
from typing import Any, Dict, List, Optional, Tuple

from .constants import JST


# ============================================================================
# Enumå®šç¾©
# ============================================================================

class QualityCriterion(Enum):
    """å“è³ªåŸºæº–"""
    RELEVANCE = "relevance"           # è³ªå•ã«ç­”ãˆã¦ã„ã‚‹ã‹
    COMPLETENESS = "completeness"     # å¿…è¦ãªæƒ…å ±ãŒæƒã£ã¦ã„ã‚‹ã‹
    CONSISTENCY = "consistency"       # çŸ›ç›¾ãŒãªã„ã‹
    TONE = "tone"                     # ãƒˆãƒ¼ãƒ³ãŒé©åˆ‡ã‹
    ACTIONABILITY = "actionability"   # æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãŒæ˜ç¢ºã‹
    SAFETY = "safety"                 # å®‰å…¨ã‹ï¼ˆæ©Ÿå¯†æƒ…å ±ã€ä¸é©åˆ‡è¡¨ç¾ï¼‰


class IssueType(Enum):
    """å•é¡Œã‚¿ã‚¤ãƒ—"""
    INCOMPLETE_SENTENCE = "incomplete_sentence"   # æ–‡ãŒé€”åˆ‡ã‚Œã¦ã„ã‚‹
    CONTRADICTION = "contradiction"               # çŸ›ç›¾ã—ã¦ã„ã‚‹
    MISSING_INFO = "missing_info"                 # æƒ…å ±ãŒä¸è¶³ã—ã¦ã„ã‚‹
    WRONG_TONE = "wrong_tone"                     # ãƒˆãƒ¼ãƒ³ãŒä¸é©åˆ‡
    UNCLEAR_ACTION = "unclear_action"             # æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãŒä¸æ˜ç¢º
    SENSITIVE_INFO = "sensitive_info"             # æ©Ÿå¯†æƒ…å ±ã‚’å«ã‚€
    TOO_LONG = "too_long"                         # é•·ã™ãã‚‹
    TOO_SHORT = "too_short"                       # çŸ­ã™ãã‚‹
    OFF_TOPIC = "off_topic"                       # è©±é¡ŒãŒãšã‚Œã¦ã„ã‚‹


class IssueSeverity(Enum):
    """å•é¡Œã®æ·±åˆ»åº¦"""
    CRITICAL = "critical"   # å¿…ãšä¿®æ­£ãŒå¿…è¦
    HIGH = "high"           # ä¿®æ­£æ¨å¥¨
    MEDIUM = "medium"       # ã§ãã‚Œã°ä¿®æ­£
    LOW = "low"             # è»½å¾®


# ============================================================================
# ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹
# ============================================================================

@dataclass
class QualityScore:
    """å“è³ªã‚¹ã‚³ã‚¢"""
    criterion: QualityCriterion
    score: float  # 0.0 ã€œ 1.0
    reasoning: str
    details: Dict[str, Any] = field(default_factory=dict)


@dataclass
class DetectedIssue:
    """æ¤œå‡ºã•ã‚ŒãŸå•é¡Œ"""
    issue_type: IssueType
    severity: IssueSeverity
    description: str
    location: Optional[str] = None  # å•é¡Œã®ã‚ã‚‹ç®‡æ‰€
    suggestion: Optional[str] = None  # æ”¹å–„ææ¡ˆ


@dataclass
class CritiqueResult:
    """æ‰¹åˆ¤çµæœ"""
    scores: List[QualityScore]
    issues: List[DetectedIssue]
    overall_score: float
    needs_refinement: bool
    refinement_priority: List[IssueType]


@dataclass
class RefinedResponse:
    """æ”¹å–„ã•ã‚ŒãŸå›ç­”"""
    original: str
    refined: str
    improvements: List[DetectedIssue]
    refinement_applied: bool
    refinement_time_ms: float


# ============================================================================
# å®šæ•°
# ============================================================================

# å“è³ªåŸºæº–ã®é–¾å€¤
QUALITY_THRESHOLDS = {
    QualityCriterion.RELEVANCE: 0.7,
    QualityCriterion.COMPLETENESS: 0.6,
    QualityCriterion.CONSISTENCY: 0.8,
    QualityCriterion.TONE: 0.7,
    QualityCriterion.ACTIONABILITY: 0.5,
    QualityCriterion.SAFETY: 0.9,
}

# å…¨ä½“ã‚¹ã‚³ã‚¢ã®é–¾å€¤ï¼ˆã“ã‚Œä»¥ä¸‹ãªã‚‰æ”¹å–„å¿…é ˆï¼‰
OVERALL_REFINEMENT_THRESHOLD = 0.7

# ã‚½ã‚¦ãƒ«ãã‚“ã‚‰ã—ã„è¡¨ç¾ãƒ‘ã‚¿ãƒ¼ãƒ³
SOULKUN_TONE_PATTERNS = [
    r"ã‚¦ãƒ«[ğŸºï¼!]?",
    r"ã ã‚ˆ",
    r"ã ã­",
    r"ã€œã­",
    r"ã‹ãª",
    r"æ€ã†",
]

# ä¸é©åˆ‡ãªãƒˆãƒ¼ãƒ³ãƒ‘ã‚¿ãƒ¼ãƒ³
INAPPROPRIATE_TONE_PATTERNS = [
    r"ã§ã™ã€‚$",          # ç¡¬ã™ãã‚‹çµ‚ã‚ã‚Šæ–¹
    r"ã”ã–ã„ã¾ã™",        # éåº¦ã«ä¸å¯§
    r"ã„ãŸã—ã¾ã™",        # éåº¦ã«ä¸å¯§
    r"ã—ã¦ãã ã•ã„ã€‚$",   # å‘½ä»¤èª¿
    r"ã—ãªã•ã„",          # å‘½ä»¤èª¿
    r"ã¹ãã§ã™",          # æ–­å®šçš„ã™ãã‚‹
]

# æ–‡ç« ã®é€”åˆ‡ã‚Œã‚’ç¤ºã™ãƒ‘ã‚¿ãƒ¼ãƒ³
INCOMPLETE_SENTENCE_PATTERNS = [
    r"[ã‚’ã«ãŒã¯ã§ã¨ã¸ã‚‚ã®]$",           # åŠ©è©ã§çµ‚ã‚ã‚‹
    r"[ã€]$",                           # èª­ç‚¹ã§çµ‚ã‚ã‚‹
    r"[ã‚ã„ã†ãˆãŠã‹ããã‘ã“]ã£$",       # ä¿ƒéŸ³ã§çµ‚ã‚ã‚‹ï¼ˆã€Œæ€ã£ã€ãªã©ï¼‰
    r"ã¨ã„ã†ã“$",                       # ã€Œã¨ã„ã†ã“ã¨ã€ãŒåˆ‡ã‚Œã¦ã„ã‚‹
    r"ã§ã™ã®$",                         # ã€Œã§ã™ã®ã§ã€ãŒåˆ‡ã‚Œã¦ã„ã‚‹
]

# æ©Ÿå¯†æƒ…å ±ãƒ‘ã‚¿ãƒ¼ãƒ³
SENSITIVE_INFO_PATTERNS = [
    r"\d{3}-?\d{4}-?\d{4}",              # é›»è©±ç•ªå·
    r"[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+", # ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹
    r"ã€’?\d{3}-?\d{4}",                  # éƒµä¾¿ç•ªå·
    r"ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰[:ï¼š]?\s*\S+",           # ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰
    r"API[ã‚­ãƒ¼éµ][:ï¼š]?\s*\S+",          # APIã‚­ãƒ¼
    r"ç§˜å¯†[:ï¼š]?\s*\S+",                 # ç§˜å¯†æƒ…å ±
]

# å›ç­”ã®é•·ã•ã®ç›®å®‰
LENGTH_GUIDELINES = {
    "min": 10,        # æœ€å°æ–‡å­—æ•°
    "ideal_min": 30,  # ç†æƒ³çš„ãªæœ€å°
    "ideal_max": 200, # ç†æƒ³çš„ãªæœ€å¤§
    "max": 500,       # æœ€å¤§æ–‡å­—æ•°ï¼ˆã“ã‚Œä»¥ä¸Šã¯é•·ã™ãã‚‹ï¼‰
}


# ============================================================================
# SelfCritiqueã‚¯ãƒ©ã‚¹
# ============================================================================

class SelfCritique:
    """
    è‡ªå·±æ‰¹åˆ¤ã‚¨ãƒ³ã‚¸ãƒ³

    å›ç­”ã‚’é€ä¿¡å‰ã«è©•ä¾¡ã—ã€å“è³ªã‚’æ‹…ä¿ã™ã‚‹ã€‚
    å•é¡ŒãŒã‚ã‚Œã°æ”¹å–„ææ¡ˆã‚’è¡Œã†ã€‚
    """

    def __init__(self, llm_client=None):
        """
        åˆæœŸåŒ–

        Args:
            llm_client: LLMã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ã€é«˜åº¦ãªæ”¹å–„ç”¨ï¼‰
        """
        self.llm_client = llm_client

    def critique(
        self,
        response: str,
        original_message: str,
        context: Optional[Dict[str, Any]] = None
    ) -> CritiqueResult:
        """
        å›ç­”ã‚’æ‰¹åˆ¤çš„ã«è©•ä¾¡

        Args:
            response: ç”Ÿæˆã•ã‚ŒãŸå›ç­”
            original_message: å…ƒã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            context: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±

        Returns:
            CritiqueResult: æ‰¹åˆ¤çµæœ
        """
        context = context or {}
        scores = []
        issues = []

        # å„å“è³ªåŸºæº–ã§è©•ä¾¡
        relevance_score = self._evaluate_relevance(response, original_message, context)
        scores.append(relevance_score)

        completeness_score = self._evaluate_completeness(response, original_message, context)
        scores.append(completeness_score)

        consistency_score = self._evaluate_consistency(response, context)
        scores.append(consistency_score)

        tone_score = self._evaluate_tone(response)
        scores.append(tone_score)

        actionability_score = self._evaluate_actionability(response, original_message)
        scores.append(actionability_score)

        safety_score = self._evaluate_safety(response)
        scores.append(safety_score)

        # å•é¡Œã‚’æ¤œå‡º
        issues.extend(self._detect_issues(response, scores, original_message, context))

        # å…¨ä½“ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ï¼ˆé‡ã¿ä»˜ãå¹³å‡ï¼‰
        weights = {
            QualityCriterion.RELEVANCE: 0.25,
            QualityCriterion.COMPLETENESS: 0.15,
            QualityCriterion.CONSISTENCY: 0.20,
            QualityCriterion.TONE: 0.15,
            QualityCriterion.ACTIONABILITY: 0.10,
            QualityCriterion.SAFETY: 0.15,
        }

        overall_score = sum(
            score.score * weights.get(score.criterion, 0.1)
            for score in scores
        )

        # æ”¹å–„ãŒå¿…è¦ã‹åˆ¤æ–­
        needs_refinement = (
            overall_score < OVERALL_REFINEMENT_THRESHOLD
            or any(issue.severity == IssueSeverity.CRITICAL for issue in issues)
        )

        # æ”¹å–„ã®å„ªå…ˆé †ä½
        refinement_priority = self._determine_refinement_priority(issues)

        return CritiqueResult(
            scores=scores,
            issues=issues,
            overall_score=overall_score,
            needs_refinement=needs_refinement,
            refinement_priority=refinement_priority,
        )

    def refine(
        self,
        response: str,
        critique_result: CritiqueResult,
        original_message: str,
        context: Optional[Dict[str, Any]] = None
    ) -> RefinedResponse:
        """
        æ‰¹åˆ¤çµæœã«åŸºã¥ã„ã¦å›ç­”ã‚’æ”¹å–„

        Args:
            response: å…ƒã®å›ç­”
            critique_result: æ‰¹åˆ¤çµæœ
            original_message: å…ƒã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            context: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±

        Returns:
            RefinedResponse: æ”¹å–„ã•ã‚ŒãŸå›ç­”
        """
        start_time = datetime.now(JST)
        refined = response

        if not critique_result.needs_refinement:
            return RefinedResponse(
                original=response,
                refined=response,
                improvements=[],
                refinement_applied=False,
                refinement_time_ms=0,
            )

        applied_improvements = []

        # å„ªå…ˆåº¦é †ã«æ”¹å–„ã‚’é©ç”¨
        for issue_type in critique_result.refinement_priority:
            matching_issues = [
                issue for issue in critique_result.issues
                if issue.issue_type == issue_type
            ]

            for issue in matching_issues:
                refined_text, applied = self._apply_fix(refined, issue, original_message, context)
                if applied:
                    refined = refined_text
                    applied_improvements.append(issue)

        # æ”¹å–„å¾Œã®æ™‚é–“ã‚’è¨ˆç®—
        end_time = datetime.now(JST)
        refinement_time_ms = (end_time - start_time).total_seconds() * 1000

        return RefinedResponse(
            original=response,
            refined=refined,
            improvements=applied_improvements,
            refinement_applied=len(applied_improvements) > 0,
            refinement_time_ms=refinement_time_ms,
        )

    def evaluate_and_refine(
        self,
        response: str,
        original_message: str,
        context: Optional[Dict[str, Any]] = None
    ) -> RefinedResponse:
        """
        è©•ä¾¡ã¨æ”¹å–„ã‚’ä¸€æ‹¬ã§å®Ÿè¡Œ

        Args:
            response: ç”Ÿæˆã•ã‚ŒãŸå›ç­”
            original_message: å…ƒã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            context: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±

        Returns:
            RefinedResponse: æ”¹å–„ã•ã‚ŒãŸå›ç­”
        """
        critique_result = self.critique(response, original_message, context)
        return self.refine(response, critique_result, original_message, context)

    # ========================================================================
    # å“è³ªè©•ä¾¡ãƒ¡ã‚½ãƒƒãƒ‰
    # ========================================================================

    def _evaluate_relevance(
        self,
        response: str,
        original_message: str,
        context: Dict[str, Any]
    ) -> QualityScore:
        """
        é–¢é€£æ€§ã‚’è©•ä¾¡

        è³ªå•ã«ç­”ãˆã¦ã„ã‚‹ã‹ã©ã†ã‹
        """
        score = 1.0
        reasoning_parts = []

        # è³ªå•ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒå›ç­”ã«åæ˜ ã•ã‚Œã¦ã„ã‚‹ã‹
        question_keywords = self._extract_keywords(original_message)
        response_lower = response.lower()

        matched_keywords = [kw for kw in question_keywords if kw in response_lower]
        keyword_match_ratio = len(matched_keywords) / max(len(question_keywords), 1)

        if keyword_match_ratio < 0.3:
            score -= 0.3
            reasoning_parts.append(f"ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®åæ˜ ãŒå°‘ãªã„: {len(matched_keywords)}/{len(question_keywords)}")
        elif keyword_match_ratio >= 0.6:
            reasoning_parts.append(f"ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒã‚ˆãåæ˜ ã•ã‚Œã¦ã„ã‚‹: {len(matched_keywords)}/{len(question_keywords)}")

        # è³ªå•å½¢å¼ã¸ã®å¯¾å¿œ
        if "ï¼Ÿ" in original_message or "?" in original_message:
            # è³ªå•ã«ã¯ä½•ã‚‰ã‹ã®å›ç­”ãŒå«ã¾ã‚Œã‚‹ã¹ã
            answer_indicators = ["ã¯", "ã§ã™", "ã ã‚ˆ", "ã‚¦ãƒ«", "æ€ã†", "ã‹ãª"]
            if not any(ind in response for ind in answer_indicators):
                score -= 0.2
                reasoning_parts.append("è³ªå•ã«å¯¾ã™ã‚‹å›ç­”ãŒä¸æ˜ç¢º")
            else:
                reasoning_parts.append("è³ªå•ã«å›ç­”ã—ã¦ã„ã‚‹")

        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã®æ•´åˆæ€§
        if context.get("expected_topic"):
            if context["expected_topic"].lower() not in response_lower:
                score -= 0.2
                reasoning_parts.append(f"æœŸå¾…ã•ã‚Œã‚‹ãƒˆãƒ”ãƒƒã‚¯ã€Œ{context['expected_topic']}ã€ã«è¨€åŠãªã—")

        return QualityScore(
            criterion=QualityCriterion.RELEVANCE,
            score=max(0.0, min(1.0, score)),
            reasoning="; ".join(reasoning_parts) if reasoning_parts else "é–¢é€£æ€§ã¯å•é¡Œãªã—",
            details={"keyword_match_ratio": keyword_match_ratio, "matched_keywords": matched_keywords},
        )

    def _evaluate_completeness(
        self,
        response: str,
        original_message: str,
        context: Dict[str, Any]
    ) -> QualityScore:
        """
        å®Œå…¨æ€§ã‚’è©•ä¾¡

        å¿…è¦ãªæƒ…å ±ãŒæƒã£ã¦ã„ã‚‹ã‹
        """
        score = 1.0
        reasoning_parts = []

        # é•·ã•ãƒã‚§ãƒƒã‚¯
        response_length = len(response)
        if response_length < LENGTH_GUIDELINES["min"]:
            score -= 0.4
            reasoning_parts.append(f"çŸ­ã™ãã‚‹: {response_length}æ–‡å­—ï¼ˆæœ€å°{LENGTH_GUIDELINES['min']}æ–‡å­—ï¼‰")
        elif response_length < LENGTH_GUIDELINES["ideal_min"]:
            score -= 0.2
            reasoning_parts.append(f"ã‚„ã‚„çŸ­ã„: {response_length}æ–‡å­—")
        elif response_length > LENGTH_GUIDELINES["max"]:
            score -= 0.3
            reasoning_parts.append(f"é•·ã™ãã‚‹: {response_length}æ–‡å­—ï¼ˆæœ€å¤§{LENGTH_GUIDELINES['max']}æ–‡å­—ï¼‰")
        elif response_length > LENGTH_GUIDELINES["ideal_max"]:
            score -= 0.1
            reasoning_parts.append(f"ã‚„ã‚„é•·ã„: {response_length}æ–‡å­—")
        else:
            reasoning_parts.append(f"é©åˆ‡ãªé•·ã•: {response_length}æ–‡å­—")

        # æ–‡ã®é€”åˆ‡ã‚Œãƒã‚§ãƒƒã‚¯
        for pattern in INCOMPLETE_SENTENCE_PATTERNS:
            if re.search(pattern, response):
                score -= 0.5
                reasoning_parts.append(f"æ–‡ãŒé€”åˆ‡ã‚Œã¦ã„ã‚‹ï¼ˆãƒ‘ã‚¿ãƒ¼ãƒ³: {pattern}ï¼‰")
                break

        # è¤‡æ•°ã®è³ªå•ã¸ã®å¯¾å¿œ
        question_marks = original_message.count("ï¼Ÿ") + original_message.count("?")
        if question_marks > 1:
            # è¤‡æ•°ã®è³ªå•ãŒã‚ã‚‹å ´åˆã€ãã‚Œãã‚Œã«ç­”ãˆã¦ã„ã‚‹ã‹
            sentences = re.split(r"[ã€‚ï¼!]", response)
            if len(sentences) < question_marks:
                score -= 0.2
                reasoning_parts.append(f"è¤‡æ•°ã®è³ªå•ï¼ˆ{question_marks}å€‹ï¼‰ã«å¯¾ã—å›ç­”ãŒå°‘ãªã„ï¼ˆ{len(sentences)}æ–‡ï¼‰")

        return QualityScore(
            criterion=QualityCriterion.COMPLETENESS,
            score=max(0.0, min(1.0, score)),
            reasoning="; ".join(reasoning_parts) if reasoning_parts else "å®Œå…¨æ€§ã¯å•é¡Œãªã—",
            details={"response_length": response_length},
        )

    def _evaluate_consistency(
        self,
        response: str,
        context: Dict[str, Any]
    ) -> QualityScore:
        """
        ä¸€è²«æ€§ã‚’è©•ä¾¡

        çŸ›ç›¾ãŒãªã„ã‹ã€å‰ã®ç™ºè¨€ã¨æ•´åˆã—ã¦ã„ã‚‹ã‹
        """
        score = 1.0
        reasoning_parts = []

        # å›ç­”å†…ã®çŸ›ç›¾ãƒã‚§ãƒƒã‚¯
        contradiction_pairs = [
            ("ã§ãã‚‹", "ã§ããªã„"),
            ("ã‚ã‚‹", "ãªã„"),
            ("ã—ãŸ", "ã—ã¦ã„ãªã„"),
            ("ã¯ã„", "ã„ã„ãˆ"),
            ("å¿…è¦", "ä¸è¦"),
        ]

        for positive, negative in contradiction_pairs:
            if positive in response and negative in response:
                # åŒã˜æ–‡è„ˆã§ä¸¡æ–¹å‡ºã¦ããŸã‚‰çŸ›ç›¾ã®å¯èƒ½æ€§
                score -= 0.3
                reasoning_parts.append(f"æ½œåœ¨çš„ãªçŸ›ç›¾: ã€Œ{positive}ã€ã¨ã€Œ{negative}ã€ãŒä¸¡æ–¹å­˜åœ¨")

        # å‰ã®ç™ºè¨€ã¨ã®æ•´åˆæ€§
        if context.get("previous_response"):
            prev = context["previous_response"]
            # å‰ã¨çœŸé€†ã®ã“ã¨ã‚’è¨€ã£ã¦ã„ãªã„ã‹ï¼ˆç°¡æ˜“ãƒã‚§ãƒƒã‚¯ï¼‰
            prev_positive = "ã§ãã‚‹" in prev or "ã‚ã‚‹" in prev or "ã¯ã„" in prev
            curr_negative = "ã§ããªã„" in response or "ãªã„" in response or "ã„ã„ãˆ" in response

            if prev_positive and curr_negative:
                # æ–‡è„ˆæ¬¡ç¬¬ã§ã¯å•é¡Œãªã„ãŒã€ãƒ•ãƒ©ã‚°ã‚’ç«‹ã¦ã‚‹
                reasoning_parts.append("å‰å›ã®ç™ºè¨€ã¨ç•°ãªã‚‹å†…å®¹ï¼ˆæ„å›³çš„ã‹ã‚‚ã—ã‚Œãªã„ï¼‰")

        if not reasoning_parts:
            reasoning_parts.append("ä¸€è²«æ€§ã¯å•é¡Œãªã—")

        return QualityScore(
            criterion=QualityCriterion.CONSISTENCY,
            score=max(0.0, min(1.0, score)),
            reasoning="; ".join(reasoning_parts),
            details={},
        )

    def _evaluate_tone(self, response: str) -> QualityScore:
        """
        ãƒˆãƒ¼ãƒ³ã‚’è©•ä¾¡

        ã‚½ã‚¦ãƒ«ãã‚“ã‚‰ã—ã„å£èª¿ã‹
        """
        score = 1.0
        reasoning_parts = []

        # ã‚½ã‚¦ãƒ«ãã‚“ã‚‰ã—ã„è¡¨ç¾ãŒã‚ã‚‹ã‹
        soulkun_matches = sum(
            1 for pattern in SOULKUN_TONE_PATTERNS
            if re.search(pattern, response)
        )

        if soulkun_matches == 0:
            score -= 0.3
            reasoning_parts.append("ã‚½ã‚¦ãƒ«ãã‚“ã‚‰ã—ã„è¡¨ç¾ãŒãªã„ï¼ˆã‚¦ãƒ«ã€ã€œã ã­ç­‰ï¼‰")
        elif soulkun_matches >= 2:
            reasoning_parts.append(f"ã‚½ã‚¦ãƒ«ãã‚“ã‚‰ã—ã„è¡¨ç¾ãŒ{soulkun_matches}å€‹ã‚ã‚‹")

        # ä¸é©åˆ‡ãªãƒˆãƒ¼ãƒ³ãŒãªã„ã‹
        inappropriate_matches = []
        for pattern in INAPPROPRIATE_TONE_PATTERNS:
            if re.search(pattern, response):
                inappropriate_matches.append(pattern)

        if inappropriate_matches:
            score -= 0.2 * len(inappropriate_matches)
            reasoning_parts.append(f"ä¸é©åˆ‡ãªãƒˆãƒ¼ãƒ³: {len(inappropriate_matches)}ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡º")

        return QualityScore(
            criterion=QualityCriterion.TONE,
            score=max(0.0, min(1.0, score)),
            reasoning="; ".join(reasoning_parts) if reasoning_parts else "ãƒˆãƒ¼ãƒ³ã¯é©åˆ‡",
            details={"soulkun_matches": soulkun_matches, "inappropriate_matches": inappropriate_matches},
        )

    def _evaluate_actionability(
        self,
        response: str,
        original_message: str
    ) -> QualityScore:
        """
        è¡Œå‹•å¯èƒ½æ€§ã‚’è©•ä¾¡

        æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãŒæ˜ç¢ºã‹
        """
        score = 1.0
        reasoning_parts = []

        # ä¾é ¼ã¸ã®å›ç­”ã®å ´åˆã€æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãŒæ˜ç¢ºã‹
        request_indicators = ["ã—ã¦", "ã—ãŸã„", "ãŠé¡˜ã„", "ãã ã•ã„", "é ¼ã‚€"]
        is_request = any(ind in original_message for ind in request_indicators)

        if is_request:
            # ä¾é ¼ã«å¯¾ã—ã¦ã¯ä½•ã‚‰ã‹ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³è¡¨æ˜ãŒå¿…è¦
            action_indicators = [
                "ã™ã‚‹", "ã—ãŸ", "ã‚„ã‚‹", "ã‚„ã£ãŸ", "å®Œäº†", "çµ‚ã‚ã£ãŸ",
                "ã§ãã‚‹", "ã§ããªã„", "ã‚ã‹ã£ãŸ", "äº†è§£", "æ‰¿çŸ¥",
            ]
            has_action = any(ind in response for ind in action_indicators)

            if not has_action:
                score -= 0.3
                reasoning_parts.append("ä¾é ¼ã«å¯¾ã™ã‚‹ã‚¢ã‚¯ã‚·ãƒ§ãƒ³è¡¨æ˜ãŒãªã„")
            else:
                reasoning_parts.append("ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’è¡¨æ˜ã—ã¦ã„ã‚‹")

        # è³ªå•å½¢å¼ã§çµ‚ã‚ã£ã¦ã„ã‚‹ã‹ï¼ˆç¢ºèªã‚’æ±‚ã‚ã¦ã„ã‚‹ï¼‰
        if response.rstrip().endswith(("ï¼Ÿ", "?")):
            reasoning_parts.append("ç¢ºèªã‚’æ±‚ã‚ã‚‹å½¢ã§çµ‚ã‚ã£ã¦ã„ã‚‹ï¼ˆæ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’ä¿ƒã—ã¦ã„ã‚‹ï¼‰")

        if not reasoning_parts:
            reasoning_parts.append("è¡Œå‹•å¯èƒ½æ€§ã¯å•é¡Œãªã—")

        return QualityScore(
            criterion=QualityCriterion.ACTIONABILITY,
            score=max(0.0, min(1.0, score)),
            reasoning="; ".join(reasoning_parts),
            details={"is_request": is_request},
        )

    def _evaluate_safety(self, response: str) -> QualityScore:
        """
        å®‰å…¨æ€§ã‚’è©•ä¾¡

        æ©Ÿå¯†æƒ…å ±ã‚„ä¸é©åˆ‡ãªè¡¨ç¾ãŒãªã„ã‹
        """
        score = 1.0
        reasoning_parts = []
        detected_patterns = []

        # æ©Ÿå¯†æƒ…å ±ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒã‚§ãƒƒã‚¯
        for pattern in SENSITIVE_INFO_PATTERNS:
            if re.search(pattern, response):
                score -= 0.5
                detected_patterns.append(pattern)

        if detected_patterns:
            reasoning_parts.append(f"æ©Ÿå¯†æƒ…å ±ã®å¯èƒ½æ€§: {len(detected_patterns)}ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡º")
        else:
            reasoning_parts.append("æ©Ÿå¯†æƒ…å ±ã¯æ¤œå‡ºã•ã‚Œãš")

        return QualityScore(
            criterion=QualityCriterion.SAFETY,
            score=max(0.0, min(1.0, score)),
            reasoning="; ".join(reasoning_parts),
            details={"detected_patterns": detected_patterns},
        )

    # ========================================================================
    # å•é¡Œæ¤œå‡ºãƒ¡ã‚½ãƒƒãƒ‰
    # ========================================================================

    def _detect_issues(
        self,
        response: str,
        scores: List[QualityScore],
        original_message: str,
        context: Dict[str, Any]
    ) -> List[DetectedIssue]:
        """
        å•é¡Œã‚’æ¤œå‡º
        """
        issues = []

        # ã‚¹ã‚³ã‚¢ãƒ™ãƒ¼ã‚¹ã®å•é¡Œæ¤œå‡º
        for score in scores:
            threshold = QUALITY_THRESHOLDS.get(score.criterion, 0.7)
            if score.score < threshold:
                severity = self._determine_severity(score.score, threshold)
                issues.append(DetectedIssue(
                    issue_type=self._criterion_to_issue_type(score.criterion),
                    severity=severity,
                    description=score.reasoning,
                    suggestion=self._generate_suggestion(score.criterion, score),
                ))

        # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ™ãƒ¼ã‚¹ã®å•é¡Œæ¤œå‡º
        pattern_issues = self._detect_pattern_issues(response, original_message)
        issues.extend(pattern_issues)

        return issues

    def _detect_pattern_issues(
        self,
        response: str,
        original_message: str
    ) -> List[DetectedIssue]:
        """
        ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ™ãƒ¼ã‚¹ã§å•é¡Œã‚’æ¤œå‡º
        """
        issues = []

        # æ–‡ã®é€”åˆ‡ã‚Œ
        for pattern in INCOMPLETE_SENTENCE_PATTERNS:
            match = re.search(pattern, response)
            if match:
                issues.append(DetectedIssue(
                    issue_type=IssueType.INCOMPLETE_SENTENCE,
                    severity=IssueSeverity.CRITICAL,
                    description=f"æ–‡ãŒé€”åˆ‡ã‚Œã¦ã„ã‚‹: ã€Œ{response[-20:]}ã€",
                    location=match.group(),
                    suggestion="æ–‡ã‚’å®Œçµã•ã›ã‚‹",
                ))
                break  # æœ€åˆã®1ã¤ã ã‘

        # é•·ã™ãã‚‹
        if len(response) > LENGTH_GUIDELINES["max"]:
            issues.append(DetectedIssue(
                issue_type=IssueType.TOO_LONG,
                severity=IssueSeverity.MEDIUM,
                description=f"å›ç­”ãŒé•·ã™ãã‚‹: {len(response)}æ–‡å­—",
                suggestion=f"{LENGTH_GUIDELINES['ideal_max']}æ–‡å­—ç¨‹åº¦ã«è¦ç´„ã™ã‚‹",
            ))

        # çŸ­ã™ãã‚‹
        if len(response) < LENGTH_GUIDELINES["min"]:
            issues.append(DetectedIssue(
                issue_type=IssueType.TOO_SHORT,
                severity=IssueSeverity.HIGH,
                description=f"å›ç­”ãŒçŸ­ã™ãã‚‹: {len(response)}æ–‡å­—",
                suggestion="ã‚‚ã†å°‘ã—è©³ã—ãå›ç­”ã™ã‚‹",
            ))

        return issues

    def _determine_severity(self, score: float, threshold: float) -> IssueSeverity:
        """
        ã‚¹ã‚³ã‚¢ã‹ã‚‰æ·±åˆ»åº¦ã‚’åˆ¤å®š
        """
        gap = threshold - score
        if gap > 0.4:
            return IssueSeverity.CRITICAL
        elif gap > 0.2:
            return IssueSeverity.HIGH
        elif gap > 0.1:
            return IssueSeverity.MEDIUM
        else:
            return IssueSeverity.LOW

    def _criterion_to_issue_type(self, criterion: QualityCriterion) -> IssueType:
        """
        å“è³ªåŸºæº–ã‹ã‚‰å•é¡Œã‚¿ã‚¤ãƒ—ã«å¤‰æ›
        """
        mapping = {
            QualityCriterion.RELEVANCE: IssueType.OFF_TOPIC,
            QualityCriterion.COMPLETENESS: IssueType.MISSING_INFO,
            QualityCriterion.CONSISTENCY: IssueType.CONTRADICTION,
            QualityCriterion.TONE: IssueType.WRONG_TONE,
            QualityCriterion.ACTIONABILITY: IssueType.UNCLEAR_ACTION,
            QualityCriterion.SAFETY: IssueType.SENSITIVE_INFO,
        }
        return mapping.get(criterion, IssueType.MISSING_INFO)

    def _generate_suggestion(
        self,
        criterion: QualityCriterion,
        score: QualityScore
    ) -> str:
        """
        æ”¹å–„ææ¡ˆã‚’ç”Ÿæˆ
        """
        suggestions = {
            QualityCriterion.RELEVANCE: "è³ªå•ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å›ç­”ã«å«ã‚ã‚‹",
            QualityCriterion.COMPLETENESS: "å¿…è¦ãªæƒ…å ±ã‚’è¿½åŠ ã™ã‚‹",
            QualityCriterion.CONSISTENCY: "çŸ›ç›¾ã‚’è§£æ¶ˆã™ã‚‹",
            QualityCriterion.TONE: "ã€Œã‚¦ãƒ«ã€ã€Œã€œã ã­ã€ãªã©ã‚½ã‚¦ãƒ«ãã‚“ã‚‰ã—ã„è¡¨ç¾ã‚’è¿½åŠ ",
            QualityCriterion.ACTIONABILITY: "æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ˜ç¢ºã«ã™ã‚‹",
            QualityCriterion.SAFETY: "æ©Ÿå¯†æƒ…å ±ã‚’å‰Šé™¤ã™ã‚‹",
        }
        return suggestions.get(criterion, "å“è³ªã‚’æ”¹å–„ã™ã‚‹")

    def _determine_refinement_priority(
        self,
        issues: List[DetectedIssue]
    ) -> List[IssueType]:
        """
        æ”¹å–„ã®å„ªå…ˆé †ä½ã‚’æ±ºå®š
        """
        # æ·±åˆ»åº¦é †ã«ã‚½ãƒ¼ãƒˆ
        severity_order = {
            IssueSeverity.CRITICAL: 0,
            IssueSeverity.HIGH: 1,
            IssueSeverity.MEDIUM: 2,
            IssueSeverity.LOW: 3,
        }

        sorted_issues = sorted(
            issues,
            key=lambda i: severity_order.get(i.severity, 99)
        )

        # é‡è¤‡ã‚’é™¤ã„ã¦å•é¡Œã‚¿ã‚¤ãƒ—ã®ãƒªã‚¹ãƒˆã‚’è¿”ã™
        seen = set()
        priority = []
        for issue in sorted_issues:
            if issue.issue_type not in seen:
                seen.add(issue.issue_type)
                priority.append(issue.issue_type)

        return priority

    # ========================================================================
    # æ”¹å–„é©ç”¨ãƒ¡ã‚½ãƒƒãƒ‰
    # ========================================================================

    def _apply_fix(
        self,
        response: str,
        issue: DetectedIssue,
        original_message: str,
        context: Optional[Dict[str, Any]]
    ) -> Tuple[str, bool]:
        """
        å•é¡Œã‚’ä¿®æ­£

        Args:
            response: ç¾åœ¨ã®å›ç­”
            issue: å•é¡Œ
            original_message: å…ƒã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            context: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ

        Returns:
            (ä¿®æ­£å¾Œã®å›ç­”, ä¿®æ­£ãŒé©ç”¨ã•ã‚ŒãŸã‹)
        """
        if issue.issue_type == IssueType.INCOMPLETE_SENTENCE:
            return self._fix_incomplete_sentence(response), True

        elif issue.issue_type == IssueType.WRONG_TONE:
            return self._fix_tone(response), True

        elif issue.issue_type == IssueType.TOO_SHORT:
            return self._fix_too_short(response, original_message), True

        elif issue.issue_type == IssueType.SENSITIVE_INFO:
            return self._fix_sensitive_info(response), True

        # ãã®ä»–ã®å•é¡Œã¯LLMãŒå¿…è¦ï¼ˆç¾åœ¨ã¯æœªå¯¾å¿œï¼‰
        return response, False

    def _fix_incomplete_sentence(self, response: str) -> str:
        """
        é€”åˆ‡ã‚ŒãŸæ–‡ã‚’ä¿®æ­£ï¼ˆãƒˆãƒ¼ãƒ³ä»˜ä¸ã¯LLMã«ä»»ã›ã‚‹ï¼‰
        """
        # åŠ©è©ã§çµ‚ã‚ã£ã¦ã„ã‚‹å ´åˆã€é©åˆ‡ãªçµ‚ã‚ã‚Šæ–¹ã‚’è¿½åŠ 
        if re.search(r"[ã‚’ã«ãŒã¯ã§ã¨ã¸ã‚‚ã®]$", response):
            response = response.rstrip("ã‚’ã«ãŒã¯ã§ã¨ã¸ã‚‚ã®")
            response += "..."

        # èª­ç‚¹ã§çµ‚ã‚ã£ã¦ã„ã‚‹å ´åˆ
        if response.endswith("ã€"):
            response = response.rstrip("ã€")
            response += "ã€‚"

        return response

    def _fix_tone(self, response: str) -> str:
        """
        ãƒˆãƒ¼ãƒ³ã‚’ä¿®æ­£ï¼ˆã‚¦ãƒ«ä»˜ä¸ã¯LLMã®ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§é »åº¦åˆ¶å¾¡ã™ã‚‹ãŸã‚ã€
        ã“ã“ã§ã¯ç¡¬ã„è¡¨ç¾ã‚’æŸ”ã‚‰ã‹ãã™ã‚‹ã ã‘ã«ç•™ã‚ã‚‹ï¼‰
        """
        # ç¡¬ã„çµ‚ã‚ã‚Šæ–¹ã‚’æŸ”ã‚‰ã‹ãã™ã‚‹
        if response.endswith("ã§ã™ã€‚"):
            response = response[:-2] + "ã ã‚ˆã€‚"
        elif response.endswith("ã¾ã™ã€‚"):
            response = response[:-1] + "ï¼"

        return response

    def _fix_too_short(self, response: str, original_message: str) -> str:
        """
        çŸ­ã™ãã‚‹å›ç­”ã‚’ä¿®æ­£ï¼ˆãƒˆãƒ¼ãƒ³ä»˜ä¸ã¯LLMã«ä»»ã›ã‚‹ï¼‰
        """
        # æœ€ä½é™ã®è£œè¶³ã‚’è¿½åŠ 
        if len(response) < 10:
            if "ï¼Ÿ" in original_message or "?" in original_message:
                response += " è©³ã—ãçŸ¥ã‚ŠãŸã„ã“ã¨ãŒã‚ã‚Œã°èã„ã¦ã­ï¼"
            else:
                response += " ä»–ã«ä½•ã‹ã‚ã‚Œã°è¨€ã£ã¦ã­ï¼"

        return response

    def _fix_sensitive_info(self, response: str) -> str:
        """
        æ©Ÿå¯†æƒ…å ±ã‚’å‰Šé™¤
        """
        for pattern in SENSITIVE_INFO_PATTERNS:
            response = re.sub(pattern, "[æ©Ÿå¯†æƒ…å ±]", response)

        return response

    # ========================================================================
    # ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
    # ========================================================================

    def _extract_keywords(self, message: str) -> List[str]:
        """
        ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º
        """
        # ç°¡æ˜“çš„ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º
        # åŠ©è©ã‚„è¨˜å·ã‚’é™¤ã„ãŸåè©çš„ãªå˜èªã‚’æŠ½å‡º
        words = re.findall(r"[ä¸€-é¾ ã-ã‚“ã‚¡-ãƒ³]+", message)
        # çŸ­ã™ãã‚‹å˜èªã¨åŠ©è©ã‚’é™¤å¤–
        stopwords = {"ã®", "ã¯", "ãŒ", "ã‚’", "ã«", "ã§", "ã¨", "ã‚‚", "ã‚„", "ã¸", "ã‹ã‚‰", "ã¾ã§", "ã‚ˆã‚Š"}
        keywords = [w for w in words if len(w) > 1 and w not in stopwords]
        return keywords


# ============================================================================
# ãƒ•ã‚¡ã‚¯ãƒˆãƒªé–¢æ•°
# ============================================================================

def create_self_critique(llm_client=None) -> SelfCritique:
    """
    SelfCritiqueã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ

    Args:
        llm_client: LLMã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

    Returns:
        SelfCritique ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
    """
    return SelfCritique(llm_client=llm_client)
