# lib/brain/memory_authority.py
"""
Ë®òÊÜ∂Ê®©Â®ÅÂ±§ÔºàMemory Authority LayerÔºâ

v10.43.0 P4: Èï∑ÊúüË®òÊÜ∂„Å®„ÅÆÁüõÁõæ„ÇíÊúÄÁµÇ„ÉÅ„Çß„ÉÉ„ÇØ„Åô„Çã„É¨„Ç§„É§„Éº

„ÄêÂΩπÂâ≤„Äë
P3 ValueAuthority „Åß‰æ°ÂÄ§Ë¶≥„ÉÅ„Çß„ÉÉ„ÇØ„ÇíÈÄöÈÅé„Åó„Åü„Ç¢„ÇØ„Ç∑„Éß„É≥„Å´ÂØæ„Åó„ÄÅ
„É¶„Éº„Ç∂„Éº„ÅÆ„ÄåÈï∑ÊúüË®òÊÜ∂„ÄçÔºà‰øùÂ≠òÊ∏à„Åø„ÅÆÊñπÈáù„ÉªÁ¶ÅÊ≠¢‰∫ãÈ†Ö„ÉªÂÑ™ÂÖàÈ†Ü‰ΩçÔºâ„Å®„ÅÆÁüõÁõæ„ÇíÊúÄÁµÇÂà§ÂÆö„Åô„Çã„ÄÇ

„ÄêË®≠Ë®àÊÄùÊÉ≥„Äë
- Ë™§„Éñ„É≠„ÉÉ„ÇØ„ÇíÊúÄÂ∞èÂåñ„Åô„Çã„Åü„ÇÅ„ÄÅHARD CONFLICT „ÅÆ„ÅøÂç≥Â∫ß„Å´„Éñ„É≠„ÉÉ„ÇØ
- ÊõñÊòß„Å™„Ç±„Éº„Çπ„ÅØ REQUIRE_CONFIRMATION „ÅßÁ¢∫Ë™ç„Çí‰øÉ„Åô
- Èï∑ÊúüË®òÊÜ∂„Åå„Å™„ÅÑ/Âº±„ÅÑ„Éû„ÉÉ„ÉÅ„ÅÆÂ†¥Âêà„ÅØ„Éã„É•„Éº„Éà„É©„É´ÔºàAPPROVEÔºâ„Å´ÂÄí„Åô

„ÄêÂà§ÂÆö„Éï„É≠„Éº„Äë
P3 ValueAuthority ‚Üí MemoryAuthorityÂà§ÂÆö ‚Üí OK„Å™„ÇâExecution / NG„Å™„Çâ‰ª£ÊõøÊèêÊ°à or Á¢∫Ë™ç

„ÄêÁµ±Âêà‰ΩçÁΩÆ„Äë
core.py „ÅÆ _execute() „Å´„Å¶„ÄÅP3 „ÅÆÁõ¥Âæå„ÉªÂÆüË°åÁõ¥Ââç

Ë®≠Ë®àÊõ∏: docs/13_brain_architecture.md
"""

import logging
import re
import unicodedata
from dataclasses import dataclass, field
from enum import Enum
from typing import Any, Dict, List, Optional, TypedDict

logger = logging.getLogger(__name__)


# =============================================================================
# Âà§ÂÆöÁµêÊûú„ÅÆÂûãÂÆöÁæ©
# =============================================================================


class MemoryDecision(Enum):
    """
    Ë®òÊÜ∂Ê®©Â®ÅÂ±§„ÅÆÂà§ÂÆöÁµêÊûú

    APPROVE: ÂÆüË°åOKÔºàÁüõÁõæ„Å™„Åó or Èï∑ÊúüË®òÊÜ∂„Å™„ÅóÔºâ
    BLOCK_AND_SUGGEST: ÂÆüË°å„Éñ„É≠„ÉÉ„ÇØ + ‰ª£ÊõøÊ°àÊèêÁ§∫ÔºàHARD CONFLICTÔºâ
    FORCE_MODE_SWITCH: „É¢„Éº„ÉâÂº∑Âà∂ÈÅ∑ÁßªÔºàÈáçÂ§ß„Å™ÁüõÁõæÔºâ
    REQUIRE_CONFIRMATION: Á¢∫Ë™ç„ÅåÂøÖË¶ÅÔºàSOFT CONFLICTÔºâ
    """
    APPROVE = "approve"
    BLOCK_AND_SUGGEST = "block_and_suggest"
    FORCE_MODE_SWITCH = "force_mode_switch"
    REQUIRE_CONFIRMATION = "require_confirmation"


class MemoryConflict(TypedDict):
    """Ë®òÊÜ∂„Å®„ÅÆÁüõÁõæÊÉÖÂ†±"""
    memory_type: str
    excerpt: str
    why_conflict: str
    severity: str  # "hard" or "soft"


@dataclass
class MemoryAuthorityResult:
    """
    Ë®òÊÜ∂Ê®©Â®ÅÂ±§„ÅÆÂà§ÂÆöÁµêÊûú

    Attributes:
        decision: Âà§ÂÆöÁµêÊûú
        original_action: ÂÖÉ„ÅÆ„Ç¢„ÇØ„Ç∑„Éß„É≥Âêç
        reasons: „Éñ„É≠„ÉÉ„ÇØ/Á¢∫Ë™çÁêÜÁî±„ÅÆ„É™„Çπ„Éà
        conflicts: Ê§úÂá∫„Åï„Çå„ÅüÁüõÁõæ„ÅÆ„É™„Çπ„Éà
        suggested_actions: ‰ª£Êõø„Ç¢„ÇØ„Ç∑„Éß„É≥ÂÄôË£ú
        confidence: Âà§ÂÆö„ÅÆÁ¢∫‰ø°Â∫¶Ôºà0.0-1.0Ôºâ
        confirmation_message: Á¢∫Ë™çÁî®„É°„ÉÉ„Çª„Éº„Ç∏ÔºàREQUIRE_CONFIRMATIONÊôÇÔºâ
        alternative_message: ‰ª£ÊõøÂøúÁ≠î„É°„ÉÉ„Çª„Éº„Ç∏ÔºàBLOCKÊôÇÔºâ
        forced_mode: Âº∑Âà∂ÈÅ∑ÁßªÂÖà„É¢„Éº„ÉâÂêç
    """
    decision: MemoryDecision
    original_action: str
    reasons: List[str] = field(default_factory=list)
    conflicts: List[MemoryConflict] = field(default_factory=list)
    suggested_actions: List[str] = field(default_factory=list)
    confidence: float = 1.0
    confirmation_message: Optional[str] = None
    alternative_message: Optional[str] = None
    forced_mode: Optional[str] = None

    @property
    def is_approved(self) -> bool:
        """ÂÆüË°å„ÅåÊâøË™ç„Åï„Çå„Åü„Åã"""
        return self.decision == MemoryDecision.APPROVE

    @property
    def should_block(self) -> bool:
        """ÂÆüË°å„Çí„Éñ„É≠„ÉÉ„ÇØ„Åô„Åπ„Åç„Åã"""
        return self.decision in (
            MemoryDecision.BLOCK_AND_SUGGEST,
            MemoryDecision.FORCE_MODE_SWITCH,
        )

    @property
    def needs_confirmation(self) -> bool:
        """Á¢∫Ë™ç„ÅåÂøÖË¶Å„Åã"""
        return self.decision == MemoryDecision.REQUIRE_CONFIRMATION

    @property
    def should_force_mode_switch(self) -> bool:
        """„É¢„Éº„ÉâÂº∑Âà∂ÈÅ∑Áßª„Åô„Åπ„Åç„Åã"""
        return self.decision == MemoryDecision.FORCE_MODE_SWITCH


# =============================================================================
# HARD CONFLICT „Éë„Çø„Éº„É≥ÂÆöÁæ©ÔºàÂç≥„Éñ„É≠„ÉÉ„ÇØÂØæË±°Ôºâ
# =============================================================================


HARD_CONFLICT_PATTERNS: Dict[str, Dict[str, Any]] = {
    "explicit_prohibition": {
        "memory_keywords": ["Á¶ÅÊ≠¢", "Áµ∂ÂØæ„Å´„Åó„Å™„ÅÑ", "„ÇÑ„Çâ„Å™„ÅÑ", "NG", "Âé≥Á¶Å"],
        "description": "ÊòéÁ§∫ÁöÑ„Å´Á¶ÅÊ≠¢„Åï„Çå„Å¶„ÅÑ„ÇãË°åÂãï",
        "weight": 1.0,
    },
    "legal_compliance": {
        "memory_keywords": ["Ê≥ïÂãô", "„Ç≥„É≥„Éó„É©„Ç§„Ç¢„É≥„Çπ", "Ê≥ï‰ª§", "Ë¶èÁ¥Ñ", "Â•ëÁ¥ÑÈÅïÂèç"],
        "description": "Ê≥ïÂãô„Éª„Ç≥„É≥„Éó„É©ÁöÑ„Å™Á¶ÅÊ≠¢ÊñπÈáù",
        "weight": 1.0,
    },
    "privacy_protection": {
        "memory_keywords": ["ÂÄã‰∫∫ÊÉÖÂ†±", "Ê©üÂØÜ", "ÁßòÂØÜ", "„Éó„É©„Ç§„Éê„Ç∑„Éº", "ÊºèÊ¥©Á¶ÅÊ≠¢"],
        "description": "ÂÄã‰∫∫ÊÉÖÂ†±/Ê©üÂæÆÊÉÖÂ†±„ÅÆÊâ±„ÅÑ„Å´Èñ¢„Åô„ÇãÁ¶ÅÊ≠¢",
        "weight": 1.0,
    },
    "security_policy": {
        "memory_keywords": ["„Çª„Ç≠„É•„É™„ÉÜ„Ç£", "„Éë„Çπ„ÉØ„Éº„Éâ", "Ë™çË®º", "„Ç¢„ÇØ„Çª„ÇπÂà∂Èôê"],
        "description": "„Çª„Ç≠„É•„É™„ÉÜ„Ç£„Éù„É™„Ç∑„ÉºÈÅïÂèç",
        "weight": 0.9,
    },
}


# =============================================================================
# SOFT CONFLICT „Éë„Çø„Éº„É≥ÂÆöÁæ©ÔºàÁ¢∫Ë™çÂØæË±°Ôºâ
# =============================================================================


SOFT_CONFLICT_PATTERNS: Dict[str, Dict[str, Any]] = {
    "priority_contradiction": {
        "memory_keywords": ["ÊúÄÂÑ™ÂÖà", "Á¨¨‰∏ÄÂÑ™ÂÖà", "‰Ωï„Çà„ÇäÂ§ß‰∫ã", "ÊúÄÈáçË¶Å"],
        "check_patterns": [
            r"ÂæåÂõû„Åó",
            r"ÂÑ™ÂÖà.*‰∏ã„Åí",
            r"Âª∂Êúü",
            r"„Ç≠„É£„É≥„Çª„É´",
        ],
        "description": "ÂÑ™ÂÖàÈ†Ü‰Ωç„Å®„ÅÆÁüõÁõæ",
        "weight": 0.7,
    },
    "family_health_risk": {
        "memory_keywords": ["ÂÆ∂Êóè", "ÂÅ•Â∫∑", "‰ΩìË™ø", "‰ºëÊÅØ"],
        "check_patterns": [
            r"ÂæπÂ§ú",
            r"Ê∑±Â§ú",
            r"‰ºë„Åø.*Ëøî‰∏ä",
            r"ÁÑ°ÁêÜ.*„Åó„Å¶",
        ],
        "description": "ÂÆ∂Êóè„ÉªÂÅ•Â∫∑„ÇíÂâä„ÇãÂèØËÉΩÊÄß",
        "weight": 0.6,
    },
    "freedom_restriction": {
        "memory_keywords": ["Ëá™Áî±", "Ëá™ÂàÜ„ÅÆÊôÇÈñì", "„Éó„É©„Ç§„Éô„Éº„Éà", "„ÉØ„Éº„ÇØ„É©„Ç§„Éï„Éê„É©„É≥„Çπ"],
        "check_patterns": [
            r"Âº∑Âà∂",
            r"ÂøÖÈ†à",
            r"Áµ∂ÂØæ.*„ÇÑ„Çã",
            r"ÈÄÉ„Åí„Çâ„Çå„Å™„ÅÑ",
        ],
        "description": "Ëá™Áî±„ÇíÂº∑„ÅèÂà∂Èôê„Åô„ÇãÂèØËÉΩÊÄß",
        "weight": 0.5,
    },
}


# =============================================================================
# ALIGNMENT „Éë„Çø„Éº„É≥ÂÆöÁæ©ÔºàÁ©çÊ•µÊâøË™çÂØæË±°Ôºâ
# =============================================================================


ALIGNMENT_PATTERNS: Dict[str, Dict[str, Any]] = {
    "business_priority": {
        "memory_keywords": ["ÂèóÊ≥®", "Â£≤‰∏ä", "Êé°Áî®", "ÊàêÁ¥Ñ"],
        "description": "„Éì„Ç∏„Éç„ÇπÁõÆÊ®ô„Å´Ê≤ø„ÅÜ",
        "weight": 0.8,
    },
    "systematization": {
        "memory_keywords": ["‰ªïÁµÑ„ÅøÂåñ", "Ëá™ÂãïÂåñ", "ÂäπÁéáÂåñ", "Ê®ôÊ∫ñÂåñ"],
        "description": "‰ªïÁµÑ„ÅøÂåñ„ÉªÂäπÁéáÂåñ„Å´Ê≤ø„ÅÜ",
        "weight": 0.7,
    },
    "growth": {
        "memory_keywords": ["ÊàêÈï∑", "Â≠¶Áøí", "„Çπ„Ç≠„É´„Ç¢„ÉÉ„Éó", "ÊåëÊà¶"],
        "description": "ÊàêÈï∑ÁõÆÊ®ô„Å´Ê≤ø„ÅÜ",
        "weight": 0.7,
    },
}


# =============================================================================
# „ÉÜ„Ç≠„Çπ„ÉàÊ≠£Ë¶èÂåñÈñ¢Êï∞
# =============================================================================


def normalize_text(text: str) -> str:
    """
    „ÉÜ„Ç≠„Çπ„Éà„ÇíÊ≠£Ë¶èÂåñÔºàÂÖ®ËßíÂçäËßíÁµ±‰∏Ä„ÄÅ„Çπ„Éö„Éº„ÇπÂâäÈô§„ÄÅË®òÂè∑Èô§ÂéªÔºâ

    Args:
        text: Ê≠£Ë¶èÂåñÂØæË±°„ÉÜ„Ç≠„Çπ„Éà

    Returns:
        Ê≠£Ë¶èÂåñ„Åï„Çå„Åü„ÉÜ„Ç≠„Çπ„Éà
    """
    if not text:
        return ""

    # NFKCÊ≠£Ë¶èÂåñÔºàÂÖ®Ëßí‚ÜíÂçäËßí„ÄÅ‰∫íÊèõÊñáÂ≠óÁµ±‰∏ÄÔºâ
    text = unicodedata.normalize("NFKC", text)

    # Â∞èÊñáÂ≠óÂåñ
    text = text.lower()

    # ÈÄ£Á∂ö„Çπ„Éö„Éº„Çπ„ÇíÂçò‰∏Ä„Çπ„Éö„Éº„Çπ„Å´
    text = re.sub(r"\s+", " ", text)

    # ÂâçÂæå„ÅÆÁ©∫ÁôΩ„ÇíÈô§Âéª
    text = text.strip()

    return text


def extract_keywords(text: str, min_length: int = 2) -> List[str]:
    """
    „ÉÜ„Ç≠„Çπ„Éà„Åã„Çâ„Ç≠„Éº„ÉØ„Éº„Éâ„ÇíÊäΩÂá∫ÔºàÊó•Êú¨Ë™ûÂØæÂøúÔºâ

    Args:
        text: ÊäΩÂá∫ÂØæË±°„ÉÜ„Ç≠„Çπ„Éà
        min_length: ÊúÄÂ∞èÊñáÂ≠óÊï∞

    Returns:
        „Ç≠„Éº„ÉØ„Éº„Éâ„É™„Çπ„Éà
    """
    if not text:
        return []

    normalized = normalize_text(text)
    words = []

    for word in normalized.split():
        if len(word) >= min_length:
            words.append(word)

    japanese_pattern = r"[\u3040-\u309F\u30A0-\u30FF\u4E00-\u9FFF]+"
    for match in re.finditer(japanese_pattern, normalized):
        word = match.group()
        if len(word) >= min_length and word not in words:
            words.append(word)

    return words


def has_keyword_match(
    text: str,
    keywords: List[str],
    require_exact: bool = False,
) -> tuple[bool, List[str]]:
    """
    „ÉÜ„Ç≠„Çπ„ÉàÂÜÖ„Å´„Ç≠„Éº„ÉØ„Éº„Éâ„ÅåÂê´„Åæ„Çå„Çã„Åã„ÉÅ„Çß„ÉÉ„ÇØ

    Args:
        text: Ê§úÊüªÂØæË±°„ÉÜ„Ç≠„Çπ„Éà
        keywords: Ê§úÁ¥¢„Ç≠„Éº„ÉØ„Éº„Éâ„É™„Çπ„Éà
        require_exact: ÂÆåÂÖ®‰∏ÄËá¥„ÇíË¶ÅÊ±Ç„Åô„Çã„Åã

    Returns:
        („Éû„ÉÉ„ÉÅ„Åó„Åü„Åã, „Éû„ÉÉ„ÉÅ„Åó„Åü„Ç≠„Éº„ÉØ„Éº„Éâ„É™„Çπ„Éà)
    """
    if not text or not keywords:
        return False, []

    normalized_text = normalize_text(text)
    matched = []

    for keyword in keywords:
        normalized_kw = normalize_text(keyword)
        if not normalized_kw:
            continue

        if require_exact:
            pattern = rf"\b{re.escape(normalized_kw)}\b"
            if re.search(pattern, normalized_text):
                matched.append(keyword)
        else:
            if normalized_kw in normalized_text:
                matched.append(keyword)

    return len(matched) > 0, matched


def calculate_overlap_score(
    text1: str,
    text2: str,
    ngram_size: int = 3,
) -> float:
    """
    2„Å§„ÅÆ„ÉÜ„Ç≠„Çπ„ÉàÈñì„ÅÆN-gramÈáçË§á„Çπ„Ç≥„Ç¢„ÇíË®àÁÆó

    Args:
        text1: „ÉÜ„Ç≠„Çπ„Éà1
        text2: „ÉÜ„Ç≠„Çπ„Éà2
        ngram_size: N-gram„Çµ„Ç§„Ç∫Ôºà„Éá„Éï„Ç©„É´„Éà3Ôºâ

    Returns:
        ÈáçË§á„Çπ„Ç≥„Ç¢Ôºà0.0-1.0Ôºâ
    """
    if not text1 or not text2:
        return 0.0

    normalized1 = normalize_text(text1)
    normalized2 = normalize_text(text2)

    if len(normalized1) < ngram_size or len(normalized2) < ngram_size:
        return 0.0

    ngrams1 = set()
    ngrams2 = set()

    for i in range(len(normalized1) - ngram_size + 1):
        ngrams1.add(normalized1[i:i + ngram_size])

    for i in range(len(normalized2) - ngram_size + 1):
        ngrams2.add(normalized2[i:i + ngram_size])

    if not ngrams1 or not ngrams2:
        return 0.0

    intersection = len(ngrams1 & ngrams2)
    union = len(ngrams1 | ngrams2)

    if union == 0:
        return 0.0

    return intersection / union


# =============================================================================
# Memory Authority „ÇØ„É©„Çπ
# =============================================================================


class MemoryAuthority:
    """
    Ë®òÊÜ∂Ê®©Â®ÅÂ±§

    „É¶„Éº„Ç∂„Éº„ÅÆÈï∑ÊúüË®òÊÜ∂Ôºà‰øùÂ≠òÊ∏à„Åø„ÅÆÊñπÈáù„ÉªÁ¶ÅÊ≠¢‰∫ãÈ†Ö„ÉªÂÑ™ÂÖàÈ†Ü‰ΩçÔºâ„Å´ÁÖß„Çâ„Åó„Å¶
    „Äå„Åì„ÅÆ„Ç¢„ÇØ„Ç∑„Éß„É≥„ÅØÂÆüË°å„Åó„Å¶„Çà„ÅÑ„Åã„Äç„ÇíÊúÄÁµÇÂà§ÂÆö„Åô„Çã„É¨„Ç§„É§„Éº„ÄÇ
    """

    HARD_THRESHOLD = 0.8
    SOFT_THRESHOLD = 0.5
    LOW_CONFIDENCE_THRESHOLD = 0.3

    def __init__(
        self,
        long_term_memory: Optional[List[Dict[str, Any]]] = None,
        user_name: str = "",
        organization_id: str = "",
    ):
        self.long_term_memory = long_term_memory or []
        self.user_name = user_name or "„ÅÇ„Å™„Åü"
        self.organization_id = organization_id
        self._categorized_memory = self._categorize_memory()

        logger.debug(
            f"MemoryAuthority initialized: "
            f"memory_count={len(self.long_term_memory)}, "
            f"user_name={user_name}"
        )

    def _categorize_memory(self) -> Dict[str, List[Dict[str, Any]]]:
        categorized: Dict[str, List[Dict[str, Any]]] = {
            "compliance": [],
            "principles": [],
            "values": [],
            "goals": [],
            "preferences": [],
        }

        type_weights = {
            "compliance": 1.0,
            "legal": 1.0,
            "principles": 0.9,
            "life_why": 0.8,
            "values": 0.7,
            "long_term_goal": 0.6,
            "identity": 0.5,
        }

        for memory in self.long_term_memory:
            memory_type = memory.get("memory_type", "")
            content = memory.get("content", "")

            if not content:
                continue

            if memory_type in ("compliance", "legal"):
                categorized["compliance"].append(memory)
            elif memory_type in ("principles", "life_why"):
                categorized["principles"].append(memory)
            elif memory_type == "values":
                categorized["values"].append(memory)
            elif memory_type in ("long_term_goal", "goal"):
                categorized["goals"].append(memory)
            else:
                categorized["preferences"].append(memory)

            memory["_weight"] = type_weights.get(memory_type, 0.3)

        return categorized

    def evaluate(
        self,
        message: str,
        action: str,
        action_params: Optional[Dict[str, Any]] = None,
        context: Optional[Dict[str, Any]] = None,
    ) -> MemoryAuthorityResult:
        action_params = action_params or {}
        context = context or {}

        logger.debug(f"üîç [MemoryAuthority] Evaluating action: {action}")

        if not self.long_term_memory:
            logger.debug("[MemoryAuthority] No long-term memory, auto-approving")
            return MemoryAuthorityResult(
                decision=MemoryDecision.APPROVE,
                original_action=action,
                reasons=["Èï∑ÊúüË®òÊÜ∂„Éá„Éº„Çø„Å™„ÅóÔºà„Éã„É•„Éº„Éà„É©„É´Âà§ÂÆöÔºâ"],
                confidence=1.0,
            )

        check_text = self._build_check_text(message, action_params)

        hard_result = self._check_hard_conflicts(check_text, action)
        if hard_result:
            return hard_result

        soft_result = self._check_soft_conflicts(check_text, action)
        if soft_result:
            return soft_result

        alignment_reasons = self._check_alignment(check_text)

        logger.debug(f"‚úÖ [MemoryAuthority] Action approved: {action}")
        return MemoryAuthorityResult(
            decision=MemoryDecision.APPROVE,
            original_action=action,
            reasons=alignment_reasons if alignment_reasons else ["ÁüõÁõæ„Å™„Åó"],
            confidence=0.9 if alignment_reasons else 0.7,
        )

    def _build_check_text(
        self,
        message: str,
        action_params: Dict[str, Any],
    ) -> str:
        parts = [message]

        for key in ("task_body", "content", "description", "title", "body"):
            if key in action_params:
                parts.append(str(action_params[key]))

        return " ".join(parts)

    def _check_hard_conflicts(
        self,
        check_text: str,
        action: str,
    ) -> Optional[MemoryAuthorityResult]:
        conflicts: List[MemoryConflict] = []
        reasons: List[str] = []

        high_priority_memories = (
            self._categorized_memory.get("compliance", []) +
            self._categorized_memory.get("principles", [])
        )

        for memory in high_priority_memories:
            content = memory.get("content", "")
            memory_type = memory.get("memory_type", "")
            weight = memory.get("_weight", 0.5)

            for pattern_key, pattern_def in HARD_CONFLICT_PATTERNS.items():
                keywords = pattern_def.get("memory_keywords", [])

                has_hard_keyword, matched_kws = has_keyword_match(content, keywords)
                if not has_hard_keyword:
                    continue

                overlap_score = calculate_overlap_score(content, check_text)

                if overlap_score >= self.HARD_THRESHOLD or (
                    weight >= 0.9 and overlap_score >= self.SOFT_THRESHOLD
                ):
                    conflict: MemoryConflict = {
                        "memory_type": memory_type,
                        "excerpt": content[:100] + ("..." if len(content) > 100 else ""),
                        "why_conflict": pattern_def.get("description", "Á¶ÅÊ≠¢‰∫ãÈ†Ö„Å´Ë©≤ÂΩì"),
                        "severity": "hard",
                    }
                    conflicts.append(conflict)
                    reasons.append(
                        f"„Äê{pattern_def.get('description', 'HARD CONFLICT')}„Äë"
                        f"Ë®òÊÜ∂„Äå{content[:30]}...„Äç„Å®„ÅÆÁüõÁõæ"
                    )

        if conflicts:
            logger.warning(
                f"üö® [MemoryAuthority] HARD CONFLICT detected: {len(conflicts)} conflicts"
            )
            return MemoryAuthorityResult(
                decision=MemoryDecision.BLOCK_AND_SUGGEST,
                original_action=action,
                reasons=reasons,
                conflicts=conflicts,
                suggested_actions=["general_conversation"],
                confidence=0.95,
                alternative_message=(
                    f"üê∫ „Å°„Çá„Å£„Å®ÂæÖ„Å£„Å¶„Ç¶„É´ÔºÅ{self.user_name}„Åï„Çì„ÄÅ"
                    f"„Åì„Çå„ÅØ‰ª•ÂâçÊ±∫„ÇÅ„ÅüÊñπÈáù„Å®ÁüõÁõæ„Åó„Å¶„Çã„Åã„ÇÇ„Ç¶„É´„ÄÇ\n"
                    f"„Äå{conflicts[0]['excerpt'][:50]}„Äç„Å®„ÅÆÊï¥ÂêàÊÄß„ÇíÁ¢∫Ë™ç„Åó„Å¶„Åª„Åó„ÅÑ„Ç¶„É´üê∫"
                ),
            )

        return None

    def _check_soft_conflicts(
        self,
        check_text: str,
        action: str,
    ) -> Optional[MemoryAuthorityResult]:
        conflicts: List[MemoryConflict] = []
        reasons: List[str] = []

        all_memories = []
        for category in self._categorized_memory.values():
            all_memories.extend(category)

        for memory in all_memories:
            content = memory.get("content", "")
            memory_type = memory.get("memory_type", "")
            weight = memory.get("_weight", 0.5)

            for pattern_key, pattern_def in SOFT_CONFLICT_PATTERNS.items():
                keywords = pattern_def.get("memory_keywords", [])
                check_patterns = pattern_def.get("check_patterns", [])

                has_soft_keyword, _ = has_keyword_match(content, keywords)
                if not has_soft_keyword:
                    continue

                pattern_matched = False
                for pattern in check_patterns:
                    if re.search(pattern, normalize_text(check_text)):
                        pattern_matched = True
                        break

                if pattern_matched:
                    if weight < self.LOW_CONFIDENCE_THRESHOLD:
                        continue

                    conflict: MemoryConflict = {
                        "memory_type": memory_type,
                        "excerpt": content[:100] + ("..." if len(content) > 100 else ""),
                        "why_conflict": pattern_def.get("description", "ÂÑ™ÂÖàÈ†Ü‰Ωç„Å®„ÅÆÁüõÁõæ"),
                        "severity": "soft",
                    }
                    conflicts.append(conflict)
                    reasons.append(
                        f"„Äê{pattern_def.get('description', 'SOFT CONFLICT')}„Äë"
                        f"Ë®òÊÜ∂„Äå{content[:30]}...„Äç„Å®„ÅÆÊΩúÂú®ÁöÑÁüõÁõæ"
                    )

        if conflicts:
            logger.info(
                f"‚ö†Ô∏è [MemoryAuthority] SOFT CONFLICT detected: {len(conflicts)} conflicts"
            )
            return MemoryAuthorityResult(
                decision=MemoryDecision.REQUIRE_CONFIRMATION,
                original_action=action,
                reasons=reasons,
                conflicts=conflicts,
                suggested_actions=[action, "general_conversation"],
                confidence=0.6,
                confirmation_message=(
                    f"üê∫ Á¢∫Ë™ç„Åï„Åõ„Å¶„Ç¶„É´ÔºÅ{self.user_name}„Åï„Çì„ÄÅ\n"
                    f"„Åì„Çå„ÄÅ„Äå{conflicts[0]['excerpt'][:40]}„Äç„Å®Â∞ë„ÅóÁüõÁõæ„Åô„Çã„Åã„ÇÇ„Ç¶„É´„ÄÇ\n"
                    f"Êú¨ÂΩì„Å´ÈÄ≤„ÇÅ„Å¶„ÅÑ„ÅÑ„Ç¶„É´Ôºüüê∫"
                ),
            )

        return None

    def _check_alignment(self, check_text: str) -> List[str]:
        reasons: List[str] = []

        goal_memories = self._categorized_memory.get("goals", [])

        for memory in goal_memories:
            content = memory.get("content", "")

            for pattern_key, pattern_def in ALIGNMENT_PATTERNS.items():
                keywords = pattern_def.get("memory_keywords", [])

                has_alignment_keyword, matched_kws = has_keyword_match(content, keywords)
                if not has_alignment_keyword:
                    continue

                has_check_keyword, _ = has_keyword_match(check_text, keywords)
                if has_check_keyword:
                    reasons.append(
                        f"‚úÖ {pattern_def.get('description', 'ÁõÆÊ®ô')}„Å´Ê≤ø„ÅÜË°åÂãï"
                    )
                    break

        return reasons


# =============================================================================
# „Éï„Ç°„ÇØ„Éà„É™„ÉºÈñ¢Êï∞
# =============================================================================


def create_memory_authority(
    long_term_memory: Optional[List[Dict[str, Any]]] = None,
    user_name: str = "",
    organization_id: str = "",
) -> MemoryAuthority:
    return MemoryAuthority(
        long_term_memory=long_term_memory,
        user_name=user_name,
        organization_id=organization_id,
    )
