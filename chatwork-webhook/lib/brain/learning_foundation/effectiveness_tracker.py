"""
Phase 2E: å­¦ç¿’åŸºç›¤ - æœ‰åŠ¹æ€§è¿½è·¡å±¤

è¨­è¨ˆæ›¸: docs/18_phase2e_learning_foundation.md v1.1.0
ã‚»ã‚¯ã‚·ãƒ§ãƒ³: 7. Phase 2Næº–å‚™ï¼ˆæœ‰åŠ¹æ€§è¿½è·¡ï¼‰

å­¦ç¿’ã®æœ‰åŠ¹æ€§ã‚’è¿½è·¡ã—ã€æ”¹å–„ææ¡ˆã‚’ç”Ÿæˆã™ã‚‹ã€‚
Phase 2Nã§æœ¬æ ¼å®Ÿè£…äºˆå®šã®æ©Ÿèƒ½ã®åŸºç›¤ã‚’æä¾›ã™ã‚‹ã€‚
"""

from dataclasses import dataclass, field
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional, Tuple

from sqlalchemy.engine import Connection

from .constants import (
    AuthorityLevel,
    DecisionImpact,
    LearningCategory,
    DEFAULT_CONFIDENCE_DECAY_RATE,
)
from .models import (
    EffectivenessResult,
    ImprovementSuggestion,
    Learning,
    LearningLog,
)
from .repository import LearningRepository


@dataclass
class EffectivenessMetrics:
    """æœ‰åŠ¹æ€§ãƒ¡ãƒˆãƒªã‚¯ã‚¹"""
    apply_count: int = 0
    positive_feedback_count: int = 0
    negative_feedback_count: int = 0
    feedback_ratio: float = 0.0  # positive / (positive + negative)
    days_since_creation: int = 0
    days_since_last_apply: Optional[int] = None
    confidence_score: float = 1.0  # æ¸›è¡°å¾Œã®ç¢ºä¿¡åº¦


@dataclass
class LearningHealth:
    """å­¦ç¿’ã®å¥å…¨æ€§"""
    learning_id: str
    category: str
    status: str  # healthy, warning, critical, stale
    metrics: EffectivenessMetrics
    issues: List[str] = field(default_factory=list)
    suggestions: List[str] = field(default_factory=list)


class EffectivenessTracker:
    """æœ‰åŠ¹æ€§è¿½è·¡ã‚¯ãƒ©ã‚¹

    å­¦ç¿’ã®æœ‰åŠ¹æ€§ã‚’è¿½è·¡ã—ã€
    æ”¹å–„ææ¡ˆã‚’ç”Ÿæˆã™ã‚‹ã€‚

    Phase 2Nã§æœ¬æ ¼å®Ÿè£…äºˆå®šã®æ©Ÿèƒ½ã®åŸºç›¤ã€‚
    """

    def __init__(
        self,
        organization_id: str,
        repository: Optional[LearningRepository] = None,
        confidence_decay_rate: float = DEFAULT_CONFIDENCE_DECAY_RATE,
    ):
        """åˆæœŸåŒ–

        Args:
            organization_id: çµ„ç¹”ID
            repository: ãƒªãƒã‚¸ãƒˆãƒª
            confidence_decay_rate: ç¢ºä¿¡åº¦æ¸›è¡°ç‡ï¼ˆ1æ—¥ã‚ãŸã‚Šï¼‰
        """
        self.organization_id = organization_id
        self.repository = repository or LearningRepository(organization_id)
        self.confidence_decay_rate = confidence_decay_rate

    # ========================================================================
    # æœ‰åŠ¹æ€§è¨ˆç®—
    # ========================================================================

    def calculate_effectiveness(
        self,
        learning: Learning,
        logs: Optional[List[LearningLog]] = None,
    ) -> EffectivenessResult:
        """å­¦ç¿’ã®æœ‰åŠ¹æ€§ã‚’è¨ˆç®—

        Args:
            learning: å­¦ç¿’
            logs: é©ç”¨ãƒ­ã‚°ï¼ˆæŒ‡å®šã—ãªã„å ´åˆã¯ã‚«ã‚¦ãƒ³ã‚¿ã‹ã‚‰è¨ˆç®—ï¼‰

        Returns:
            æœ‰åŠ¹æ€§çµæœ
        """
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¨ˆç®—
        metrics = self._calculate_metrics(learning)

        # ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
        score = self._calculate_score(metrics)

        # æ”¹å–„ææ¡ˆã‚’ç”Ÿæˆ
        suggestions = self._generate_suggestions(learning, metrics)

        # æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ±ºå®š
        recommendation = self._determine_recommendation(score, metrics)

        if not learning.id:
            raise ValueError("learning.id is required for effectiveness calculation")

        return EffectivenessResult(
            learning_id=learning.id,
            total_applications=metrics.apply_count,
            successful_applications=metrics.positive_feedback_count,
            failed_applications=metrics.negative_feedback_count,
            positive_feedbacks=metrics.positive_feedback_count,
            negative_feedbacks=metrics.negative_feedback_count,
            effectiveness_score=score,
            recommendation=recommendation,
        )

    def calculate_effectiveness_batch(
        self,
        conn: Connection,
        learnings: Optional[List[Learning]] = None,
    ) -> List[EffectivenessResult]:
        """è¤‡æ•°å­¦ç¿’ã®æœ‰åŠ¹æ€§ã‚’ä¸€æ‹¬è¨ˆç®—

        Args:
            conn: DBæ¥ç¶š
            learnings: å­¦ç¿’ã®ãƒªã‚¹ãƒˆï¼ˆæŒ‡å®šã—ãªã„å ´åˆã¯å…¨ä»¶ï¼‰

        Returns:
            æœ‰åŠ¹æ€§çµæœã®ãƒªã‚¹ãƒˆ
        """
        if learnings is None:
            learnings, _ = self.repository.find_all(conn, active_only=True)

        results = []
        for learning in learnings:
            result = self.calculate_effectiveness(learning)
            results.append(result)

        return results

    def _calculate_metrics(
        self,
        learning: Learning,
    ) -> EffectivenessMetrics:
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¨ˆç®—

        Args:
            learning: å­¦ç¿’

        Returns:
            ãƒ¡ãƒˆãƒªã‚¯ã‚¹
        """
        now = datetime.now()

        # é©ç”¨å›æ•°
        apply_count = learning.applied_count or 0

        # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ï¼ˆsuccess/failure countã‚’positive/negativeã¨ã—ã¦ä½¿ç”¨ï¼‰
        positive = learning.success_count or 0
        negative = learning.failure_count or 0
        total_feedback = positive + negative
        feedback_ratio = positive / total_feedback if total_feedback > 0 else 0.0

        # çµŒéæ—¥æ•°
        created_at = learning.created_at or now
        days_since_creation = (now - created_at).days

        # æœ€çµ‚é©ç”¨ã‹ã‚‰ã®æ—¥æ•°ï¼ˆupdated_atã§è¿‘ä¼¼ï¼‰
        updated_at = learning.updated_at or created_at
        days_since_last_apply = (now - updated_at).days

        # ç¢ºä¿¡åº¦ã®æ¸›è¡°
        decay = self.confidence_decay_rate * days_since_creation
        confidence_score = max(0.0, 1.0 - decay)

        return EffectivenessMetrics(
            apply_count=apply_count,
            positive_feedback_count=positive,
            negative_feedback_count=negative,
            feedback_ratio=feedback_ratio,
            days_since_creation=days_since_creation,
            days_since_last_apply=days_since_last_apply,
            confidence_score=confidence_score,
        )

    def _calculate_score(
        self,
        metrics: EffectivenessMetrics,
    ) -> float:
        """æœ‰åŠ¹æ€§ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—

        ã‚¹ã‚³ã‚¢è¨ˆç®—å¼:
        - åŸºæœ¬ã‚¹ã‚³ã‚¢: ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯æ¯”ç‡ * 0.4 + ä½¿ç”¨é »åº¦ã‚¹ã‚³ã‚¢ * 0.3 + ç¢ºä¿¡åº¦ * 0.3
        - ä½¿ç”¨é »åº¦ã‚¹ã‚³ã‚¢: min(1.0, apply_count / 10)  # 10å›ã§æœ€å¤§

        Args:
            metrics: ãƒ¡ãƒˆãƒªã‚¯ã‚¹

        Returns:
            æœ‰åŠ¹æ€§ã‚¹ã‚³ã‚¢ï¼ˆ0.0ã€œ1.0ï¼‰
        """
        # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯æ¯”ç‡ï¼ˆãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãŒãªã„å ´åˆã¯0.5ã¨ã™ã‚‹ï¼‰
        if metrics.positive_feedback_count + metrics.negative_feedback_count == 0:
            feedback_score = 0.5
        else:
            feedback_score = metrics.feedback_ratio

        # ä½¿ç”¨é »åº¦ã‚¹ã‚³ã‚¢
        frequency_score = min(1.0, metrics.apply_count / 10.0)

        # ç¢ºä¿¡åº¦
        confidence_score = metrics.confidence_score

        # ç·åˆã‚¹ã‚³ã‚¢
        score = (
            feedback_score * 0.4 +
            frequency_score * 0.3 +
            confidence_score * 0.3
        )

        return round(score, 3)

    def _determine_recommendation(
        self,
        score: float,
        metrics: EffectivenessMetrics,
    ) -> str:
        """æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ±ºå®š

        Args:
            score: æœ‰åŠ¹æ€§ã‚¹ã‚³ã‚¢
            metrics: ãƒ¡ãƒˆãƒªã‚¯ã‚¹

        Returns:
            æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³: 'keep', 'review', 'deactivate'
        """
        # é©ç”¨ã•ã‚Œã¦ã„ãªã„å­¦ç¿’ã¯'review'
        if metrics.apply_count == 0 and metrics.days_since_creation > 30:
            return "review"

        # ã‚¹ã‚³ã‚¢ãŒä½ã„å ´åˆã¯'deactivate'ã‚’æ¤œè¨
        if score < 0.3:
            return "deactivate"

        # ã‚¹ã‚³ã‚¢ãŒä¸­ç¨‹åº¦ã®å ´åˆã¯'review'
        if score < 0.5:
            return "review"

        # é«˜ã‚¹ã‚³ã‚¢ã¯'keep'
        return "keep"

    def _generate_suggestions(
        self,
        learning: Learning,
        metrics: EffectivenessMetrics,
    ) -> List[ImprovementSuggestion]:
        """æ”¹å–„ææ¡ˆã‚’ç”Ÿæˆ

        Args:
            learning: å­¦ç¿’
            metrics: ãƒ¡ãƒˆãƒªã‚¯ã‚¹

        Returns:
            æ”¹å–„ææ¡ˆã®ãƒªã‚¹ãƒˆ
        """
        suggestions = []

        learning_id = learning.id or ""

        # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯æ¯”ç‡ãŒä½ã„
        if metrics.feedback_ratio < 0.5 and metrics.negative_feedback_count >= 3:
            suggestions.append(ImprovementSuggestion(
                suggestion_type="review_content",
                description=f"ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãŒå¤šã„ã§ã™ï¼ˆ{metrics.negative_feedback_count}ä»¶ï¼‰ã€‚å†…å®¹ã‚’è¦‹ç›´ã™ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚",
                priority="high",
                learning_id=learning_id,
            ))

        # é•·æœŸé–“ä½¿ç”¨ã•ã‚Œã¦ã„ãªã„
        if metrics.days_since_last_apply and metrics.days_since_last_apply > 90:
            suggestions.append(ImprovementSuggestion(
                suggestion_type="check_relevance",
                description=f"{metrics.days_since_last_apply}æ—¥é–“é©ç”¨ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã¾ã å¿…è¦ãªå­¦ç¿’ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚",
                priority="medium",
                learning_id=learning_id,
            ))

        # ä¸€åº¦ã‚‚ä½¿ç”¨ã•ã‚Œã¦ã„ãªã„
        if metrics.apply_count == 0 and metrics.days_since_creation > 30:
            suggestions.append(ImprovementSuggestion(
                suggestion_type="unused",
                description="30æ—¥ä»¥ä¸ŠçµŒéã—ã¦ã„ã¾ã™ãŒä¸€åº¦ã‚‚é©ç”¨ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ãƒˆãƒªã‚¬ãƒ¼æ¡ä»¶ã‚’è¦‹ç›´ã™ã‹ã€å‰Šé™¤ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚",
                priority="medium",
                learning_id=learning_id,
            ))

        # ç¢ºä¿¡åº¦ãŒä½ä¸‹
        if metrics.confidence_score < 0.5:
            suggestions.append(ImprovementSuggestion(
                suggestion_type="refresh",
                description="æ™‚é–“çµŒéã«ã‚ˆã‚Šç¢ºä¿¡åº¦ãŒä½ä¸‹ã—ã¦ã„ã¾ã™ã€‚å†…å®¹ãŒç¾åœ¨ã‚‚æ­£ã—ã„ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚",
                priority="low",
                learning_id=learning_id,
            ))

        return suggestions

    # ========================================================================
    # å¥å…¨æ€§ãƒã‚§ãƒƒã‚¯
    # ========================================================================

    def check_health(
        self,
        learning: Learning,
    ) -> LearningHealth:
        """å­¦ç¿’ã®å¥å…¨æ€§ã‚’ãƒã‚§ãƒƒã‚¯

        Args:
            learning: å­¦ç¿’

        Returns:
            å¥å…¨æ€§çµæœ
        """
        metrics = self._calculate_metrics(learning)
        issues = []
        suggestions = []

        # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ¤å®š
        status = "healthy"

        # Criticalæ¡ä»¶
        if metrics.feedback_ratio < 0.3 and metrics.negative_feedback_count >= 5:
            status = "critical"
            issues.append("ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãŒéå¸¸ã«å¤šã„")
            suggestions.append("å†…å®¹ã‚’å¤§å¹…ã«è¦‹ç›´ã™ã‹ã€å‰Šé™¤ã‚’æ¤œè¨ã—ã¦ãã ã•ã„")

        # Warningæ¡ä»¶
        elif metrics.feedback_ratio < 0.5 and metrics.negative_feedback_count >= 3:
            status = "warning"
            issues.append("ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãŒå¤šã„")
            suggestions.append("å†…å®¹ã‚’è¦‹ç›´ã—ã¦ãã ã•ã„")

        # Staleæ¡ä»¶
        elif metrics.days_since_last_apply and metrics.days_since_last_apply > 180:
            status = "stale"
            issues.append("é•·æœŸé–“ä½¿ç”¨ã•ã‚Œã¦ã„ãªã„")
            suggestions.append("ã¾ã å¿…è¦ã‹ç¢ºèªã—ã¦ãã ã•ã„")

        # æœªä½¿ç”¨
        elif metrics.apply_count == 0 and metrics.days_since_creation > 60:
            status = "warning"
            issues.append("ä¸€åº¦ã‚‚ä½¿ç”¨ã•ã‚Œã¦ã„ãªã„")
            suggestions.append("ãƒˆãƒªã‚¬ãƒ¼æ¡ä»¶ã‚’è¦‹ç›´ã—ã¦ãã ã•ã„")

        return LearningHealth(
            learning_id=learning.id or "",  # Empty string fallback for health check display
            category=learning.category,
            status=status,
            metrics=metrics,
            issues=issues,
            suggestions=suggestions,
        )

    def check_health_batch(
        self,
        conn: Connection,
        learnings: Optional[List[Learning]] = None,
    ) -> Dict[str, List[LearningHealth]]:
        """è¤‡æ•°å­¦ç¿’ã®å¥å…¨æ€§ã‚’ä¸€æ‹¬ãƒã‚§ãƒƒã‚¯

        Args:
            conn: DBæ¥ç¶š
            learnings: å­¦ç¿’ã®ãƒªã‚¹ãƒˆ

        Returns:
            ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ¥ã®å¥å…¨æ€§çµæœ
        """
        if learnings is None:
            learnings, _ = self.repository.find_all(conn, active_only=True)

        result: Dict[str, List[LearningHealth]] = {
            "healthy": [],
            "warning": [],
            "critical": [],
            "stale": [],
        }

        for learning in learnings:
            health = self.check_health(learning)
            if health.status in result:
                result[health.status].append(health)

        return result

    # ========================================================================
    # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯è¨˜éŒ²
    # ========================================================================

    def record_feedback(
        self,
        conn: Connection,
        learning_id: str,
        impact: DecisionImpact,
        context: Optional[str] = None,
    ) -> bool:
        """ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’è¨˜éŒ²

        Args:
            conn: DBæ¥ç¶š
            learning_id: å­¦ç¿’ID
            impact: åˆ¤æ–­ã¸ã®å½±éŸ¿åº¦
            context: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±

        Returns:
            æˆåŠŸã—ãŸã‹ã©ã†ã‹
        """
        is_positive = impact == DecisionImpact.POSITIVE
        return self.repository.update_feedback_count(conn, learning_id, is_positive)

    def record_positive_feedback(
        self,
        conn: Connection,
        learning_id: str,
    ) -> bool:
        """ãƒã‚¸ãƒ†ã‚£ãƒ–ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’è¨˜éŒ²

        Args:
            conn: DBæ¥ç¶š
            learning_id: å­¦ç¿’ID

        Returns:
            æˆåŠŸã—ãŸã‹ã©ã†ã‹
        """
        return self.record_feedback(conn, learning_id, DecisionImpact.POSITIVE)

    def record_negative_feedback(
        self,
        conn: Connection,
        learning_id: str,
    ) -> bool:
        """ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’è¨˜éŒ²

        Args:
            conn: DBæ¥ç¶š
            learning_id: å­¦ç¿’ID

        Returns:
            æˆåŠŸã—ãŸã‹ã©ã†ã‹
        """
        return self.record_feedback(conn, learning_id, DecisionImpact.NEGATIVE)

    # ========================================================================
    # ã‚¹ã‚³ã‚¢æ›´æ–°
    # ========================================================================

    def update_effectiveness_scores(
        self,
        conn: Connection,
    ) -> int:
        """å…¨å­¦ç¿’ã®æœ‰åŠ¹æ€§ã‚¹ã‚³ã‚¢ã‚’æ›´æ–°

        Args:
            conn: DBæ¥ç¶š

        Returns:
            æ›´æ–°ã—ãŸä»¶æ•°
        """
        learnings, _ = self.repository.find_all(conn, active_only=True)
        updated = 0

        for learning in learnings:
            if not learning.id:
                continue
            result = self.calculate_effectiveness(learning)
            success = self.repository.update_effectiveness_score(
                conn, learning.id, result.effectiveness_score
            )
            if success:
                updated += 1

        return updated

    # ========================================================================
    # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    # ========================================================================

    def generate_summary_report(
        self,
        conn: Connection,
    ) -> Dict[str, Any]:
        """ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ

        Args:
            conn: DBæ¥ç¶š

        Returns:
            ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆ
        """
        health_by_status = self.check_health_batch(conn)

        # çµ±è¨ˆ
        total = sum(len(v) for v in health_by_status.values())
        healthy = len(health_by_status["healthy"])
        warning = len(health_by_status["warning"])
        critical = len(health_by_status["critical"])
        stale = len(health_by_status["stale"])

        # å…¨ä½“ã®ã‚¹ã‚³ã‚¢
        learnings, _ = self.repository.find_all(conn, active_only=True)
        if learnings:
            scores = [
                self.calculate_effectiveness(l).effectiveness_score
                for l in learnings
            ]
            avg_score = sum(scores) / len(scores)
        else:
            avg_score = 0.0

        return {
            "total_learnings": total,
            "by_status": {
                "healthy": healthy,
                "warning": warning,
                "critical": critical,
                "stale": stale,
            },
            "health_ratio": round(healthy / total, 2) if total > 0 else 0,
            "average_effectiveness_score": round(avg_score, 3),
            "critical_learnings": [
                {
                    "id": h.learning_id,
                    "category": h.category,
                    "issues": h.issues,
                }
                for h in health_by_status["critical"]
            ],
            "improvement_suggestions_count": sum(
                len(h.suggestions)
                for status_list in health_by_status.values()
                for h in status_list
            ),
        }

    def format_summary_report(
        self,
        report: Dict[str, Any],
    ) -> str:
        """ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ

        Args:
            report: generate_summary_report()ã®çµæœ

        Returns:
            ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã•ã‚ŒãŸãƒ¬ãƒãƒ¼ãƒˆ
        """
        lines = ["ğŸ“Š å­¦ç¿’ã®æœ‰åŠ¹æ€§ãƒ¬ãƒãƒ¼ãƒˆã ã‚¦ãƒ«ğŸº\n"]

        lines.append(f"ğŸ“š å…¨å­¦ç¿’æ•°: {report['total_learnings']}ä»¶")
        lines.append(f"ğŸ’š å¥å…¨: {report['by_status']['healthy']}ä»¶")
        lines.append(f"ğŸ’› æ³¨æ„: {report['by_status']['warning']}ä»¶")
        lines.append(f"â¤ï¸ è¦å¯¾å¿œ: {report['by_status']['critical']}ä»¶")
        lines.append(f"ğŸ”˜ æœªä½¿ç”¨: {report['by_status']['stale']}ä»¶")
        lines.append(f"\nğŸ“ˆ å¹³å‡æœ‰åŠ¹æ€§ã‚¹ã‚³ã‚¢: {report['average_effectiveness_score']:.1%}")
        lines.append(f"ğŸ¥ å¥å…¨ç‡: {report['health_ratio']:.0%}")

        if report['critical_learnings']:
            lines.append("\nâš ï¸ è¦å¯¾å¿œã®å­¦ç¿’:")
            for item in report['critical_learnings'][:5]:
                issues = ", ".join(item['issues'])
                lines.append(f"  â€¢ [{item['category']}] {issues}")

        if report['improvement_suggestions_count'] > 0:
            lines.append(
                f"\nğŸ’¡ æ”¹å–„ææ¡ˆ: {report['improvement_suggestions_count']}ä»¶"
            )

        return "\n".join(lines)


# ============================================================================
# ãƒ•ã‚¡ã‚¯ãƒˆãƒªé–¢æ•°
# ============================================================================

def create_effectiveness_tracker(
    organization_id: str,
    repository: Optional[LearningRepository] = None,
    confidence_decay_rate: float = DEFAULT_CONFIDENCE_DECAY_RATE,
) -> EffectivenessTracker:
    """æœ‰åŠ¹æ€§è¿½è·¡å™¨ã‚’ä½œæˆ

    Args:
        organization_id: çµ„ç¹”ID
        repository: ãƒªãƒã‚¸ãƒˆãƒª
        confidence_decay_rate: ç¢ºä¿¡åº¦æ¸›è¡°ç‡

    Returns:
        EffectivenessTracker ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
    """
    return EffectivenessTracker(
        organization_id, repository, confidence_decay_rate
    )
