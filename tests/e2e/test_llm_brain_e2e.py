"""
LLM Brain E2Eãƒ†ã‚¹ãƒˆ

è¨­è¨ˆæ›¸: docs/25_llm_native_brain_architecture.md

ã€ç›®çš„ã€‘
å®Ÿéš›ã®OpenRouter/Anthropic APIã‚’ä½¿ç”¨ã—ã¦ã€LLM BrainãŒæ­£ã—ãå‹•ä½œã™ã‚‹ã“ã¨ã‚’ç¢ºèªã™ã‚‹ã€‚

ã€å‰ææ¡ä»¶ã€‘
æœ¬ç•ªç’°å¢ƒ:
  1. GCP Secret Manager ã« "openrouter-api-key" ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ã“ã¨

ãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™º:
  1. ç’°å¢ƒå¤‰æ•° OPENROUTER_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ã“ã¨
  ã¾ãŸã¯
  2. ç’°å¢ƒå¤‰æ•° ANTHROPIC_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ã“ã¨

ã€APIå–å¾—å„ªå…ˆé †ä½ã€‘
1. ç’°å¢ƒå¤‰æ•° OPENROUTER_API_KEY
2. GCP Secret Manager (openrouter-api-key)
3. ç’°å¢ƒå¤‰æ•° ANTHROPIC_API_KEY (ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯)

ã€ãƒ†ã‚¹ãƒˆå†…å®¹ã€‘
1. LLM Brainã®åˆæœŸåŒ–
2. ã€Œã‚¿ã‚¹ã‚¯è¿½åŠ ã—ã¦ã€ã§Toolå‘¼ã³å‡ºã—ãŒæ­£ã—ãè¡Œã‚ã‚Œã‚‹ã‹
3. ç¢ºèªãƒ•ãƒ­ãƒ¼ãŒæ­£ã—ãå‹•ä½œã™ã‚‹ã‹
4. Guardian LayerãŒæ­£ã—ãæ©Ÿèƒ½ã™ã‚‹ã‹

Author: Claude Opus 4.5
Created: 2026-01-30
Updated: 2026-01-30 - OpenRouterå¯¾å¿œã€lib/secretsçµ±åˆ
"""

import asyncio
import os
import sys
import logging
from datetime import datetime
from typing import Optional, Tuple

import pytest

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(name)s: %(message)s",
)
logger = logging.getLogger(__name__)

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.dirname(__file__))))


def get_api_key_info() -> Tuple[Optional[str], str]:
    """
    APIã‚­ãƒ¼ã®å–å¾—çŠ¶æ³ã‚’ç¢ºèªã™ã‚‹

    Returns:
        Tuple[Optional[str], str]: (å–å¾—ã—ãŸã‚­ãƒ¼ã®ç¨®é¡, è©³ç´°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸)
        ç¨®é¡: "openrouter_env", "openrouter_secret", "anthropic_env", None
    """
    # 1. ç’°å¢ƒå¤‰æ•° OPENROUTER_API_KEY
    openrouter_env = os.getenv("OPENROUTER_API_KEY")
    if openrouter_env:
        return ("openrouter_env", f"ç’°å¢ƒå¤‰æ•° OPENROUTER_API_KEY (length={len(openrouter_env)})")

    # 2. GCP Secret Manager
    try:
        from lib.secrets import get_secret_cached
        openrouter_secret = get_secret_cached("openrouter-api-key")
        if openrouter_secret:
            return ("openrouter_secret", f"GCP Secret Manager (length={len(openrouter_secret)})")
    except Exception as e:
        logger.debug(f"Secret Managerå–å¾—å¤±æ•—: {e}")

    # 3. ç’°å¢ƒå¤‰æ•° ANTHROPIC_API_KEY (ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯)
    anthropic_env = os.getenv("ANTHROPIC_API_KEY")
    if anthropic_env:
        return ("anthropic_env", f"ç’°å¢ƒå¤‰æ•° ANTHROPIC_API_KEY (length={len(anthropic_env)})")

    return (None, "APIã‚­ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")


def check_prerequisites() -> bool:
    """å‰ææ¡ä»¶ã‚’ãƒã‚§ãƒƒã‚¯"""
    print("=" * 60)
    print("ğŸ§ª LLM Brain E2Eãƒ†ã‚¹ãƒˆ - å‰ææ¡ä»¶ãƒã‚§ãƒƒã‚¯")
    print("=" * 60)

    errors = []

    # APIã‚­ãƒ¼å–å¾—çŠ¶æ³ã‚’ç¢ºèª
    key_type, key_info = get_api_key_info()

    if key_type == "openrouter_env":
        print(f"âœ… APIã‚­ãƒ¼: {key_info}")
        print("   â†’ OpenRouterçµŒç”±ã§Claude Opus 4.5ã‚’ä½¿ç”¨")
    elif key_type == "openrouter_secret":
        print(f"âœ… APIã‚­ãƒ¼: {key_info}")
        print("   â†’ OpenRouterçµŒç”±ã§Claude Opus 4.5ã‚’ä½¿ç”¨")
    elif key_type == "anthropic_env":
        print(f"âš ï¸  OpenRouterã‚­ãƒ¼ãªã—ã€‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯:")
        print(f"âœ… APIã‚­ãƒ¼: {key_info}")
        print("   â†’ Anthropicç›´æ¥APIã‚’ä½¿ç”¨")
    else:
        print("âŒ APIã‚­ãƒ¼: æœªè¨­å®š")
        errors.append("API_KEY")

    # ENABLE_LLM_BRAIN (æƒ…å ±ã¨ã—ã¦è¡¨ç¤ºã€å¿…é ˆã§ã¯ãªã„)
    llm_brain_flag = os.getenv("ENABLE_LLM_BRAIN", "false").lower()
    if llm_brain_flag == "true":
        print("âœ… ENABLE_LLM_BRAIN: true")
    else:
        print(f"âš ï¸  ENABLE_LLM_BRAIN: {llm_brain_flag} (ãƒ†ã‚¹ãƒˆæ™‚ã«å¼·åˆ¶æœ‰åŠ¹åŒ–)")

    print("=" * 60)

    if errors:
        print(f"\nâŒ APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„:")
        print(f"\n   ã€æ¨å¥¨ã€‘OpenRouter:")
        print(f"   export OPENROUTER_API_KEY=<your-openrouter-key>")
        print(f"\n   ã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã€‘Anthropicç›´æ¥:")
        print(f"   export ANTHROPIC_API_KEY=<your-anthropic-key>")
        print(f"\n   ã€æœ¬ç•ªç’°å¢ƒã€‘GCP Secret Manager:")
        print(f"   ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆå: openrouter-api-key")
        return False

    return True


async def test_llm_brain_initialization():
    """LLM Brainã®åˆæœŸåŒ–ãƒ†ã‚¹ãƒˆï¼ˆãƒ•ã‚¡ã‚¯ãƒˆãƒªé–¢æ•°ä½¿ç”¨ï¼‰"""
    print("\n" + "=" * 60)
    print("ğŸ“‹ ãƒ†ã‚¹ãƒˆ1: LLM BrainåˆæœŸåŒ–")
    print("=" * 60)

    try:
        from lib.brain.llm_brain import create_llm_brain_auto, APIProvider

        # è‡ªå‹•æ¤œå‡ºã§Brainã‚’ä½œæˆ
        brain = create_llm_brain_auto()

        api_name = "OpenRouter" if brain.api_provider == APIProvider.OPENROUTER else "Anthropicç›´æ¥"

        print(f"âœ… LLMBrainåˆæœŸåŒ–æˆåŠŸ")
        print(f"   ãƒ¢ãƒ‡ãƒ«: {brain.model}")
        print(f"   max_tokens: {brain.max_tokens}")
        print(f"   API: {api_name}")
        print(f"   ç¢ºä¿¡åº¦é–¾å€¤ï¼ˆè‡ªå‹•å®Ÿè¡Œï¼‰: {brain.CONFIDENCE_THRESHOLD_AUTO_EXECUTE}")
        print(f"   ç¢ºä¿¡åº¦é–¾å€¤ï¼ˆç¢ºèªå¿…è¦ï¼‰: {brain.CONFIDENCE_THRESHOLD_CONFIRM}")

        return brain
    except Exception as e:
        print(f"âŒ LLMBrainåˆæœŸåŒ–å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return None


async def test_context_builder():
    """Context Builderã®ãƒ†ã‚¹ãƒˆ"""
    print("\n" + "=" * 60)
    print("ğŸ“‹ ãƒ†ã‚¹ãƒˆ2: Context Builder")
    print("=" * 60)

    try:
        from lib.brain.context_builder import LLMContext, Message, UserPreferences

        # ãƒ†ã‚¹ãƒˆç”¨ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½œæˆ
        context = LLMContext(
            user_id="test_user_123",
            user_name="ãƒ†ã‚¹ãƒˆãƒ¦ãƒ¼ã‚¶ãƒ¼",
            room_id="test_room_456",
            organization_id="org_test",
            recent_messages=[
                Message(role="user", content="ãŠã¯ã‚ˆã†ã”ã–ã„ã¾ã™"),
                Message(role="assistant", content="ãŠã¯ã‚ˆã†ã”ã–ã„ã¾ã™ã‚¦ãƒ«ï¼"),
            ],
            user_preferences=UserPreferences(
                preferred_name="ãƒ†ã‚¹ãƒˆã•ã‚“",
            ),
        )

        prompt_string = context.to_prompt_string()
        print(f"âœ… LLMContextä½œæˆæˆåŠŸ")
        print(f"   ãƒ¦ãƒ¼ã‚¶ãƒ¼: {context.user_name}")
        print(f"   ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°: {len(context.recent_messages)}")
        print(f"\nğŸ“ Promptæ–‡å­—åˆ—ï¼ˆæŠœç²‹ï¼‰:")
        print(prompt_string[:500] + "..." if len(prompt_string) > 500 else prompt_string)

        return context
    except Exception as e:
        print(f"âŒ Context Builderå¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return None


async def test_tool_converter():
    """Tool Converterã®ãƒ†ã‚¹ãƒˆ"""
    print("\n" + "=" * 60)
    print("ğŸ“‹ ãƒ†ã‚¹ãƒˆ3: Tool Converter")
    print("=" * 60)

    try:
        from lib.brain.tool_converter import get_tools_for_llm

        tools = get_tools_for_llm()
        print(f"âœ… Toolå¤‰æ›æˆåŠŸ: {len(tools)}å€‹ã®Toolã‚’ç”Ÿæˆ")

        # ä¸»è¦ãªToolã‚’è¡¨ç¤º
        important_tools = [
            "chatwork_task_create",
            "chatwork_task_list",
            "knowledge_search",
            "goal_add",
        ]

        print("\nğŸ“ ä¸»è¦ãªTool:")
        for tool in tools:
            if tool["name"] in important_tools:
                desc = tool.get('description', '')[:50]
                print(f"   - {tool['name']}: {desc}...")

        return tools
    except Exception as e:
        print(f"âŒ Tool Converterå¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return None


@pytest.mark.skip(reason="E2Eãƒ†ã‚¹ãƒˆ: main()ã‹ã‚‰å‘¼ã³å‡ºã™ï¼ˆpytestã‹ã‚‰ç›´æ¥å®Ÿè¡Œä¸å¯ï¼‰")
async def test_llm_brain_process(brain, context, tools):
    """LLM Brainã®å‡¦ç†ãƒ†ã‚¹ãƒˆï¼ˆå®Ÿéš›ã®APIå‘¼ã³å‡ºã—ï¼‰"""
    print("\n" + "=" * 60)
    print("ğŸ“‹ ãƒ†ã‚¹ãƒˆ4: LLM Brainå‡¦ç†ï¼ˆAPIå‘¼ã³å‡ºã—ï¼‰")
    print("=" * 60)

    test_messages = [
        "ã‚¿ã‚¹ã‚¯è¿½åŠ ã—ã¦",
        "è‡ªåˆ†ã®ã‚¿ã‚¹ã‚¯æ•™ãˆã¦",
        "ãŠã¯ã‚ˆã†ã”ã–ã„ã¾ã™",
    ]

    results = []

    for message in test_messages:
        print(f"\nğŸ”¹ ãƒ†ã‚¹ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: ã€Œ{message}ã€")
        print("-" * 40)

        try:
            result = await brain.process(
                context=context,
                message=message,
                tools=tools,
            )

            print(f"âœ… å‡¦ç†æˆåŠŸ")
            print(f"   å‡ºåŠ›ã‚¿ã‚¤ãƒ—: {result.output_type}")
            print(f"   ç¢ºä¿¡åº¦: {result.confidence.overall:.2f}")
            print(f"   å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³: {result.input_tokens}")
            print(f"   å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³: {result.output_tokens}")

            if result.tool_calls:
                print(f"   Toolå‘¼ã³å‡ºã—:")
                for tc in result.tool_calls:
                    print(f"      - {tc.tool_name}: {tc.parameters}")

            if result.text_response:
                response_preview = result.text_response[:100] + "..." if len(result.text_response) > 100 else result.text_response
                print(f"   å¿œç­”: {response_preview}")

            if result.reasoning:
                reasoning_preview = result.reasoning[:150] + "..." if len(result.reasoning) > 150 else result.reasoning
                print(f"   æ€è€ƒéç¨‹: {reasoning_preview}")

            results.append((message, result, None))

        except Exception as e:
            print(f"âŒ å‡¦ç†å¤±æ•—: {e}")
            import traceback
            traceback.print_exc()
            results.append((message, None, str(e)))

    return results


async def test_guardian_layer():
    """Guardian Layerã®ãƒ†ã‚¹ãƒˆ"""
    print("\n" + "=" * 60)
    print("ğŸ“‹ ãƒ†ã‚¹ãƒˆ5: Guardian Layer")
    print("=" * 60)

    try:
        from lib.brain.guardian_layer import GuardianLayer, GuardianAction
        from lib.brain.llm_brain import LLMBrainResult, ToolCall, ConfidenceScores
        from lib.brain.context_builder import LLMContext

        guardian = GuardianLayer(ceo_teachings=[])

        # ãƒ†ã‚¹ãƒˆç”¨ã®LLMBrainResultï¼ˆreasoningã¯å¿…é ˆï¼‰
        test_result = LLMBrainResult(
            output_type="tool_call",
            tool_calls=[
                ToolCall(
                    tool_name="chatwork_task_create",
                    parameters={"body": "ãƒ†ã‚¹ãƒˆã‚¿ã‚¹ã‚¯"},
                )
            ],
            confidence=ConfidenceScores(overall=0.8),
            reasoning="ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã‚¿ã‚¹ã‚¯è¿½åŠ ã‚’ä¾é ¼ã—ãŸã®ã§chatwork_task_createã‚’ä½¿ç”¨ã™ã‚‹ã‚¦ãƒ«",
        )

        test_context = LLMContext(
            user_id="test_user",
            user_name="ãƒ†ã‚¹ã‚¿ãƒ¼",
            room_id="test_room",
            organization_id="org_test",
        )

        guardian_result = await guardian.check(test_result, test_context)

        print(f"âœ… Guardian Layerå‹•ä½œç¢ºèª")
        print(f"   ã‚¢ã‚¯ã‚·ãƒ§ãƒ³: {guardian_result.action.value}")
        print(f"   ç†ç”±: {guardian_result.reason}")

        if guardian_result.action == GuardianAction.ALLOW:
            print(f"   â†’ Toolå®Ÿè¡Œã‚’è¨±å¯")
        elif guardian_result.action == GuardianAction.CONFIRM:
            print(f"   â†’ ç¢ºèªãŒå¿…è¦")
        elif guardian_result.action == GuardianAction.BLOCK:
            print(f"   â†’ å®Ÿè¡Œã‚’ãƒ–ãƒ­ãƒƒã‚¯")

        return guardian_result

    except Exception as e:
        print(f"âŒ Guardian Layerå¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return None


def print_summary(results: list):
    """ãƒ†ã‚¹ãƒˆçµæœã®ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º"""
    print("\n" + "=" * 60)
    print("ğŸ“Š ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼")
    print("=" * 60)

    if not results:
        print("âš ï¸  ãƒ†ã‚¹ãƒˆçµæœãŒã‚ã‚Šã¾ã›ã‚“")
        return

    success_count = sum(1 for _, result, error in results if result is not None)
    total_count = len(results)

    print(f"\næˆåŠŸ: {success_count}/{total_count}")

    for message, result, error in results:
        if result is not None:
            status = "âœ…"
            detail = f"type={result.output_type}, confidence={result.confidence.overall:.2f}"
            if result.tool_calls:
                detail += f", tools={[tc.tool_name for tc in result.tool_calls]}"
        else:
            status = "âŒ"
            detail = f"error={error}"

        print(f"  {status} ã€Œ{message}ã€: {detail}")


async def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("\nğŸº ã‚½ã‚¦ãƒ«ãã‚“ LLM Brain E2Eãƒ†ã‚¹ãƒˆ ğŸº")
    print("=" * 60)

    # å‰ææ¡ä»¶ãƒã‚§ãƒƒã‚¯
    if not check_prerequisites():
        print("\nâŒ å‰ææ¡ä»¶ã‚’æº€ãŸã—ã¦ã„ã¾ã›ã‚“ã€‚ãƒ†ã‚¹ãƒˆã‚’ä¸­æ­¢ã—ã¾ã™ã€‚")
        sys.exit(1)

    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    try:
        # 1. LLM BrainåˆæœŸåŒ–
        brain = await test_llm_brain_initialization()
        if not brain:
            print("\nâŒ LLM BrainåˆæœŸåŒ–ã«å¤±æ•—ã—ãŸãŸã‚ã€ãƒ†ã‚¹ãƒˆã‚’ä¸­æ­¢ã—ã¾ã™ã€‚")
            sys.exit(1)

        # 2. Context Builder
        context = await test_context_builder()
        if not context:
            print("\nâŒ Context Builderã«å¤±æ•—ã—ãŸãŸã‚ã€ãƒ†ã‚¹ãƒˆã‚’ä¸­æ­¢ã—ã¾ã™ã€‚")
            sys.exit(1)

        # 3. Tool Converter
        tools = await test_tool_converter()
        if not tools:
            print("\nâŒ Tool Converterã«å¤±æ•—ã—ãŸãŸã‚ã€ãƒ†ã‚¹ãƒˆã‚’ä¸­æ­¢ã—ã¾ã™ã€‚")
            sys.exit(1)

        # 4. LLM Brainå‡¦ç†ï¼ˆå®Ÿéš›ã®APIå‘¼ã³å‡ºã—ï¼‰
        results = await test_llm_brain_process(brain, context, tools)

        # 5. Guardian Layer
        await test_guardian_layer()

        # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
        print_summary(results)

        print("\n" + "=" * 60)
        print("ğŸ‰ E2Eãƒ†ã‚¹ãƒˆå®Œäº†ï¼")
        print("=" * 60)

    except KeyboardInterrupt:
        print("\n\nâš ï¸  ãƒ†ã‚¹ãƒˆãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())
