# lib/brain/graph/nodes/responses.py
"""
ãƒãƒ¼ãƒ‰: ãƒ¬ã‚¹ãƒãƒ³ã‚¹ç”Ÿæˆ

å„åˆ†å²ã®æœ€çµ‚ã‚¹ãƒ†ãƒƒãƒ—ã§ BrainResponse ã‚’æ§‹ç¯‰ã™ã‚‹ã€‚
- handle_block: GuardianãŒãƒ–ãƒ­ãƒƒã‚¯ã—ãŸå ´åˆ
- handle_confirm: GuardianãŒç¢ºèªã‚’æ±‚ã‚ãŸå ´åˆ
- text_response: Toolå‘¼ã³å‡ºã—ãªã—ï¼ˆãƒ†ã‚­ã‚¹ãƒˆå¿œç­”ã®ã¿ï¼‰
- build_response: Toolå®Ÿè¡Œå¾Œã®æœ€çµ‚å¿œç­”
"""

import logging
from typing import TYPE_CHECKING

if TYPE_CHECKING:
    from lib.brain.core import SoulkunBrain

from lib.brain.graph.state import BrainGraphState
from lib.brain.models import BrainResponse

logger = logging.getLogger(__name__)


def make_handle_block(brain: "SoulkunBrain"):
    """Guardianãƒ–ãƒ­ãƒƒã‚¯æ™‚ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ç”Ÿæˆ"""

    async def handle_block(state: BrainGraphState) -> dict:
        from lib.brain.core import _safe_confidence_to_dict

        guardian_result = state["guardian_result"]
        llm_result = state["llm_result"]
        start_time = state["start_time"]

        block_message = (
            guardian_result.blocked_reason
            or guardian_result.reason
            or "ãã®æ“ä½œã¯å®Ÿè¡Œã§ãã¾ã›ã‚“ã‚¦ãƒ«ğŸº"
        )

        response = BrainResponse(
            message=block_message,
            action_taken="guardian_block",
            success=False,
            debug_info={
                "llm_brain": {
                    "tool_calls": [tc.to_dict() for tc in llm_result.tool_calls] if llm_result.tool_calls else [],
                    "confidence": _safe_confidence_to_dict(
                        llm_result.confidence, "graph:handle_block"
                    ),
                    "reasoning": llm_result.reasoning[:200] if llm_result.reasoning else None,
                },
                "guardian": {
                    "action": guardian_result.action.value,
                    "reason": guardian_result.reason,
                },
            },
            total_time_ms=brain._elapsed_ms(start_time),
        )
        return {"response": response}

    return handle_block


def make_handle_confirm(brain: "SoulkunBrain"):
    """Guardianç¢ºèªè¦æ±‚æ™‚ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ç”Ÿæˆ"""

    async def handle_confirm(state: BrainGraphState) -> dict:
        import uuid as uuid_mod
        from lib.brain.core import _extract_confidence_value, _safe_confidence_to_dict
        from lib.brain.state_manager import LLMPendingAction

        guardian_result = state["guardian_result"]
        llm_result = state["llm_result"]
        start_time = state["start_time"]

        tool_call = llm_result.tool_calls[0] if llm_result.tool_calls else None
        confirm_question = (
            guardian_result.confirmation_question
            or guardian_result.reason
            or "ç¢ºèªã•ã›ã¦ã»ã—ã„ã‚¦ãƒ«ğŸº"
        )

        confirm_confidence = _extract_confidence_value(
            llm_result.confidence, "graph:handle_confirm:confidence"
        )

        pending_action = LLMPendingAction(
            action_id=str(uuid_mod.uuid4()),
            tool_name=tool_call.tool_name if tool_call else "",
            parameters=tool_call.parameters if tool_call else {},
            confirmation_question=confirm_question,
            confirmation_type=guardian_result.risk_level or "ambiguous",
            original_message=state["message"],
            original_reasoning=llm_result.reasoning or "",
            confidence=confirm_confidence,
        )
        await brain.llm_state_manager.set_pending_action(
            user_id=state["account_id"],
            room_id=state["room_id"],
            pending_action=pending_action,
        )

        response = BrainResponse(
            message=confirm_question,
            action_taken="request_confirmation",
            success=True,
            awaiting_confirmation=True,
            state_changed=True,
            new_state="llm_confirmation_pending",
            debug_info={
                "llm_brain": {
                    "tool_calls": [tc.to_dict() for tc in llm_result.tool_calls] if llm_result.tool_calls else [],
                    "confidence": _safe_confidence_to_dict(
                        llm_result.confidence, "graph:handle_confirm"
                    ),
                },
                "guardian": {
                    "action": guardian_result.action.value,
                    "reason": guardian_result.reason,
                },
            },
            total_time_ms=brain._elapsed_ms(start_time),
        )
        return {"response": response}

    return handle_confirm


def make_text_response(brain: "SoulkunBrain"):
    """ãƒ†ã‚­ã‚¹ãƒˆå¿œç­”ã®ã¿ï¼ˆToolå‘¼ã³å‡ºã—ãªã—ï¼‰ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ç”Ÿæˆ"""

    async def text_response(state: BrainGraphState) -> dict:
        from lib.brain.core import _safe_confidence_to_dict

        llm_result = state["llm_result"]
        start_time = state["start_time"]

        response = BrainResponse(
            message=llm_result.text_response or "ãŠæ‰‹ä¼ã„ã§ãã‚‹ã“ã¨ã¯ã‚ã‚Šã¾ã™ã‹ã‚¦ãƒ«ï¼ŸğŸº",
            action_taken="llm_text_response",
            success=True,
            debug_info={
                "llm_brain": {
                    "confidence": _safe_confidence_to_dict(
                        llm_result.confidence, "graph:text_response"
                    ),
                    "reasoning": llm_result.reasoning[:200] if llm_result.reasoning else None,
                },
            },
            total_time_ms=brain._elapsed_ms(start_time),
        )
        return {"response": response}

    return text_response


def make_build_response(brain: "SoulkunBrain"):
    """Toolå®Ÿè¡Œå¾Œã®æœ€çµ‚ãƒ¬ã‚¹ãƒãƒ³ã‚¹ç”Ÿæˆ + è¨˜æ†¶æ›´æ–°"""

    async def build_response(state: BrainGraphState) -> dict:
        from lib.brain.core import _safe_confidence_to_dict

        llm_result = state["llm_result"]
        guardian_result = state["guardian_result"]
        tool_calls = state["tool_calls_to_execute"]
        result = state["execution_result"]
        start_time = state["start_time"]
        tool_call = tool_calls[0]

        # è¨˜æ†¶æ›´æ–°ï¼ˆéåŒæœŸï¼‰
        brain._fire_and_forget(
            brain.memory_manager.update_memory_safely(
                state["message"],
                result,
                state["context"],
                state["room_id"],
                state["account_id"],
                state["sender_name"],
            )
        )

        response = BrainResponse(
            message=result.message,
            action_taken=tool_call.tool_name,
            action_params=tool_call.parameters,
            success=result.success,
            suggestions=result.suggestions,
            debug_info={
                "llm_brain": {
                    "tool_calls": [tc.to_dict() for tc in tool_calls],
                    "confidence": _safe_confidence_to_dict(
                        llm_result.confidence, "graph:build_response"
                    ),
                    "reasoning": llm_result.reasoning[:200] if llm_result.reasoning else None,
                },
                "guardian": {
                    "action": guardian_result.action.value,
                },
            },
            total_time_ms=brain._elapsed_ms(start_time),
        )
        return {"response": response}

    return build_response
