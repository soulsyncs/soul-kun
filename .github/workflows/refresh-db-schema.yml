name: ğŸ—ºï¸ DB Schema è‡ªå‹•æ›´æ–°ï¼ˆæ¯æœ6æ™‚ï¼‰

# æ¯æœ6æ™‚ï¼ˆJSTï¼‰ã«æœ¬ç•ªDBã®ã‚¹ã‚­ãƒ¼ãƒã‚’å–å¾—ã—ã¦db_schema.jsonã‚’æ›´æ–°
# å¤‰æ›´ãŒã‚ã‚Œã°PRã‚’è‡ªå‹•ä½œæˆã™ã‚‹

on:
  schedule:
    - cron: '0 21 * * *'  # UTC 21:00 = JST 06:00
  workflow_dispatch:        # æ‰‹å‹•å®Ÿè¡Œã‚‚å¯èƒ½

jobs:
  refresh-schema:
    runs-on: ubuntu-latest
    permissions:
      contents: write
      pull-requests: write

    steps:
      - name: ãƒã‚§ãƒƒã‚¯ã‚¢ã‚¦ãƒˆ
        uses: actions/checkout@v4

      - name: Python ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: psql ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
        run: sudo apt-get install -y postgresql-client

      - name: GCPèªè¨¼
        uses: google-github-actions/auth@v2
        with:
          credentials_json: '${{ secrets.GCP_CREDENTIALS_JSON }}'

      - name: Cloud SQL Proxy ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
        run: |
          curl -o cloud-sql-proxy \
            https://storage.googleapis.com/cloud-sql-connectors/cloud-sql-proxy/v2.14.1/cloud-sql-proxy.linux.amd64
          chmod +x cloud-sql-proxy
          sudo mv cloud-sql-proxy /usr/local/bin/

      - name: Cloud SQL Proxy èµ·å‹•
        run: |
          cloud-sql-proxy \
            "soulkun-production:asia-northeast1:soulkun-db" \
            --port=15432 &
          sleep 5
          nc -z 127.0.0.1 15432 && echo "âœ… Proxy ready" || (echo "âŒ Proxy failed" && exit 1)

      - name: db_schema.json æ›´æ–°
        env:
          DB_USER: soulkun_user
          PROXY_PORT: '15432'
          DB_PASS: ${{ secrets.DB_PASSWORD }}
        run: |
          python3 -c "
          import subprocess, json, sys, os, datetime

          PROXY_PORT = os.environ['PROXY_PORT']
          DB_USER = os.environ['DB_USER']
          DB_PASS = os.environ['DB_PASS']

          def get_columns(db):
              sql = '''
                  SELECT table_name, column_name, data_type, is_nullable
                  FROM information_schema.columns
                  WHERE table_schema = 'public'
                  ORDER BY table_name, ordinal_position
              '''
              cmd = ['psql', '-h', '127.0.0.1', '-p', PROXY_PORT, '-U', DB_USER, '-d', db,
                     '-t', '-A', '-F', '|', '-c', sql]
              env = dict(os.environ)
              env['PGPASSWORD'] = DB_PASS
              result = subprocess.run(cmd, capture_output=True, text=True, env=env)
              if result.returncode != 0:
                  print(f'Warning: {db}: {result.stderr[:100]}', file=sys.stderr)
                  return {}
              tables = {}
              for line in result.stdout.strip().split('\n'):
                  if not line or '|' not in line:
                      continue
                  parts = line.split('|')
                  if len(parts) < 4:
                      continue
                  table, col, dtype, nullable = parts[0], parts[1], parts[2], parts[3]
                  key = f'{db}.{table}'
                  if key not in tables:
                      tables[key] = {}
                  tables[key][col] = {'type': dtype, 'nullable': nullable == 'YES'}
              return tables

          schema = {}
          for db in ['soulkun', 'soulkun_tasks']:
              schema.update(get_columns(db))

          simple = {}
          for full_key, cols in schema.items():
              table = full_key.split('.', 1)[1]
              if table not in simple:
                  simple[table] = {}
              simple[table].update({c: v['type'] for c, v in cols.items()})

          output = {
              'generated_at': datetime.datetime.now().isoformat(),
              'databases': schema,
              'tables': simple,
          }
          with open('db_schema.json', 'w') as f:
              json.dump(output, f, indent=2, ensure_ascii=False)
          table_count = len(simple)
          print(f'âœ… {table_count} ãƒ†ãƒ¼ãƒ–ãƒ«ã®ã‚¹ã‚­ãƒ¼ãƒã‚’æ›´æ–°ã—ã¾ã—ãŸ')
          "

      - name: å·®åˆ†ç¢ºèª
        id: diff
        run: |
          if git diff --quiet db_schema.json; then
            echo "changed=false" >> $GITHUB_OUTPUT
            echo "âœ… ã‚¹ã‚­ãƒ¼ãƒã«å¤‰æ›´ãªã—"
          else
            echo "changed=true" >> $GITHUB_OUTPUT
            TABLES=$(python3 -c "import json; d=json.load(open('db_schema.json')); print(len(d['tables']))")
            echo "ğŸ“‹ ãƒ†ãƒ¼ãƒ–ãƒ«æ•°: $TABLES"
            git diff --stat db_schema.json
          fi

      - name: PRè‡ªå‹•ä½œæˆï¼ˆã‚¹ã‚­ãƒ¼ãƒå¤‰æ›´ãŒã‚ã£ãŸå ´åˆï¼‰
        if: steps.diff.outputs.changed == 'true'
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          BRANCH="auto/refresh-db-schema-$(date +%Y%m%d)"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git config user.name "github-actions[bot]"
          git checkout -b "$BRANCH"
          git add db_schema.json
          git commit -m "chore(schema): æœ¬ç•ªDBã‚¹ã‚­ãƒ¼ãƒã‚’è‡ªå‹•æ›´æ–° $(date +%Y-%m-%d)

          æ¯æœ6æ™‚ã®è‡ªå‹•å®Ÿè¡Œã«ã‚ˆã‚Š db_schema.json ã‚’æœ€æ–°åŒ–ã€‚
          3AIãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆbrain-reviewerï¼‰ãŒæ­£ç¢ºãªã‚¹ã‚­ãƒ¼ãƒæƒ…å ±ã‚’å‚ç…§ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹ã€‚

          Co-Authored-By: github-actions[bot] <github-actions[bot]@users.noreply.github.com>"
          git push origin "$BRANCH"
          gh pr create \
            --title "chore: db_schema.json è‡ªå‹•æ›´æ–° $(date +%Y-%m-%d)" \
            --body "## ğŸ“‹ DB ã‚¹ã‚­ãƒ¼ãƒè‡ªå‹•æ›´æ–°

          æ¯æœ6æ™‚ã®è‡ªå‹•ã‚¸ãƒ§ãƒ–ã«ã‚ˆã‚Šæœ¬ç•ªDBã®æœ€æ–°ã‚¹ã‚­ãƒ¼ãƒã‚’å–å¾—ã—ã¾ã—ãŸã€‚

          ### å¤‰æ›´å†…å®¹
          - db_schema.json ã‚’æœ¬ç•ªDBï¼ˆsoulkun + soulkun_tasksï¼‰ã‹ã‚‰å†ç”Ÿæˆ

          ### ãªãœé‡è¦ã‹
          - brain-reviewer / validate_sql_columns.sh ãŒã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‚ç…§ã—ã¾ã™
          - ã‚¹ã‚­ãƒ¼ãƒãŒå¤ã„ã¨ AI ãƒ¬ãƒ“ãƒ¥ãƒ¼ãŒèª¤åˆ¤å®šã—ã¾ã™ï¼ˆ2026-02-22ã®500ã‚¨ãƒ©ãƒ¼ã®æ ¹æœ¬åŸå› ï¼‰

          ğŸ¤– è‡ªå‹•ç”Ÿæˆ by refresh-db-schema.yml" \
            --base main \
            --head "$BRANCH"
          echo "âœ… PRä½œæˆå®Œäº†: $BRANCH"
