# tests/test_llm_brain_core.py
"""
LLM Brain - Core ã®ãƒ†ã‚¹ãƒˆ

Claude Opus 4.5ã‚’ä½¿ç”¨ã—ãŸFunction Callingæ–¹å¼ã®è„³ã®æ©Ÿèƒ½ã‚’ãƒ†ã‚¹ãƒˆã—ã¾ã™ã€‚

è¨­è¨ˆæ›¸: docs/25_llm_native_brain_architecture.md ã‚»ã‚¯ã‚·ãƒ§ãƒ³5.2

ãƒ†ã‚¹ãƒˆå¯¾è±¡:
- ToolCall, ConfidenceScores, LLMBrainResult ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹
- LLMBrain åˆæœŸåŒ–
- LLMBrain.process() ãƒ¡ã‚½ãƒƒãƒ‰
- ç¢ºä¿¡åº¦æŠ½å‡º
- System Promptæ§‹ç¯‰
- ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
"""

import pytest
from unittest.mock import MagicMock, AsyncMock, patch
from datetime import datetime
import os
import json

from lib.brain.llm_brain import (
    ToolCall,
    ConfidenceScores,
    LLMBrainResult,
    LLMBrain,
    APIProvider,
    DEFAULT_SYSTEM_PROMPT,
    DEFAULT_MODEL_OPENROUTER,
    DEFAULT_MODEL_ANTHROPIC,
    create_llm_brain,
    create_llm_brain_auto,
    _get_openrouter_api_key,
    _get_anthropic_api_key,
)
from lib.brain.context_builder import LLMContext


# =============================================================================
# ãƒ•ã‚£ã‚¯ã‚¹ãƒãƒ£
# =============================================================================


@pytest.fixture
def sample_context():
    """ãƒ†ã‚¹ãƒˆç”¨ã®LLMContext"""
    return LLMContext(
        user_id="user_001",
        user_name="ãƒ†ã‚¹ãƒˆãƒ¦ãƒ¼ã‚¶ãƒ¼",
        user_role="member",
        organization_id="org_test",
        room_id="room_123",
        current_datetime=datetime.now(),
    )


@pytest.fixture
def sample_tools():
    """ãƒ†ã‚¹ãƒˆç”¨ã®Toolãƒªã‚¹ãƒˆï¼ˆAnthropicå½¢å¼ï¼‰"""
    return [
        {
            "name": "chatwork_task_create",
            "description": "ã‚¿ã‚¹ã‚¯ã‚’ä½œæˆã™ã‚‹",
            "input_schema": {
                "type": "object",
                "properties": {
                    "body": {"type": "string", "description": "ã‚¿ã‚¹ã‚¯å†…å®¹"},
                    "room_id": {"type": "string", "description": "ãƒ«ãƒ¼ãƒ ID"},
                },
                "required": ["body"],
            },
        },
        {
            "name": "chatwork_task_search",
            "description": "ã‚¿ã‚¹ã‚¯ã‚’æ¤œç´¢ã™ã‚‹",
            "input_schema": {
                "type": "object",
                "properties": {
                    "query": {"type": "string", "description": "æ¤œç´¢ã‚¯ã‚¨ãƒª"},
                },
                "required": [],
            },
        },
    ]


@pytest.fixture
def mock_openrouter_response():
    """ãƒ¢ãƒƒã‚¯ã®OpenRouter APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ï¼ˆOpenAIå½¢å¼ï¼‰"""
    return {
        "choices": [
            {
                "message": {
                    "content": """ã€æ€è€ƒéç¨‹ã€‘
- æ„å›³ç†è§£: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ã‚¿ã‚¹ã‚¯ã‚’è¿½åŠ ã—ãŸã„ã¨è€ƒãˆã‚‰ã‚Œã‚‹
- æ ¹æ‹ : ã€Œã‚¿ã‚¹ã‚¯è¿½åŠ ã—ã¦ã€ã¨ã„ã†ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‹ã‚‰åˆ¤æ–­
- Toolé¸æŠ: chatwork_task_createã‚’ä½¿ç”¨ã™ã‚‹
- ç¢ºä¿¡åº¦: 90%

ã€å¿œç­”ã€‘
ã‚¿ã‚¹ã‚¯ã‚’è¿½åŠ ã™ã‚‹ã‚¦ãƒ«ï¼""",
                    "tool_calls": [
                        {
                            "id": "tu_001",
                            "type": "function",
                            "function": {
                                "name": "chatwork_task_create",
                                "arguments": json.dumps({"body": "ãƒ†ã‚¹ãƒˆã‚¿ã‚¹ã‚¯", "room_id": "123"}),
                            },
                        }
                    ],
                },
            }
        ],
        "usage": {
            "prompt_tokens": 100,
            "completion_tokens": 50,
        },
    }


@pytest.fixture
def mock_anthropic_response():
    """ãƒ¢ãƒƒã‚¯ã®Anthropic APIãƒ¬ã‚¹ãƒãƒ³ã‚¹"""
    return {
        "content": [
            {
                "type": "text",
                "text": """ã€æ€è€ƒéç¨‹ã€‘
- æ„å›³ç†è§£: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ã‚¿ã‚¹ã‚¯ã‚’è¿½åŠ ã—ãŸã„ã¨è€ƒãˆã‚‰ã‚Œã‚‹
- æ ¹æ‹ : ã€Œã‚¿ã‚¹ã‚¯è¿½åŠ ã—ã¦ã€ã¨ã„ã†ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‹ã‚‰åˆ¤æ–­
- Toolé¸æŠ: chatwork_task_createã‚’ä½¿ç”¨ã™ã‚‹
- ç¢ºä¿¡åº¦: 90%

ã€å¿œç­”ã€‘
ã‚¿ã‚¹ã‚¯ã‚’è¿½åŠ ã™ã‚‹ã‚¦ãƒ«ï¼""",
            },
            {
                "type": "tool_use",
                "id": "tu_001",
                "name": "chatwork_task_create",
                "input": {"body": "ãƒ†ã‚¹ãƒˆã‚¿ã‚¹ã‚¯", "room_id": "123"},
            },
        ],
        "stop_reason": "tool_use",
        "usage": {
            "input_tokens": 100,
            "output_tokens": 50,
        },
    }


# =============================================================================
# ToolCall ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹ãƒ†ã‚¹ãƒˆ
# =============================================================================


class TestToolCall:
    """ToolCallãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹ã®ãƒ†ã‚¹ãƒˆ"""

    def test_init(self):
        """åˆæœŸåŒ–ã§ãã‚‹ã“ã¨"""
        tc = ToolCall(
            tool_name="chatwork_task_create",
            parameters={"body": "ãƒ†ã‚¹ãƒˆ"},
            reasoning="ã‚¿ã‚¹ã‚¯ä½œæˆ",
            tool_use_id="tu_001",
        )
        assert tc.tool_name == "chatwork_task_create"
        assert tc.parameters == {"body": "ãƒ†ã‚¹ãƒˆ"}
        assert tc.reasoning == "ã‚¿ã‚¹ã‚¯ä½œæˆ"
        assert tc.tool_use_id == "tu_001"

    def test_init_defaults(self):
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã§åˆæœŸåŒ–ã§ãã‚‹ã“ã¨"""
        tc = ToolCall(
            tool_name="test",
            parameters={},
        )
        assert tc.reasoning == ""
        assert tc.tool_use_id == ""

    def test_to_dict(self):
        """to_dictãŒæ­£ã—ã„å½¢å¼ã‚’è¿”ã™ã“ã¨"""
        tc = ToolCall(
            tool_name="chatwork_task_create",
            parameters={"body": "ãƒ†ã‚¹ãƒˆ"},
            reasoning="ã‚¿ã‚¹ã‚¯ä½œæˆ",
            tool_use_id="tu_001",
        )
        d = tc.to_dict()
        assert d["tool_name"] == "chatwork_task_create"
        assert d["parameters"] == {"body": "ãƒ†ã‚¹ãƒˆ"}
        assert d["reasoning"] == "ã‚¿ã‚¹ã‚¯ä½œæˆ"
        assert d["tool_use_id"] == "tu_001"


# =============================================================================
# ConfidenceScores ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹ãƒ†ã‚¹ãƒˆ
# =============================================================================


class TestConfidenceScores:
    """ConfidenceScoresãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹ã®ãƒ†ã‚¹ãƒˆ"""

    def test_init(self):
        """åˆæœŸåŒ–ã§ãã‚‹ã“ã¨"""
        cs = ConfidenceScores(
            overall=0.85,
            intent=0.90,
            parameters=0.80,
        )
        assert cs.overall == 0.85
        assert cs.intent == 0.90
        assert cs.parameters == 0.80

    def test_init_defaults(self):
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã§åˆæœŸåŒ–ã§ãã‚‹ã“ã¨"""
        cs = ConfidenceScores()
        assert cs.overall == 0.8
        assert cs.intent == 0.8
        assert cs.parameters == 0.8

    def test_to_dict(self):
        """to_dictãŒæ­£ã—ã„å½¢å¼ã‚’è¿”ã™ã“ã¨"""
        cs = ConfidenceScores(overall=0.85, intent=0.90, parameters=0.80)
        d = cs.to_dict()
        assert d["overall"] == 0.85
        assert d["intent"] == 0.90
        assert d["parameters"] == 0.80


# =============================================================================
# LLMBrainResult ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹ãƒ†ã‚¹ãƒˆ
# =============================================================================


class TestLLMBrainResult:
    """LLMBrainResultãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹ã®ãƒ†ã‚¹ãƒˆ"""

    def test_init_text_response(self):
        """ãƒ†ã‚­ã‚¹ãƒˆå¿œç­”ã§åˆæœŸåŒ–ã§ãã‚‹ã“ã¨"""
        result = LLMBrainResult(
            output_type="text_response",
            text_response="ã“ã‚“ã«ã¡ã¯",
            reasoning="æŒ¨æ‹¶ã«å¿œç­”",
            confidence=ConfidenceScores(overall=0.9),
        )
        assert result.output_type == "text_response"
        assert result.text_response == "ã“ã‚“ã«ã¡ã¯"
        assert result.tool_calls is None

    def test_init_tool_call(self):
        """Toolå‘¼ã³å‡ºã—ã§åˆæœŸåŒ–ã§ãã‚‹ã“ã¨"""
        tc = ToolCall(tool_name="test", parameters={})
        result = LLMBrainResult(
            output_type="tool_call",
            tool_calls=[tc],
            reasoning="ãƒ„ãƒ¼ãƒ«ä½¿ç”¨",
            confidence=ConfidenceScores(overall=0.85),
        )
        assert result.output_type == "tool_call"
        assert len(result.tool_calls) == 1
        assert result.tool_calls[0].tool_name == "test"

    def test_to_dict(self):
        """to_dictãŒæ­£ã—ã„å½¢å¼ã‚’è¿”ã™ã“ã¨"""
        tc = ToolCall(tool_name="test", parameters={"a": 1})
        result = LLMBrainResult(
            output_type="tool_call",
            tool_calls=[tc],
            reasoning="ãƒ†ã‚¹ãƒˆ",
            confidence=ConfidenceScores(overall=0.8),
            api_provider="openrouter",
        )
        d = result.to_dict()
        assert d["output_type"] == "tool_call"
        assert d["reasoning"] == "ãƒ†ã‚¹ãƒˆ"
        assert d["api_provider"] == "openrouter"
        assert "confidence" in d


# =============================================================================
# DEFAULT_SYSTEM_PROMPT ãƒ†ã‚¹ãƒˆ
# =============================================================================


class TestDefaultSystemPrompt:
    """DEFAULT_SYSTEM_PROMPTã®ãƒ†ã‚¹ãƒˆ"""

    def test_not_empty(self):
        """ç©ºã§ãªã„ã“ã¨"""
        assert len(DEFAULT_SYSTEM_PROMPT) > 0

    def test_contains_soulkun_identity(self):
        """ã‚½ã‚¦ãƒ«ãã‚“ã®ã‚¢ã‚¤ãƒ‡ãƒ³ãƒ†ã‚£ãƒ†ã‚£ãŒå«ã¾ã‚Œã‚‹ã“ã¨"""
        assert "ã‚½ã‚¦ãƒ«ãã‚“" in DEFAULT_SYSTEM_PROMPT

    def test_contains_mission(self):
        """ãƒŸãƒƒã‚·ãƒ§ãƒ³ãŒå«ã¾ã‚Œã‚‹ã“ã¨"""
        assert "ãƒŸãƒƒã‚·ãƒ§ãƒ³" in DEFAULT_SYSTEM_PROMPT or "ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼" in DEFAULT_SYSTEM_PROMPT

    def test_contains_role(self):
        """å½¹å‰²ãŒå«ã¾ã‚Œã‚‹ã“ã¨"""
        assert "å½¹å‰²" in DEFAULT_SYSTEM_PROMPT

    def test_contains_speaking_rules(self):
        """è©±ã—æ–¹ã®ãƒ«ãƒ¼ãƒ«ãŒå«ã¾ã‚Œã‚‹ã“ã¨"""
        assert "ã‚¦ãƒ«" in DEFAULT_SYSTEM_PROMPT


# =============================================================================
# APIã‚­ãƒ¼å–å¾—é–¢æ•°ãƒ†ã‚¹ãƒˆ
# =============================================================================


class TestApiKeyFunctions:
    """APIã‚­ãƒ¼å–å¾—é–¢æ•°ã®ãƒ†ã‚¹ãƒˆ"""

    def test_get_openrouter_api_key_from_env(self):
        """ç’°å¢ƒå¤‰æ•°ã‹ã‚‰OpenRouter APIã‚­ãƒ¼ã‚’å–å¾—ã§ãã‚‹ã“ã¨"""
        os.environ["OPENROUTER_API_KEY"] = "sk-or-test-key"
        try:
            key = _get_openrouter_api_key()
            assert key == "sk-or-test-key"
        finally:
            del os.environ["OPENROUTER_API_KEY"]

    def test_get_openrouter_api_key_returns_none_when_not_set(self):
        """APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ãªã„å ´åˆNoneã‚’è¿”ã™ã“ã¨"""
        # ç’°å¢ƒå¤‰æ•°ã‚’ã‚¯ãƒªã‚¢
        original = os.environ.pop("OPENROUTER_API_KEY", None)
        try:
            # Secret Managerã‚‚ãƒ¢ãƒƒã‚¯ï¼ˆå¤±æ•—ã•ã›ã‚‹ï¼‰
            # get_secret_cached ã¯ lib.secrets ã‹ã‚‰ã‚¤ãƒ³ãƒãƒ¼ãƒˆã•ã‚Œã‚‹ãŸã‚ã€ãã¡ã‚‰ã‚’ãƒ‘ãƒƒãƒ
            with patch("lib.secrets.get_secret_cached", side_effect=Exception("Not available")):
                key = _get_openrouter_api_key()
                # ç’°å¢ƒå¤‰æ•°ã‚‚Secret Managerã‚‚ãªã„å ´åˆã¯None
                assert key is None
        finally:
            if original:
                os.environ["OPENROUTER_API_KEY"] = original

    def test_get_anthropic_api_key_from_env(self):
        """ç’°å¢ƒå¤‰æ•°ã‹ã‚‰Anthropic APIã‚­ãƒ¼ã‚’å–å¾—ã§ãã‚‹ã“ã¨"""
        os.environ["ANTHROPIC_API_KEY"] = "sk-ant-test-key"
        try:
            key = _get_anthropic_api_key()
            assert key == "sk-ant-test-key"
        finally:
            del os.environ["ANTHROPIC_API_KEY"]

    def test_get_anthropic_api_key_returns_none_when_not_set(self):
        """APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ãªã„å ´åˆNoneã‚’è¿”ã™ã“ã¨"""
        original = os.environ.pop("ANTHROPIC_API_KEY", None)
        try:
            key = _get_anthropic_api_key()
            assert key is None
        finally:
            if original:
                os.environ["ANTHROPIC_API_KEY"] = original


# =============================================================================
# LLMBrain åˆæœŸåŒ–ãƒ†ã‚¹ãƒˆ
# =============================================================================


class TestLLMBrainInit:
    """LLMBrainåˆæœŸåŒ–ã®ãƒ†ã‚¹ãƒˆ"""

    def test_init_without_api_key_raises_error(self):
        """APIã‚­ãƒ¼ãªã—ã§åˆæœŸåŒ–ã™ã‚‹ã¨ã‚¨ãƒ©ãƒ¼ã«ãªã‚‹ã“ã¨"""
        # ç’°å¢ƒå¤‰æ•°ã‚’ã‚¯ãƒªã‚¢
        original_openrouter = os.environ.pop("OPENROUTER_API_KEY", None)
        original_anthropic = os.environ.pop("ANTHROPIC_API_KEY", None)
        try:
            # get_secret_cached ã¯ lib.secrets ã‹ã‚‰ã‚¤ãƒ³ãƒãƒ¼ãƒˆã•ã‚Œã‚‹ãŸã‚ã€ãã¡ã‚‰ã‚’ãƒ‘ãƒƒãƒ
            with patch("lib.secrets.get_secret_cached", side_effect=Exception("Not available")):
                with pytest.raises(ValueError, match="OpenRouter API key is required"):
                    LLMBrain(use_openrouter=True)
        finally:
            if original_openrouter:
                os.environ["OPENROUTER_API_KEY"] = original_openrouter
            if original_anthropic:
                os.environ["ANTHROPIC_API_KEY"] = original_anthropic

    def test_init_with_openrouter_api_key(self):
        """OpenRouter APIã‚­ãƒ¼ä»˜ãã§åˆæœŸåŒ–ã§ãã‚‹ã“ã¨"""
        os.environ["OPENROUTER_API_KEY"] = "sk-or-test-key"
        try:
            brain = LLMBrain(use_openrouter=True)
            assert brain is not None
            assert brain.model == DEFAULT_MODEL_OPENROUTER
            assert brain.api_provider == APIProvider.OPENROUTER
            assert brain.use_openrouter is True
        finally:
            del os.environ["OPENROUTER_API_KEY"]

    def test_init_with_anthropic_api_key(self):
        """Anthropic APIã‚­ãƒ¼ä»˜ãã§åˆæœŸåŒ–ã§ãã‚‹ã“ã¨ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰"""
        os.environ["ANTHROPIC_API_KEY"] = "sk-ant-test-key"
        try:
            brain = LLMBrain(use_openrouter=False)
            assert brain is not None
            assert brain.model == DEFAULT_MODEL_ANTHROPIC
            assert brain.api_provider == APIProvider.ANTHROPIC
            assert brain.use_openrouter is False
        finally:
            del os.environ["ANTHROPIC_API_KEY"]

    def test_init_with_custom_model(self):
        """ã‚«ã‚¹ã‚¿ãƒ ãƒ¢ãƒ‡ãƒ«ã§åˆæœŸåŒ–ã§ãã‚‹ã“ã¨"""
        os.environ["OPENROUTER_API_KEY"] = "sk-or-test-key"
        os.environ["LLM_BRAIN_MODEL"] = "anthropic/claude-3-opus-20240229"
        try:
            brain = LLMBrain(use_openrouter=True)
            assert brain.model == "anthropic/claude-3-opus-20240229"
        finally:
            del os.environ["OPENROUTER_API_KEY"]
            del os.environ["LLM_BRAIN_MODEL"]

    def test_init_with_explicit_model(self):
        """å¼•æ•°ã§æ˜ç¤ºçš„ã«ãƒ¢ãƒ‡ãƒ«ã‚’æŒ‡å®šã§ãã‚‹ã“ã¨"""
        os.environ["OPENROUTER_API_KEY"] = "sk-or-test-key"
        try:
            brain = LLMBrain(model="custom/model", use_openrouter=True)
            assert brain.model == "custom/model"
        finally:
            del os.environ["OPENROUTER_API_KEY"]

    def test_thresholds(self):
        """é–¾å€¤ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ã“ã¨"""
        os.environ["OPENROUTER_API_KEY"] = "sk-or-test-key"
        try:
            brain = LLMBrain(use_openrouter=True)
            assert brain.CONFIDENCE_THRESHOLD_AUTO_EXECUTE == 0.7
            assert brain.CONFIDENCE_THRESHOLD_CONFIRM == 0.5
            assert brain.CONFIDENCE_THRESHOLD_CLARIFY == 0.3
        finally:
            del os.environ["OPENROUTER_API_KEY"]


# =============================================================================
# LLMBrain.process ãƒ†ã‚¹ãƒˆï¼ˆãƒ¢ãƒƒã‚¯ä½¿ç”¨ï¼‰
# =============================================================================


class TestLLMBrainProcess:
    """LLMBrain.processãƒ¡ã‚½ãƒƒãƒ‰ã®ãƒ†ã‚¹ãƒˆï¼ˆãƒ¢ãƒƒã‚¯ä½¿ç”¨ï¼‰"""

    @pytest.mark.asyncio
    async def test_process_returns_llm_brain_result(
        self,
        sample_context,
        sample_tools,
        mock_openrouter_response,
    ):
        """processãŒLLMBrainResultã‚’è¿”ã™ã“ã¨"""
        os.environ["OPENROUTER_API_KEY"] = "sk-or-test-key"
        try:
            with patch.object(LLMBrain, "_call_openrouter", new_callable=AsyncMock) as mock_call:
                mock_call.return_value = mock_openrouter_response
                brain = LLMBrain(use_openrouter=True)

                result = await brain.process(
                    context=sample_context,
                    message="ã‚¿ã‚¹ã‚¯è¿½åŠ ã—ã¦",
                    tools=sample_tools,
                )

                assert isinstance(result, LLMBrainResult)
                assert result.api_provider == "openrouter"
        finally:
            del os.environ["OPENROUTER_API_KEY"]

    @pytest.mark.asyncio
    async def test_process_extracts_tool_calls(
        self,
        sample_context,
        sample_tools,
        mock_openrouter_response,
    ):
        """processãŒToolå‘¼ã³å‡ºã—ã‚’æ­£ã—ãæŠ½å‡ºã™ã‚‹ã“ã¨"""
        os.environ["OPENROUTER_API_KEY"] = "sk-or-test-key"
        try:
            with patch.object(LLMBrain, "_call_openrouter", new_callable=AsyncMock) as mock_call:
                mock_call.return_value = mock_openrouter_response
                brain = LLMBrain(use_openrouter=True)

                result = await brain.process(
                    context=sample_context,
                    message="ã‚¿ã‚¹ã‚¯è¿½åŠ ã—ã¦",
                    tools=sample_tools,
                )

                assert result.tool_calls is not None
                assert len(result.tool_calls) == 1
                assert result.tool_calls[0].tool_name == "chatwork_task_create"
                assert result.tool_calls[0].parameters == {"body": "ãƒ†ã‚¹ãƒˆã‚¿ã‚¹ã‚¯", "room_id": "123"}
        finally:
            del os.environ["OPENROUTER_API_KEY"]

    @pytest.mark.asyncio
    async def test_process_extracts_reasoning(
        self,
        sample_context,
        sample_tools,
        mock_openrouter_response,
    ):
        """processãŒreasoningã‚’æŠ½å‡ºã™ã‚‹ã“ã¨"""
        os.environ["OPENROUTER_API_KEY"] = "sk-or-test-key"
        try:
            with patch.object(LLMBrain, "_call_openrouter", new_callable=AsyncMock) as mock_call:
                mock_call.return_value = mock_openrouter_response
                brain = LLMBrain(use_openrouter=True)

                result = await brain.process(
                    context=sample_context,
                    message="ã‚¿ã‚¹ã‚¯è¿½åŠ ã—ã¦",
                    tools=sample_tools,
                )

                assert result.reasoning is not None
                assert len(result.reasoning) > 0
                assert "ã‚¿ã‚¹ã‚¯" in result.reasoning
        finally:
            del os.environ["OPENROUTER_API_KEY"]

    @pytest.mark.asyncio
    async def test_process_extracts_confidence(
        self,
        sample_context,
        sample_tools,
        mock_openrouter_response,
    ):
        """processãŒç¢ºä¿¡åº¦ã‚’æŠ½å‡ºã™ã‚‹ã“ã¨"""
        os.environ["OPENROUTER_API_KEY"] = "sk-or-test-key"
        try:
            with patch.object(LLMBrain, "_call_openrouter", new_callable=AsyncMock) as mock_call:
                mock_call.return_value = mock_openrouter_response
                brain = LLMBrain(use_openrouter=True)

                result = await brain.process(
                    context=sample_context,
                    message="ã‚¿ã‚¹ã‚¯è¿½åŠ ã—ã¦",
                    tools=sample_tools,
                )

                # ã€Œç¢ºä¿¡åº¦: 90%ã€ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã®ã§0.9
                assert result.confidence.overall == 0.9
        finally:
            del os.environ["OPENROUTER_API_KEY"]

    @pytest.mark.asyncio
    async def test_process_text_only_response(
        self,
        sample_context,
        sample_tools,
    ):
        """ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã®å¿œç­”ã‚’å‡¦ç†ã§ãã‚‹ã“ã¨"""
        os.environ["OPENROUTER_API_KEY"] = "sk-or-test-key"
        try:
            mock_response = {
                "choices": [
                    {
                        "message": {
                            "content": "ã“ã‚“ã«ã¡ã¯ï¼ãŠæ‰‹ä¼ã„ã§ãã‚‹ã“ã¨ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿã‚¦ãƒ«ğŸº",
                        },
                    }
                ],
                "usage": {"prompt_tokens": 50, "completion_tokens": 20},
            }

            with patch.object(LLMBrain, "_call_openrouter", new_callable=AsyncMock) as mock_call:
                mock_call.return_value = mock_response
                brain = LLMBrain(use_openrouter=True)

                result = await brain.process(
                    context=sample_context,
                    message="ã“ã‚“ã«ã¡ã¯",
                    tools=sample_tools,
                )

                assert result.output_type == "text_response"
                assert result.text_response is not None
                assert result.tool_calls is None or len(result.tool_calls) == 0
        finally:
            del os.environ["OPENROUTER_API_KEY"]

    @pytest.mark.asyncio
    async def test_process_api_error_handling(
        self,
        sample_context,
        sample_tools,
    ):
        """APIã‚¨ãƒ©ãƒ¼æ™‚ã«ã‚¨ãƒ©ãƒ¼çµæœã‚’è¿”ã™ã“ã¨"""
        os.environ["OPENROUTER_API_KEY"] = "sk-or-test-key"
        try:
            with patch.object(LLMBrain, "_call_openrouter", new_callable=AsyncMock) as mock_call:
                mock_call.side_effect = Exception("API Error: 500")
                brain = LLMBrain(use_openrouter=True)

                result = await brain.process(
                    context=sample_context,
                    message="ã‚¿ã‚¹ã‚¯è¿½åŠ ã—ã¦",
                    tools=sample_tools,
                )

                assert result.confidence.overall == 0.0
                assert "ã‚¨ãƒ©ãƒ¼" in result.text_response
                assert "Exception" in result.text_response
        finally:
            del os.environ["OPENROUTER_API_KEY"]

    @pytest.mark.asyncio
    async def test_process_with_anthropic_api(
        self,
        sample_context,
        sample_tools,
        mock_anthropic_response,
    ):
        """Anthropic APIã§ã‚‚å‡¦ç†ã§ãã‚‹ã“ã¨"""
        os.environ["ANTHROPIC_API_KEY"] = "sk-ant-test-key"
        try:
            with patch.object(LLMBrain, "_call_anthropic", new_callable=AsyncMock) as mock_call:
                mock_call.return_value = mock_anthropic_response
                brain = LLMBrain(use_openrouter=False)

                result = await brain.process(
                    context=sample_context,
                    message="ã‚¿ã‚¹ã‚¯è¿½åŠ ã—ã¦",
                    tools=sample_tools,
                )

                assert isinstance(result, LLMBrainResult)
                assert result.api_provider == "anthropic"
                assert result.tool_calls is not None
        finally:
            del os.environ["ANTHROPIC_API_KEY"]


# =============================================================================
# LLMBrain._extract_confidence ãƒ†ã‚¹ãƒˆ
# =============================================================================


class TestLLMBrainExtractConfidence:
    """LLMBrain._extract_confidenceãƒ¡ã‚½ãƒƒãƒ‰ã®ãƒ†ã‚¹ãƒˆ"""

    @pytest.fixture
    def brain(self):
        """ãƒ†ã‚¹ãƒˆç”¨ã®LLMBrain"""
        os.environ["OPENROUTER_API_KEY"] = "sk-or-test-key"
        brain = LLMBrain(use_openrouter=True)
        del os.environ["OPENROUTER_API_KEY"]
        return brain

    def test_extract_explicit_confidence(self, brain):
        """æ˜ç¤ºçš„ãªç¢ºä¿¡åº¦ã‚’æŠ½å‡ºã§ãã‚‹ã“ã¨"""
        reasoning = "ã“ã®æ“ä½œã«ã¤ã„ã¦ç¢ºä¿¡åº¦90%ã§é€²ã‚ã¾ã™ã€‚"
        full_text = ""
        result = brain._extract_confidence(reasoning, full_text)
        assert result.overall == 0.9

    def test_extract_explicit_confidence_with_colon(self, brain):
        """ã‚³ãƒ­ãƒ³ä»˜ãã®ç¢ºä¿¡åº¦è¡¨è¨˜ã‚’æŠ½å‡ºã§ãã‚‹ã“ã¨"""
        reasoning = "- ç¢ºä¿¡åº¦: 85%"
        full_text = ""
        result = brain._extract_confidence(reasoning, full_text)
        assert result.overall == 0.85

    def test_extract_high_confidence_keyword(self, brain):
        """é«˜ç¢ºä¿¡åº¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æ¤œå‡ºã§ãã‚‹ã“ã¨"""
        reasoning = "ã“ã®æ“ä½œã¯ç¢ºå®Ÿã«æ­£ã—ã„ã§ã™ã€‚"
        full_text = ""
        result = brain._extract_confidence(reasoning, full_text)
        assert result.overall >= 0.8

    def test_extract_medium_confidence_keyword(self, brain):
        """ä¸­ç¢ºä¿¡åº¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æ¤œå‡ºã§ãã‚‹ã“ã¨"""
        reasoning = "ãŠãã‚‰ãã‚¿ã‚¹ã‚¯è¿½åŠ ã ã¨æ€ã„ã¾ã™ã€‚"
        full_text = ""
        result = brain._extract_confidence(reasoning, full_text)
        assert result.overall == 0.7

    def test_extract_low_confidence_keyword(self, brain):
        """ä½ç¢ºä¿¡åº¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æ¤œå‡ºã§ãã‚‹ã“ã¨"""
        reasoning = "ã‚ˆãã‚ã‹ã‚Šã¾ã›ã‚“ãŒã€ã‚¿ã‚¹ã‚¯é–¢é€£ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚"
        full_text = ""
        result = brain._extract_confidence(reasoning, full_text)
        assert result.overall <= 0.6

    def test_extract_default_confidence(self, brain):
        """ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒãªã„å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¿”ã™ã“ã¨"""
        reasoning = "å‡¦ç†ã‚’é€²ã‚ã¾ã™ã€‚"
        full_text = ""
        result = brain._extract_confidence(reasoning, full_text)
        assert result.overall == 0.8  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ


# =============================================================================
# LLMBrain._build_system_prompt ãƒ†ã‚¹ãƒˆ
# =============================================================================


class TestLLMBrainBuildSystemPrompt:
    """LLMBrain._build_system_promptãƒ¡ã‚½ãƒƒãƒ‰ã®ãƒ†ã‚¹ãƒˆ"""

    @pytest.fixture
    def brain(self):
        """ãƒ†ã‚¹ãƒˆç”¨ã®LLMBrain"""
        os.environ["OPENROUTER_API_KEY"] = "sk-or-test-key"
        brain = LLMBrain(use_openrouter=True)
        del os.environ["OPENROUTER_API_KEY"]
        return brain

    def test_includes_default_prompt(self, brain, sample_context):
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒå«ã¾ã‚Œã‚‹ã“ã¨"""
        prompt = brain._build_system_prompt(DEFAULT_SYSTEM_PROMPT, sample_context)
        assert "ã‚½ã‚¦ãƒ«ãã‚“" in prompt

    def test_includes_context(self, brain, sample_context):
        """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãŒå«ã¾ã‚Œã‚‹ã“ã¨"""
        sample_context.user_name = "ãƒ†ã‚¹ãƒˆå¤ªéƒ"
        prompt = brain._build_system_prompt(DEFAULT_SYSTEM_PROMPT, sample_context)
        assert "ãƒ†ã‚¹ãƒˆå¤ªéƒ" in prompt

    def test_includes_instructions(self, brain, sample_context):
        """é‡è¦ãªæŒ‡ç¤ºãŒå«ã¾ã‚Œã‚‹ã“ã¨"""
        prompt = brain._build_system_prompt(DEFAULT_SYSTEM_PROMPT, sample_context)
        assert "æ€è€ƒéç¨‹" in prompt
        assert "ç¢ºä¿¡åº¦" in prompt


# =============================================================================
# LLMBrain._convert_tools_to_openai_format ãƒ†ã‚¹ãƒˆ
# =============================================================================


class TestLLMBrainConvertTools:
    """LLMBrain._convert_tools_to_openai_formatãƒ¡ã‚½ãƒƒãƒ‰ã®ãƒ†ã‚¹ãƒˆ"""

    @pytest.fixture
    def brain(self):
        """ãƒ†ã‚¹ãƒˆç”¨ã®LLMBrain"""
        os.environ["OPENROUTER_API_KEY"] = "sk-or-test-key"
        brain = LLMBrain(use_openrouter=True)
        del os.environ["OPENROUTER_API_KEY"]
        return brain

    def test_converts_single_tool(self, brain, sample_tools):
        """å˜ä¸€ã®Toolã‚’å¤‰æ›ã§ãã‚‹ã“ã¨"""
        openai_tools = brain._convert_tools_to_openai_format([sample_tools[0]])
        assert len(openai_tools) == 1
        assert openai_tools[0]["type"] == "function"
        assert openai_tools[0]["function"]["name"] == "chatwork_task_create"

    def test_converts_multiple_tools(self, brain, sample_tools):
        """è¤‡æ•°ã®Toolã‚’å¤‰æ›ã§ãã‚‹ã“ã¨"""
        openai_tools = brain._convert_tools_to_openai_format(sample_tools)
        assert len(openai_tools) == 2

    def test_preserves_parameters(self, brain, sample_tools):
        """ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒä¿æŒã•ã‚Œã‚‹ã“ã¨"""
        openai_tools = brain._convert_tools_to_openai_format([sample_tools[0]])
        parameters = openai_tools[0]["function"]["parameters"]
        assert "properties" in parameters
        assert "body" in parameters["properties"]


# =============================================================================
# LLMBrain - ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ
# =============================================================================


class TestLLMBrainErrorHandling:
    """LLMBrainã®ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ"""

    @pytest.mark.asyncio
    async def test_handle_rate_limit_error(self, sample_context, sample_tools):
        """ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚¨ãƒ©ãƒ¼ã‚’é©åˆ‡ã«å‡¦ç†ã™ã‚‹ã“ã¨"""
        os.environ["OPENROUTER_API_KEY"] = "sk-or-test-key"
        try:
            with patch.object(LLMBrain, "_call_openrouter", new_callable=AsyncMock) as mock_call:
                mock_call.side_effect = Exception("rate_limit_error: 429 Too Many Requests")
                brain = LLMBrain(use_openrouter=True)

                result = await brain.process(
                    context=sample_context,
                    message="ãƒ†ã‚¹ãƒˆ",
                    tools=sample_tools,
                )

                assert result.confidence.overall == 0.0
                assert result.text_response is not None
                assert "ã‚¨ãƒ©ãƒ¼" in result.text_response
        finally:
            del os.environ["OPENROUTER_API_KEY"]

    @pytest.mark.asyncio
    async def test_handle_invalid_response(self, sample_context, sample_tools):
        """ç„¡åŠ¹ãªãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’é©åˆ‡ã«å‡¦ç†ã™ã‚‹ã“ã¨"""
        os.environ["OPENROUTER_API_KEY"] = "sk-or-test-key"
        try:
            mock_response = {
                "choices": [
                    {
                        "message": {
                            "content": "",  # ç©ºã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
                        },
                    }
                ],
                "usage": {"prompt_tokens": 0, "completion_tokens": 0},
            }

            with patch.object(LLMBrain, "_call_openrouter", new_callable=AsyncMock) as mock_call:
                mock_call.return_value = mock_response
                brain = LLMBrain(use_openrouter=True)

                result = await brain.process(
                    context=sample_context,
                    message="ãƒ†ã‚¹ãƒˆ",
                    tools=sample_tools,
                )

                # ã‚¨ãƒ©ãƒ¼ã«ãªã‚‰ãšã€ä½•ã‚‰ã‹ã®çµæœãŒè¿”ã‚‹ã“ã¨
                assert isinstance(result, LLMBrainResult)
        finally:
            del os.environ["OPENROUTER_API_KEY"]

    @pytest.mark.asyncio
    async def test_handle_empty_choices(self, sample_context, sample_tools):
        """ç©ºã®choicesã‚’é©åˆ‡ã«å‡¦ç†ã™ã‚‹ã“ã¨"""
        os.environ["OPENROUTER_API_KEY"] = "sk-or-test-key"
        try:
            mock_response = {
                "choices": [],
                "usage": {"prompt_tokens": 0, "completion_tokens": 0},
            }

            with patch.object(LLMBrain, "_call_openrouter", new_callable=AsyncMock) as mock_call:
                mock_call.return_value = mock_response
                brain = LLMBrain(use_openrouter=True)

                result = await brain.process(
                    context=sample_context,
                    message="ãƒ†ã‚¹ãƒˆ",
                    tools=sample_tools,
                )

                # ã‚¨ãƒ©ãƒ¼çµæœãŒè¿”ã‚‹ã“ã¨
                assert result.confidence.overall == 0.0
                assert "ã‚¨ãƒ©ãƒ¼" in result.text_response
        finally:
            del os.environ["OPENROUTER_API_KEY"]


# =============================================================================
# ãƒ•ã‚¡ã‚¯ãƒˆãƒªé–¢æ•°ãƒ†ã‚¹ãƒˆ
# =============================================================================


class TestFactoryFunctions:
    """ãƒ•ã‚¡ã‚¯ãƒˆãƒªé–¢æ•°ã®ãƒ†ã‚¹ãƒˆ"""

    def test_create_llm_brain_openrouter(self):
        """create_llm_brainãŒOpenRouterç”¨ã®LLMBrainã‚’ä½œæˆã™ã‚‹ã“ã¨"""
        os.environ["OPENROUTER_API_KEY"] = "sk-or-test-key"
        try:
            brain = create_llm_brain(use_openrouter=True)
            assert brain.api_provider == APIProvider.OPENROUTER
        finally:
            del os.environ["OPENROUTER_API_KEY"]

    def test_create_llm_brain_anthropic(self):
        """create_llm_brainãŒAnthropicç”¨ã®LLMBrainã‚’ä½œæˆã™ã‚‹ã“ã¨"""
        os.environ["ANTHROPIC_API_KEY"] = "sk-ant-test-key"
        try:
            brain = create_llm_brain(use_openrouter=False)
            assert brain.api_provider == APIProvider.ANTHROPIC
        finally:
            del os.environ["ANTHROPIC_API_KEY"]

    def test_create_llm_brain_auto_prefers_openrouter(self):
        """create_llm_brain_autoãŒOpenRouterã‚’å„ªå…ˆã™ã‚‹ã“ã¨"""
        os.environ["OPENROUTER_API_KEY"] = "sk-or-test-key"
        os.environ["ANTHROPIC_API_KEY"] = "sk-ant-test-key"
        try:
            brain = create_llm_brain_auto()
            assert brain.api_provider == APIProvider.OPENROUTER
        finally:
            del os.environ["OPENROUTER_API_KEY"]
            del os.environ["ANTHROPIC_API_KEY"]

    def test_create_llm_brain_auto_falls_back_to_anthropic(self):
        """create_llm_brain_autoãŒAnthropicã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã™ã‚‹ã“ã¨"""
        original_openrouter = os.environ.pop("OPENROUTER_API_KEY", None)
        os.environ["ANTHROPIC_API_KEY"] = "sk-ant-test-key"
        try:
            # get_secret_cached ã¯ lib.secrets ã‹ã‚‰ã‚¤ãƒ³ãƒãƒ¼ãƒˆã•ã‚Œã‚‹ãŸã‚ã€ãã¡ã‚‰ã‚’ãƒ‘ãƒƒãƒ
            with patch("lib.secrets.get_secret_cached", side_effect=Exception("Not available")):
                brain = create_llm_brain_auto()
                assert brain.api_provider == APIProvider.ANTHROPIC
        finally:
            if original_openrouter:
                os.environ["OPENROUTER_API_KEY"] = original_openrouter
            del os.environ["ANTHROPIC_API_KEY"]

    def test_create_llm_brain_auto_raises_when_no_key(self):
        """create_llm_brain_autoãŒã‚­ãƒ¼ãªã—ã§ã‚¨ãƒ©ãƒ¼ã‚’æŠ•ã’ã‚‹ã“ã¨"""
        original_openrouter = os.environ.pop("OPENROUTER_API_KEY", None)
        original_anthropic = os.environ.pop("ANTHROPIC_API_KEY", None)
        try:
            # get_secret_cached ã¯ lib.secrets ã‹ã‚‰ã‚¤ãƒ³ãƒãƒ¼ãƒˆã•ã‚Œã‚‹ãŸã‚ã€ãã¡ã‚‰ã‚’ãƒ‘ãƒƒãƒ
            with patch("lib.secrets.get_secret_cached", side_effect=Exception("Not available")):
                with pytest.raises(ValueError, match="No API key available"):
                    create_llm_brain_auto()
        finally:
            if original_openrouter:
                os.environ["OPENROUTER_API_KEY"] = original_openrouter
            if original_anthropic:
                os.environ["ANTHROPIC_API_KEY"] = original_anthropic
