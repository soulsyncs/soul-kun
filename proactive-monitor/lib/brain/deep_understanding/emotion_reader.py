# lib/brain/deep_understanding/emotion_reader.py
"""
Phase 2I: ç†è§£åŠ›å¼·åŒ–ï¼ˆDeep Understandingï¼‰- æ„Ÿæƒ…ãƒ»ãƒ‹ãƒ¥ã‚¢ãƒ³ã‚¹ã®èª­ã¿å–ã‚Š

è¨­è¨ˆæ›¸: docs/17_brain_completion_roadmap.md ã‚»ã‚¯ã‚·ãƒ§ãƒ³17.3 Phase 2I

ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã«ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç™ºè©±ã‹ã‚‰æ„Ÿæƒ…ãƒ»ç·Šæ€¥åº¦ãƒ»ãƒ‹ãƒ¥ã‚¢ãƒ³ã‚¹ã‚’èª­ã¿å–ã‚‹æ©Ÿèƒ½ã‚’å®Ÿè£…ã—ã¾ã™ã€‚

ã€ä¸»ãªæ©Ÿèƒ½ã€‘
- æ„Ÿæƒ…ã®æ¤œå‡ºï¼ˆå–œæ€’å“€æ¥½ã€ã‚¹ãƒˆãƒ¬ã‚¹ç­‰ï¼‰
- ç·Šæ€¥åº¦ã®åˆ¤å®šï¼ˆã€Œã¡ã‚‡ã£ã¨æ€¥ã„ã§ã‚‹ã€ã®è§£é‡ˆï¼‰
- ãƒ‹ãƒ¥ã‚¢ãƒ³ã‚¹ã®èª­ã¿å–ã‚Šï¼ˆç¢ºä¿¡åº¦ã€ä¸å¯§ã•ã€ãƒˆãƒ¼ãƒ³ï¼‰
- æ–‡è„ˆã‚’è€ƒæ…®ã—ãŸæ„Ÿæƒ…ã®è£œæ­£

Author: Claude Opus 4.5
Created: 2026-01-27
"""

import logging
import re
import time
from typing import Optional, List, Dict, Any, Tuple

from .constants import (
    EmotionCategory,
    UrgencyLevel,
    NuanceType,
    EMOTION_INDICATORS,
    URGENCY_INDICATORS,
    EMOTION_CONFIDENCE_THRESHOLDS,
)
from .models import (
    DetectedEmotion,
    DetectedUrgency,
    DetectedNuance,
    EmotionReadingResult,
    DeepUnderstandingInput,
)

logger = logging.getLogger(__name__)


class EmotionReader:
    """
    æ„Ÿæƒ…ãƒ»ãƒ‹ãƒ¥ã‚¢ãƒ³ã‚¹èª­ã¿å–ã‚Šã‚¨ãƒ³ã‚¸ãƒ³

    ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç™ºè©±ã‹ã‚‰æ„Ÿæƒ…ã€ç·Šæ€¥åº¦ã€ãƒ‹ãƒ¥ã‚¢ãƒ³ã‚¹ã‚’æ¤œå‡ºã—ã€
    æ–‡è„ˆã‚’è€ƒæ…®ã—ãŸè§£é‡ˆã‚’è¡Œã†ã€‚

    ä½¿ç”¨ä¾‹:
        reader = EmotionReader()
        result = await reader.read(
            message="ã¡ã‚‡ã£ã¨æ€¥ã„ã§ã‚‹ã‚“ã ã‘ã©ã€ã“ã‚ŒãŠé¡˜ã„ã§ãã‚‹ï¼Ÿ",
            input_context=deep_understanding_input,
        )
    """

    def __init__(self):
        """åˆæœŸåŒ–"""
        logger.info("EmotionReader initialized")

    # =========================================================================
    # ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ
    # =========================================================================

    async def read(
        self,
        message: str,
        input_context: DeepUnderstandingInput,
    ) -> EmotionReadingResult:
        """
        æ„Ÿæƒ…ãƒ»ãƒ‹ãƒ¥ã‚¢ãƒ³ã‚¹ã‚’èª­ã¿å–ã‚‹

        Args:
            message: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            input_context: æ·±ã„ç†è§£å±¤ã¸ã®å…¥åŠ›ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ

        Returns:
            EmotionReadingResult: æ„Ÿæƒ…èª­ã¿å–ã‚Šã®çµæœ
        """
        start_time = time.time()

        try:
            # Step 1: æ„Ÿæƒ…ã®æ¤œå‡º
            emotions = self._detect_emotions(message)

            # Step 2: ç·Šæ€¥åº¦ã®æ¤œå‡º
            urgency = self._detect_urgency(message)

            # Step 3: ãƒ‹ãƒ¥ã‚¢ãƒ³ã‚¹ã®æ¤œå‡º
            nuances = self._detect_nuances(message)

            # Step 4: æ–‡è„ˆã‚’è€ƒæ…®ã—ãŸè£œæ­£
            emotions, urgency = self._apply_context_correction(
                emotions=emotions,
                urgency=urgency,
                context=input_context,
            )

            # Step 5: ä¸»è¦ãªæ„Ÿæƒ…ã‚’é¸æŠ
            primary_emotion = self._select_primary_emotion(emotions)

            # Step 6: ã‚µãƒãƒªãƒ¼ã®ç”Ÿæˆ
            summary = self._generate_summary(emotions, urgency, nuances)

            # Step 7: å…¨ä½“ã®ä¿¡é ¼åº¦ã‚’è¨ˆç®—
            overall_confidence = self._calculate_overall_confidence(
                emotions=emotions,
                urgency=urgency,
                nuances=nuances,
            )

            result = EmotionReadingResult(
                emotions=emotions,
                primary_emotion=primary_emotion,
                urgency=urgency,
                nuances=nuances,
                original_message=message,
                overall_confidence=overall_confidence,
                processing_time_ms=self._elapsed_ms(start_time),
                summary=summary,
            )

            logger.info(
                f"Emotion reading complete: "
                f"emotions={len(emotions)}, "
                f"primary={primary_emotion.category.value if primary_emotion else 'none'}, "
                f"urgency={urgency.level.value if urgency else 'none'}"
            )

            return result

        except Exception as e:
            logger.error(f"Error in emotion reading: {e}")
            return EmotionReadingResult(
                emotions=[],
                urgency=None,
                nuances=[],
                original_message=message,
                overall_confidence=0.0,
                processing_time_ms=self._elapsed_ms(start_time),
                summary="æ„Ÿæƒ…ã®èª­ã¿å–ã‚Šã«å¤±æ•—ã—ã¾ã—ãŸ",
            )

    # =========================================================================
    # æ„Ÿæƒ…ã®æ¤œå‡º
    # =========================================================================

    def _detect_emotions(self, message: str) -> List[DetectedEmotion]:
        """
        ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰æ„Ÿæƒ…ã‚’æ¤œå‡º
        """
        detected_emotions: List[DetectedEmotion] = []
        normalized = message.lower()

        for emotion_value, indicators in EMOTION_INDICATORS.items():
            keywords = indicators.get("keywords", [])
            expressions = indicators.get("expressions", [])
            intensity_words = indicators.get("intensity", [])

            # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒ
            matched_keywords = []
            for keyword in keywords:
                if keyword in message or keyword in normalized:
                    matched_keywords.append(keyword)

            # è¡¨ç¾ãƒãƒƒãƒï¼ˆçµµæ–‡å­—ã€é¡”æ–‡å­—ç­‰ï¼‰
            matched_expressions = []
            for expr in expressions:
                if expr in message:
                    matched_expressions.append(expr)

            # å¼·åº¦ä¿®é£¾èªã®ãƒã‚§ãƒƒã‚¯
            has_intensity = any(word in message for word in intensity_words)

            # ãƒãƒƒãƒãŒã‚ã‚Œã°æ„Ÿæƒ…ã¨ã—ã¦æ¤œå‡º
            total_matches = len(matched_keywords) + len(matched_expressions)
            if total_matches > 0:
                # ä¿¡é ¼åº¦ã®è¨ˆç®—
                confidence = min(0.5 + (total_matches * 0.15), 0.95)

                # å¼·åº¦ã®è¨ˆç®—
                intensity = 0.5
                if has_intensity:
                    intensity = 0.8
                if total_matches >= 3:
                    intensity = min(intensity + 0.2, 1.0)

                try:
                    category = EmotionCategory(emotion_value)
                except ValueError:
                    continue

                detected_emotions.append(DetectedEmotion(
                    category=category,
                    intensity=intensity,
                    confidence=confidence,
                    indicators=matched_keywords + matched_expressions,
                    reasoning=f"ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã€Œ{', '.join(matched_keywords[:3])}ã€ã‚’æ¤œå‡º",
                ))

        # è¿½åŠ ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ™ãƒ¼ã‚¹æ¤œå‡º
        additional = self._detect_emotion_patterns(message)
        detected_emotions.extend(additional)

        # é‡è¤‡ã‚’é™¤å»ï¼ˆåŒã˜ã‚«ãƒ†ã‚´ãƒªã¯ä¿¡é ¼åº¦ãŒé«˜ã„æ–¹ã‚’æ®‹ã™ï¼‰
        return self._deduplicate_emotions(detected_emotions)

    def _detect_emotion_patterns(self, message: str) -> List[DetectedEmotion]:
        """
        ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ™ãƒ¼ã‚¹ã®æ„Ÿæƒ…æ¤œå‡º
        """
        emotions: List[DetectedEmotion] = []

        # ç¹°ã‚Šè¿”ã—è¡¨ç¾ï¼ˆå¼·ã„æ„Ÿæƒ…ã®è¡¨ã‚Œï¼‰
        if re.search(r'(.)\1{2,}', message):  # åŒã˜æ–‡å­—ã®3å›ä»¥ä¸Šã®ç¹°ã‚Šè¿”ã—
            # æ–‡è„ˆã‹ã‚‰æ„Ÿæƒ…ã‚’æ¨å®š
            if any(word in message for word in ["ã†ã‚Œã—ã„", "ã‚„ã£ãŸ", "æœ€é«˜"]):
                emotions.append(DetectedEmotion(
                    category=EmotionCategory.EXCITED,
                    intensity=0.9,
                    confidence=0.7,
                    indicators=["æ–‡å­—ã®ç¹°ã‚Šè¿”ã—"],
                    reasoning="å¼·èª¿è¡¨ç¾ã‹ã‚‰èˆˆå¥®ã‚’æ¤œå‡º",
                ))

        # ç–‘å•ç¬¦ã®é€£ç¶šï¼ˆå›°æƒ‘ãƒ»ç–‘å•ï¼‰
        if re.search(r'\?{2,}|ï¼Ÿ{2,}', message):
            emotions.append(DetectedEmotion(
                category=EmotionCategory.CONFUSED,
                intensity=0.7,
                confidence=0.65,
                indicators=["è¤‡æ•°ã®ç–‘å•ç¬¦"],
                reasoning="è¤‡æ•°ã®ç–‘å•ç¬¦ã‹ã‚‰å›°æƒ‘ã‚’æ¤œå‡º",
            ))

        # æ„Ÿå˜†ç¬¦ã®é€£ç¶šï¼ˆå¼·ã„æ„Ÿæƒ…ï¼‰
        if re.search(r'!{2,}|ï¼{2,}', message):
            emotions.append(DetectedEmotion(
                category=EmotionCategory.EXCITED,
                intensity=0.8,
                confidence=0.6,
                indicators=["è¤‡æ•°ã®æ„Ÿå˜†ç¬¦"],
                reasoning="è¤‡æ•°ã®æ„Ÿå˜†ç¬¦ã‹ã‚‰å¼·ã„æ„Ÿæƒ…ã‚’æ¤œå‡º",
            ))

        # çœç•¥è¨˜å·ï¼ˆãŸã‚ã‚‰ã„ã€å›°æƒ‘ï¼‰
        if re.search(r'\.{3,}|â€¦+', message):
            emotions.append(DetectedEmotion(
                category=EmotionCategory.UNCERTAIN,
                intensity=0.5,
                confidence=0.55,
                indicators=["çœç•¥è¨˜å·"],
                reasoning="çœç•¥è¨˜å·ã‹ã‚‰ãŸã‚ã‚‰ã„ã‚’æ¤œå‡º",
            ))

        # æ•¬èªã®å´©ã‚Œï¼ˆãƒ•ãƒ©ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
        if re.search(r'(ãªã‚“ã§|ã©ã†ã—ã¦|ãµã–ã‘)', message) and not re.search(r'(ã§ã™ã‹|ã¾ã™ã‹|ã§ã—ã‚‡ã†ã‹)', message):
            emotions.append(DetectedEmotion(
                category=EmotionCategory.FRUSTRATED,
                intensity=0.7,
                confidence=0.6,
                indicators=["æ•¬èªã®å´©ã‚Œ"],
                reasoning="æ•¬èªã‚’ä½¿ã‚ãªã„ç–‘å•ã‹ã‚‰ãƒ•ãƒ©ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æ¤œå‡º",
            ))

        return emotions

    def _deduplicate_emotions(
        self,
        emotions: List[DetectedEmotion],
    ) -> List[DetectedEmotion]:
        """
        æ„Ÿæƒ…ã®é‡è¤‡ã‚’é™¤å»ï¼ˆåŒã˜ã‚«ãƒ†ã‚´ãƒªã¯ä¿¡é ¼åº¦ãŒé«˜ã„æ–¹ã‚’æ®‹ã™ï¼‰
        """
        by_category: Dict[EmotionCategory, DetectedEmotion] = {}

        for emotion in emotions:
            existing = by_category.get(emotion.category)
            if existing is None or emotion.confidence > existing.confidence:
                by_category[emotion.category] = emotion

        return list(by_category.values())

    # =========================================================================
    # ç·Šæ€¥åº¦ã®æ¤œå‡º
    # =========================================================================

    def _detect_urgency(self, message: str) -> Optional[DetectedUrgency]:
        """
        ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰ç·Šæ€¥åº¦ã‚’æ¤œå‡º
        """
        # å„ç·Šæ€¥åº¦ãƒ¬ãƒ™ãƒ«ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ãƒã‚§ãƒƒã‚¯
        for level_value in [
            UrgencyLevel.CRITICAL.value,
            UrgencyLevel.VERY_HIGH.value,
            UrgencyLevel.HIGH.value,
            UrgencyLevel.MEDIUM.value,
            UrgencyLevel.LOW.value,
            UrgencyLevel.VERY_LOW.value,
        ]:
            keywords = URGENCY_INDICATORS.get(level_value, [])
            matched = []

            for keyword in keywords:
                if keyword in message:
                    matched.append(keyword)

            if matched:
                level = UrgencyLevel(level_value)

                # æ¨å®šæœŸé™ï¼ˆæ™‚é–“ï¼‰
                deadline_hours = self._estimate_deadline_hours(level)

                # ä¿¡é ¼åº¦ã®è¨ˆç®—
                confidence = 0.7 + (len(matched) * 0.1)
                confidence = min(confidence, 0.95)

                return DetectedUrgency(
                    level=level,
                    confidence=confidence,
                    estimated_deadline_hours=deadline_hours,
                    indicators=matched,
                    reasoning=f"ç·Šæ€¥åº¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã€Œ{', '.join(matched[:2])}ã€ã‚’æ¤œå‡º",
                )

        # ç·Šæ€¥åº¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒãªã„å ´åˆã¯ä¸­ç¨‹åº¦ã¨æ¨å®š
        return DetectedUrgency(
            level=UrgencyLevel.MEDIUM,
            confidence=0.5,
            estimated_deadline_hours=None,
            indicators=[],
            reasoning="ç·Šæ€¥åº¦ã‚’ç¤ºã™æ˜ç¢ºãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãªã—",
        )

    def _estimate_deadline_hours(self, level: UrgencyLevel) -> float:
        """
        ç·Šæ€¥åº¦ãƒ¬ãƒ™ãƒ«ã‹ã‚‰æ¨å®šæœŸé™ã‚’è¨ˆç®—
        """
        mapping = {
            UrgencyLevel.CRITICAL: 1.0,
            UrgencyLevel.VERY_HIGH: 4.0,
            UrgencyLevel.HIGH: 8.0,
            UrgencyLevel.MEDIUM: 48.0,
            UrgencyLevel.LOW: 168.0,  # 1é€±é–“
            UrgencyLevel.VERY_LOW: 720.0,  # 1ãƒ¶æœˆ
        }
        return mapping.get(level, 48.0)

    # =========================================================================
    # ãƒ‹ãƒ¥ã‚¢ãƒ³ã‚¹ã®æ¤œå‡º
    # =========================================================================

    def _detect_nuances(self, message: str) -> List[DetectedNuance]:
        """
        ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰ãƒ‹ãƒ¥ã‚¢ãƒ³ã‚¹ã‚’æ¤œå‡º
        """
        nuances: List[DetectedNuance] = []

        # ç¢ºä¿¡åº¦ã®æ¤œå‡º
        certainty_nuance = self._detect_certainty(message)
        if certainty_nuance:
            nuances.append(certainty_nuance)

        # ä¸å¯§ã•ã®æ¤œå‡º
        formality_nuance = self._detect_formality(message)
        if formality_nuance:
            nuances.append(formality_nuance)

        # ãƒˆãƒ¼ãƒ³ã®æ¤œå‡º
        tone_nuance = self._detect_tone(message)
        if tone_nuance:
            nuances.append(tone_nuance)

        return nuances

    def _detect_certainty(self, message: str) -> Optional[DetectedNuance]:
        """
        ç¢ºä¿¡åº¦ã®ãƒ‹ãƒ¥ã‚¢ãƒ³ã‚¹ã‚’æ¤œå‡º
        """
        high_certainty_patterns = [
            r"(çµ¶å¯¾|å¿…ãš|ç¢ºå®Ÿ|é–“é•ã„ãªã|100%|ã¾ã¡ãŒã„ãªã„)",
            r"(æ–­è¨€|ç¢ºä¿¡|è‡ªä¿¡ã‚ã‚Š)",
        ]

        medium_certainty_patterns = [
            r"(ãŸã¶ã‚“|ãŠãã‚‰ã|å¤šåˆ†|æã‚‰ã|æ€ã†|ã¯ãš)",
        ]

        low_certainty_patterns = [
            r"(ã‚‚ã—ã‹ã—ãŸã‚‰|ã²ã‚‡ã£ã¨ã—ãŸã‚‰|ã‹ã‚‚ã—ã‚Œãªã„|ã‚ã‹ã‚‰ãªã„|ä¸æ˜)",
            r"(è‡ªä¿¡ãªã„|ç¢ºè¨¼ãªã„)",
        ]

        for pattern in high_certainty_patterns:
            if re.search(pattern, message):
                return DetectedNuance(
                    nuance_type=NuanceType.CERTAINTY_HIGH,
                    confidence=0.8,
                    indicators=[pattern],
                    reasoning="é«˜ã„ç¢ºä¿¡åº¦ã‚’ç¤ºã™è¡¨ç¾ã‚’æ¤œå‡º",
                )

        for pattern in medium_certainty_patterns:
            if re.search(pattern, message):
                return DetectedNuance(
                    nuance_type=NuanceType.CERTAINTY_MEDIUM,
                    confidence=0.7,
                    indicators=[pattern],
                    reasoning="ä¸­ç¨‹åº¦ã®ç¢ºä¿¡åº¦ã‚’ç¤ºã™è¡¨ç¾ã‚’æ¤œå‡º",
                )

        for pattern in low_certainty_patterns:
            if re.search(pattern, message):
                return DetectedNuance(
                    nuance_type=NuanceType.CERTAINTY_LOW,
                    confidence=0.75,
                    indicators=[pattern],
                    reasoning="ä½ã„ç¢ºä¿¡åº¦ã‚’ç¤ºã™è¡¨ç¾ã‚’æ¤œå‡º",
                )

        return None

    def _detect_formality(self, message: str) -> Optional[DetectedNuance]:
        """
        ä¸å¯§ã•ã®ãƒ‹ãƒ¥ã‚¢ãƒ³ã‚¹ã‚’æ¤œå‡º
        """
        # æ•¬èªã®ãƒã‚§ãƒƒã‚¯
        formal_patterns = [
            r"(ã§ã™|ã¾ã™|ã”ã–ã„ã¾ã™|ã„ãŸã—ã¾ã™|å­˜ã˜ã¾ã™)",
            r"(ãŠé¡˜ã„ã„ãŸã—ã¾ã™|ã”ç¢ºèªãã ã•ã„|æã‚Œå…¥ã‚Šã¾ã™ãŒ)",
        ]

        casual_patterns = [
            r"(ã ã‚ˆ|ã ã­|ã˜ã‚ƒã‚“|ã£ã™|ã ãœ|ã ãª)",
            r"(ã‚„ã£ã¦|é ¼ã‚€|æ•™ãˆã¦$)",
        ]

        formal_count = sum(1 for p in formal_patterns if re.search(p, message))
        casual_count = sum(1 for p in casual_patterns if re.search(p, message))

        if formal_count > casual_count and formal_count > 0:
            return DetectedNuance(
                nuance_type=NuanceType.FORMAL,
                confidence=0.7 + (formal_count * 0.1),
                indicators=["æ•¬èªä½¿ç”¨"],
                reasoning="æ•¬èªã®ä½¿ç”¨ã‹ã‚‰ãƒ•ã‚©ãƒ¼ãƒãƒ«ãªãƒˆãƒ¼ãƒ³ã‚’æ¤œå‡º",
            )
        elif casual_count > formal_count and casual_count > 0:
            return DetectedNuance(
                nuance_type=NuanceType.CASUAL,
                confidence=0.7 + (casual_count * 0.1),
                indicators=["ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«è¡¨ç¾"],
                reasoning="ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«ãªè¡¨ç¾ã‚’æ¤œå‡º",
            )

        return None

    def _detect_tone(self, message: str) -> Optional[DetectedNuance]:
        """
        ãƒˆãƒ¼ãƒ³ã®ãƒ‹ãƒ¥ã‚¢ãƒ³ã‚¹ã‚’æ¤œå‡º
        """
        # ãƒã‚¸ãƒ†ã‚£ãƒ–ãªãƒˆãƒ¼ãƒ³
        positive_patterns = [
            r"(å¬‰ã—ã„|æ¥½ã—ã„|ã‚ã‚ŠãŒã¨ã†|åŠ©ã‹ã‚‹|è‰¯ã„|ç´ æ™´ã‚‰ã—ã„|æœ€é«˜)",
            r"(â™ª|â˜†|â˜…|ğŸ˜Š|ğŸ‘)",
        ]

        # ãƒã‚¬ãƒ†ã‚£ãƒ–ãªãƒˆãƒ¼ãƒ³
        negative_patterns = [
            r"(æ®‹å¿µ|å›°ã£ãŸ|å•é¡Œ|ã‚¨ãƒ©ãƒ¼|å¤±æ•—|ã ã‚|ãƒ€ãƒ¡)",
            r"(ğŸ˜¢|ğŸ˜|ğŸ’”)",
        ]

        # çš®è‚‰ãƒ»ãƒ¦ãƒ¼ãƒ¢ã‚¢
        sarcastic_patterns = [
            r"(ç¬‘|www|ï½—ï½—ï½—|è‰)",
            r"(\(ç¬‘\)|\(çˆ†\))",
        ]

        positive_count = sum(1 for p in positive_patterns if re.search(p, message))
        negative_count = sum(1 for p in negative_patterns if re.search(p, message))
        sarcastic_count = sum(1 for p in sarcastic_patterns if re.search(p, message))

        if positive_count > negative_count and positive_count > sarcastic_count:
            return DetectedNuance(
                nuance_type=NuanceType.POSITIVE,
                confidence=0.65 + (positive_count * 0.1),
                indicators=["ãƒã‚¸ãƒ†ã‚£ãƒ–è¡¨ç¾"],
                reasoning="ãƒã‚¸ãƒ†ã‚£ãƒ–ãªãƒˆãƒ¼ãƒ³ã‚’æ¤œå‡º",
            )
        elif negative_count > positive_count and negative_count > sarcastic_count:
            return DetectedNuance(
                nuance_type=NuanceType.NEGATIVE,
                confidence=0.65 + (negative_count * 0.1),
                indicators=["ãƒã‚¬ãƒ†ã‚£ãƒ–è¡¨ç¾"],
                reasoning="ãƒã‚¬ãƒ†ã‚£ãƒ–ãªãƒˆãƒ¼ãƒ³ã‚’æ¤œå‡º",
            )
        elif sarcastic_count > 0:
            return DetectedNuance(
                nuance_type=NuanceType.HUMOROUS,
                confidence=0.6 + (sarcastic_count * 0.1),
                indicators=["ãƒ¦ãƒ¼ãƒ¢ã‚¢è¡¨ç¾"],
                reasoning="ãƒ¦ãƒ¼ãƒ¢ã‚¢ã®ã‚ã‚‹ãƒˆãƒ¼ãƒ³ã‚’æ¤œå‡º",
            )

        return None

    # =========================================================================
    # æ–‡è„ˆè£œæ­£
    # =========================================================================

    def _apply_context_correction(
        self,
        emotions: List[DetectedEmotion],
        urgency: Optional[DetectedUrgency],
        context: DeepUnderstandingInput,
    ) -> Tuple[List[DetectedEmotion], Optional[DetectedUrgency]]:
        """
        æ–‡è„ˆã‚’è€ƒæ…®ã—ã¦æ„Ÿæƒ…ãƒ»ç·Šæ€¥åº¦ã‚’è£œæ­£
        """
        # ç›´è¿‘ã®ä¼šè©±ã®æ„Ÿæƒ…ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’è€ƒæ…®
        if context.recent_conversation:
            emotion_trend = self._analyze_emotion_trend(context.recent_conversation)

            if emotion_trend:
                # çªç„¶ã®æ„Ÿæƒ…å¤‰åŒ–ã¯ä¿¡é ¼åº¦ã‚’ä¸‹ã’ã‚‹
                for emotion in emotions:
                    if emotion.category.value != emotion_trend:
                        emotion.confidence *= 0.9

        # ã‚¿ã‚¹ã‚¯ã®çŠ¶æ³ã‚’è€ƒæ…®
        if context.recent_tasks:
            # æœªå®Œäº†ã‚¿ã‚¹ã‚¯ãŒå¤šã„å ´åˆã¯ã‚¹ãƒˆãƒ¬ã‚¹ã‚’å¼·åŒ–
            incomplete_count = sum(
                1 for task in context.recent_tasks
                if task.get("status") != "done"
            )
            if incomplete_count >= 3:
                # ã‚¹ãƒˆãƒ¬ã‚¹æ„Ÿæƒ…ãŒã‚ã‚‹å ´åˆã¯å¼·åŒ–
                for emotion in emotions:
                    if emotion.category == EmotionCategory.STRESSED:
                        emotion.intensity = min(emotion.intensity * 1.2, 1.0)
                        emotion.confidence = min(emotion.confidence * 1.1, 0.95)

        return emotions, urgency

    def _analyze_emotion_trend(
        self,
        recent_conversation: List[Dict[str, Any]],
    ) -> Optional[str]:
        """
        ç›´è¿‘ã®ä¼šè©±ã‹ã‚‰æ„Ÿæƒ…ã®ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’åˆ†æ
        """
        emotion_counts: Dict[str, int] = {}

        for msg in recent_conversation[-5:]:
            content = msg.get("content", "")
            # ç°¡æ˜“çš„ãªæ„Ÿæƒ…æ¤œå‡º
            for emotion_value, indicators in EMOTION_INDICATORS.items():
                keywords = indicators.get("keywords", [])
                if any(kw in content for kw in keywords):
                    emotion_counts[emotion_value] = emotion_counts.get(emotion_value, 0) + 1

        if emotion_counts:
            return max(emotion_counts, key=emotion_counts.get)

        return None

    # =========================================================================
    # ãƒ˜ãƒ«ãƒ‘ãƒ¼ãƒ¡ã‚½ãƒƒãƒ‰
    # =========================================================================

    def _select_primary_emotion(
        self,
        emotions: List[DetectedEmotion],
    ) -> Optional[DetectedEmotion]:
        """
        ä¸»è¦ãªæ„Ÿæƒ…ã‚’é¸æŠ
        """
        if not emotions:
            return None

        # ä¿¡é ¼åº¦ã¨å¼·åº¦ã®çµ„ã¿åˆã‚ã›ã§é¸æŠ
        return max(emotions, key=lambda e: e.confidence * e.intensity)

    def _generate_summary(
        self,
        emotions: List[DetectedEmotion],
        urgency: Optional[DetectedUrgency],
        nuances: List[DetectedNuance],
    ) -> str:
        """
        æ„Ÿæƒ…èª­ã¿å–ã‚Šã®ã‚µãƒãƒªãƒ¼ã‚’ç”Ÿæˆ
        """
        parts = []

        if emotions:
            primary = max(emotions, key=lambda e: e.confidence)
            emotion_names = {
                EmotionCategory.HAPPY: "å–œã³",
                EmotionCategory.EXCITED: "èˆˆå¥®ãƒ»æœŸå¾…",
                EmotionCategory.GRATEFUL: "æ„Ÿè¬",
                EmotionCategory.FRUSTRATED: "å›°æƒ‘ãƒ»ã‚¤ãƒ©ã‚¤ãƒ©",
                EmotionCategory.ANXIOUS: "ä¸å®‰",
                EmotionCategory.ANGRY: "æ€’ã‚Š",
                EmotionCategory.STRESSED: "ã‚¹ãƒˆãƒ¬ã‚¹",
                EmotionCategory.CONFUSED: "å›°æƒ‘",
                EmotionCategory.NEUTRAL: "ä¸­ç«‹",
            }
            emotion_name = emotion_names.get(primary.category, primary.category.value)
            intensity_desc = "å¼·ã„" if primary.intensity > 0.7 else "ã‚„ã‚„" if primary.intensity > 0.4 else "è»½ã„"
            parts.append(f"{intensity_desc}{emotion_name}ã‚’æ„Ÿã˜ã¦ã„ã¾ã™")

        if urgency and urgency.level in (UrgencyLevel.CRITICAL, UrgencyLevel.VERY_HIGH, UrgencyLevel.HIGH):
            urgency_names = {
                UrgencyLevel.CRITICAL: "éå¸¸ã«æ€¥ã„ã§ã„ã‚‹æ§˜å­",
                UrgencyLevel.VERY_HIGH: "æ€¥ã„ã§ã„ã‚‹æ§˜å­",
                UrgencyLevel.HIGH: "ã‚„ã‚„æ€¥ã„ã§ã„ã‚‹æ§˜å­",
            }
            parts.append(urgency_names.get(urgency.level, ""))

        if nuances:
            for nuance in nuances[:2]:
                if nuance.nuance_type == NuanceType.FORMAL:
                    parts.append("ä¸å¯§ãªå£èª¿")
                elif nuance.nuance_type == NuanceType.CASUAL:
                    parts.append("ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«ãªå£èª¿")
                elif nuance.nuance_type == NuanceType.CERTAINTY_LOW:
                    parts.append("ç¢ºä¿¡ãŒä½ãã†")

        return "ã€".join(parts) if parts else "ç‰¹ã«å¼·ã„æ„Ÿæƒ…ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ"

    def _calculate_overall_confidence(
        self,
        emotions: List[DetectedEmotion],
        urgency: Optional[DetectedUrgency],
        nuances: List[DetectedNuance],
    ) -> float:
        """
        å…¨ä½“ã®ä¿¡é ¼åº¦ã‚’è¨ˆç®—
        """
        confidences = []

        for emotion in emotions:
            confidences.append(emotion.confidence)

        if urgency:
            confidences.append(urgency.confidence)

        for nuance in nuances:
            confidences.append(nuance.confidence)

        if not confidences:
            return 0.5

        return sum(confidences) / len(confidences)

    def _elapsed_ms(self, start_time: float) -> int:
        """çµŒéæ™‚é–“ã‚’ãƒŸãƒªç§’ã§è¿”ã™"""
        return int((time.time() - start_time) * 1000)


# =============================================================================
# ãƒ•ã‚¡ã‚¯ãƒˆãƒªãƒ¼é–¢æ•°
# =============================================================================

def create_emotion_reader() -> EmotionReader:
    """
    EmotionReaderã‚’ä½œæˆ

    Returns:
        EmotionReader: æ„Ÿæƒ…èª­ã¿å–ã‚Šã‚¨ãƒ³ã‚¸ãƒ³
    """
    return EmotionReader()


# =============================================================================
# ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
# =============================================================================

__all__ = [
    "EmotionReader",
    "create_emotion_reader",
]
