# proactive-monitor/main.py
"""
Phase 2K: èƒ½å‹•çš„ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚° Cloud Function

ã‚½ã‚¦ãƒ«ãã‚“ãŒè‡ªåˆ†ã‹ã‚‰å£°ã‚’ã‹ã‘ã‚‹æ©Ÿèƒ½ã€‚
Cloud Schedulerã‹ã‚‰å®šæœŸå®Ÿè¡Œã•ã‚Œã‚‹ã€‚

ãƒˆãƒªã‚¬ãƒ¼æ¡ä»¶:
1. ç›®æ¨™æ”¾ç½®: 7æ—¥é–“æ›´æ–°ãªã—
2. ã‚¿ã‚¹ã‚¯å±±ç©ã¿: 5ä»¶ä»¥ä¸Šé…å»¶
3. æ„Ÿæƒ…å¤‰åŒ–: ãƒã‚¬ãƒ†ã‚£ãƒ–ç¶™ç¶š3æ—¥
4. è³ªå•æ”¾ç½®: 24æ™‚é–“æœªå›ç­”
5. ç›®æ¨™é”æˆ: ãŠç¥ã„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
6. é•·æœŸä¸åœ¨: 14æ—¥ä»¥ä¸Š

ã€CLAUDE.mdé‰„å‰‡1bæº–æ‹ ã€‘
v1.1.0: è„³çµŒç”±ã§ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç”Ÿæˆã™ã‚‹ã‚ˆã†ã«æ”¹ä¿®
- ProactiveMonitorã¯è„³ã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç”Ÿæˆã‚’ä¾é ¼
- è„³ãŒè¨˜æ†¶ã‚’å‚ç…§ã—ã€çŠ¶æ³ã‚’ç†è§£ã—ã€é©åˆ‡ãªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç”Ÿæˆ

Author: Claude Opus 4.5
Created: 2026-01-27
Updated: 2026-01-29 (è„³çµ±åˆ)
"""

import asyncio
from flask import Flask, request as flask_request, jsonify
import logging
import os
from datetime import datetime

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ç’°å¢ƒå¤‰æ•°
# Cloud Runç”¨ Flask ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
app = Flask(__name__)

USE_PROACTIVE_MONITOR = os.environ.get("USE_PROACTIVE_MONITOR", "false").lower() == "true"
PROACTIVE_DRY_RUN = os.environ.get("PROACTIVE_DRY_RUN", "true").lower() == "true"
USE_BRAIN_FOR_PROACTIVE = os.environ.get("USE_BRAIN_FOR_PROACTIVE", "true").lower() == "true"


def get_sync_pool():
    """åŒæœŸãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒ—ãƒ¼ãƒ«ã‚’å–å¾—

    ProactiveMonitor / BrainMemoryAccess / SoulkunBrain ã¯å…¨ã¦
    pool.connect() ã‚’ sync ã§ä½¿ç”¨ã™ã‚‹ãŸã‚ã€sync Engine ãŒå¿…è¦ã€‚
    AsyncEngine ã‚’æ¸¡ã™ã¨ _get_active_users ç­‰ã§ TypeError ã«ãªã‚‹ã€‚
    """
    try:
        from lib.db import get_db_pool
        return get_db_pool()
    except Exception as e:
        logger.error(f"Failed to get sync DB pool: {e}")
        return None


async def send_chatwork_message(room_id: str, message: str) -> bool:
    """ChatWorkã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡"""
    try:
        from lib.chatwork import send_message
        result = send_message(room_id, message)
        return result is not None
    except Exception as e:
        logger.error(f"Failed to send ChatWork message: {e}")
        return False


async def create_brain_for_proactive(pool):
    """
    Proactive Monitorç”¨ã®è„³ã‚’ä½œæˆ

    CLAUDE.mdé‰„å‰‡1bæº–æ‹ : èƒ½å‹•çš„å‡ºåŠ›ã‚‚è„³ãŒç”Ÿæˆ
    è„³ã¯ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç”Ÿæˆã«å¿…è¦ãªæœ€å°é™ã®æ©Ÿèƒ½ã‚’æŒã¤
    """
    if not USE_BRAIN_FOR_PROACTIVE:
        logger.warning(
            "[ProactiveMonitor] USE_BRAIN_FOR_PROACTIVE is disabled. "
            "Using fallback templates (CLAUDE.md violation)."
        )
        return None

    try:
        from lib.brain.core import SoulkunBrain
        from lib.brain.memory_access import BrainMemoryAccess

        # çµ„ç¹”IDã‚’å–å¾—ï¼ˆç’°å¢ƒå¤‰æ•° > ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ï¼‰
        org_id = os.environ.get(
            "SOULKUN_ORG_ID", "5f98365f-e7c5-4f48-9918-7fe9aabae5df"
        )

        # è¨˜æ†¶å±¤ã‚’ä½œæˆ
        memory_access = BrainMemoryAccess(pool=pool, org_id=org_id)

        # è„³ã‚’ä½œæˆï¼ˆæœ€å°é™ã®è¨­å®šï¼‰
        brain = SoulkunBrain(
            pool=pool,
            org_id=org_id,
            handlers={},  # Proactiveã§ã¯ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ä¸è¦
            capabilities={},  # Proactiveã§ã¯capabilitiesä¸è¦
            get_ai_response_func=None,  # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç”Ÿæˆã«ã¯LLMä¸è¦ï¼ˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ™ãƒ¼ã‚¹ï¼‰
            firestore_db=None,
        )

        # è¨˜æ†¶å±¤ã‚’è¨­å®š
        brain.memory_access = memory_access

        logger.info("[ProactiveMonitor] Brain created for proactive message generation")
        return brain

    except Exception as e:
        logger.warning(
            f"[ProactiveMonitor] Failed to create brain: {e}. "
            "Using fallback templates."
        )
        return None


async def _try_generate_daily_log(pool) -> str:
    """
    æ—¥æ¬¡ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆï¼ˆJST 9:00å°ã®æœ€åˆã®1å›ã®ã¿å®Ÿè¡Œï¼‰

    Phase 2-B: æ¯æœã€å‰æ—¥ã®æ´»å‹•ã‚µãƒãƒªãƒ¼ã‚’ç”Ÿæˆã—ã¦ãƒ­ã‚°ã«è¨˜éŒ²ã™ã‚‹ã€‚
    CLAUDE.mdé‰„å‰‡1b: è„³ã®æ´»å‹•è¨˜éŒ²ã®é€æ˜æ€§å‘ä¸Šã€‚

    Note: DailyLogGeneratorã¯åŒæœŸpoolã‚’ä½¿ç”¨ã™ã‚‹ãŸã‚ã€
    get_db_pool()ã§åŒæœŸç‰ˆã‚³ãƒã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ¼ãƒ«ã‚’å–å¾—ã™ã‚‹ã€‚
    """
    from datetime import timezone, timedelta
    jst_now = datetime.now(timezone(timedelta(hours=9)))

    if jst_now.hour != 9:
        return "skipped_not_9am"

    try:
        from lib.brain.daily_log import DailyLogGenerator
        from lib.db import get_db_pool

        org_id = os.environ.get("SOULKUN_ORG_ID", "5f98365f-e7c5-4f48-9918-7fe9aabae5df")
        sync_pool = get_db_pool()  # åŒæœŸãƒ—ãƒ¼ãƒ«ï¼ˆDailyLogGeneratorã¯åŒæœŸDBæ“ä½œï¼‰
        generator = DailyLogGenerator(pool=sync_pool, org_id=org_id)
        activity = await asyncio.to_thread(generator.generate)  # åŒæœŸå‡¦ç†ã‚’ã‚¹ãƒ¬ãƒƒãƒ‰ã§å®Ÿè¡Œ
        logger.info(
            f"[DailyLog] Generated: {activity.target_date} "
            f"conversations={activity.total_conversations} "
            f"users={activity.unique_users}"
        )
        return "generated"
    except Exception as e:
        logger.warning(f"[DailyLog] Generation failed (non-critical): {e}")
        return "error"


async def _try_outcome_learning_batch() -> dict:
    """
    Phase 2F: çµæœã‹ã‚‰ã®å­¦ç¿’ â€” ãƒãƒƒãƒå‡¦ç†

    æœªæ¤œå‡ºã‚¢ã‚¦ãƒˆã‚«ãƒ ã®æ¤œçŸ¥ + ãƒ‘ã‚¿ãƒ¼ãƒ³æŠ½å‡º + è‡ªå‹•æ˜‡æ ¼ã‚’è¡Œã†ã€‚
    æ¯å›ã®å®šæœŸå®Ÿè¡Œã§å‘¼ã³å‡ºã•ã‚Œã‚‹ã€‚ã‚¨ãƒ©ãƒ¼æ™‚ã¯ãƒ­ã‚°ã®ã¿ã§ç¶šè¡Œã€‚

    Note: DailyLogGeneratorã¨åŒæ§˜ã€åŒæœŸDBãƒ—ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹ã€‚
    """
    try:
        from lib.brain.outcome_learning import create_outcome_learning
        from lib.db import get_db_pool

        org_id = os.environ.get("SOULKUN_ORG_ID", "5f98365f-e7c5-4f48-9918-7fe9aabae5df")
        outcome_learning = create_outcome_learning(org_id)
        sync_pool = get_db_pool()

        def _sync_batch():
            with sync_pool.connect() as conn:
                # 1. æœªæ¤œå‡ºã‚¢ã‚¦ãƒˆã‚«ãƒ ã®å‡¦ç†
                processed = outcome_learning.process_pending_outcomes(conn)

                # 2. ãƒ‘ã‚¿ãƒ¼ãƒ³æŠ½å‡ºï¼ˆ30æ—¥åˆ†ï¼‰
                patterns = outcome_learning.extract_patterns(conn, days=30, save=True)

                # 3. æ˜‡æ ¼å¯èƒ½ãƒ‘ã‚¿ãƒ¼ãƒ³ã®è‡ªå‹•æ˜‡æ ¼
                promotable = outcome_learning.find_promotable_patterns(conn)
                promoted_count = 0
                for p in promotable:
                    learning_id = outcome_learning.promote_pattern_to_learning(conn, p.id)
                    if learning_id:
                        promoted_count += 1

                return {
                    "processed_outcomes": processed,
                    "patterns_extracted": len(patterns),
                    "patterns_promoted": promoted_count,
                }

        result = await asyncio.to_thread(_sync_batch)
        logger.info("[OutcomeLearning] Batch complete: %s", result)
        return result
    except Exception as e:
        logger.warning("[OutcomeLearning] Batch failed: %s", type(e).__name__)
        return {"error": type(e).__name__}


async def _try_cost_budget_alert(pool) -> str:
    """
    æœˆæ¬¡äºˆç®—ã‚¢ãƒ©ãƒ¼ãƒˆï¼ˆJST 9:00å°ã«å®Ÿè¡Œï¼‰

    ä»Šæœˆã®AIã‚³ã‚¹ãƒˆãŒäºˆç®—ã®80%ã¾ãŸã¯100%ã‚’è¶…ãˆã¦ã„ãŸã‚‰ã€ChatWorkã«é€šçŸ¥ã™ã‚‹ã€‚
    é‡è¤‡é˜²æ­¢: alert_80pct_sent_at / alert_100pct_sent_at ãŒè¨˜éŒ²æ¸ˆã¿ãªã‚‰å†é€ã—ãªã„ã€‚
    ç¿Œæœˆã¯æ–°ã—ã„ãƒ¬ã‚³ãƒ¼ãƒ‰ãŒä½œã‚‰ã‚Œã‚‹ãŸã‚ã€è‡ªå‹•çš„ã«ãƒªã‚»ãƒƒãƒˆã•ã‚Œã‚‹ã€‚
    """
    from datetime import timezone, timedelta
    jst_now = datetime.now(timezone(timedelta(hours=9)))

    if jst_now.hour != 9:
        return "skipped_not_9am"

    try:
        from sqlalchemy import text as sa_text

        org_id = os.environ.get("SOULKUN_ORG_ID", "5f98365f-e7c5-4f48-9918-7fe9aabae5df")
        alert_room_id = os.environ.get("ALERT_ROOM_ID", "")
        if not alert_room_id:
            logger.warning("[CostAlert] ALERT_ROOM_ID not set, skipping")
            return "skipped_no_room"

        year_month = jst_now.strftime("%Y-%m")

        def _query():
            with pool.connect() as conn:
                result = conn.execute(
                    sa_text("""
                        SELECT total_cost_jpy, budget_jpy,
                               alert_80pct_sent_at, alert_100pct_sent_at
                        FROM ai_monthly_cost_summary
                        WHERE organization_id = :org_id
                          AND year_month = :year_month
                        LIMIT 1
                    """),
                    {"org_id": org_id, "year_month": year_month},
                )
                return result.fetchone()

        row = await asyncio.to_thread(_query)
        if row is None:
            return "skipped_no_data"

        total_cost = float(row[0] or 0)
        budget = float(row[1]) if row[1] is not None else None
        alert_80pct_sent_at = row[2]
        alert_100pct_sent_at = row[3]

        if budget is None or budget <= 0:
            return "skipped_no_budget"

        usage_pct = total_cost / budget * 100

        if usage_pct < 80:
            logger.info(
                "[CostAlert] Usage %.1f%% â€” below threshold, no alert", usage_pct
            )
            return "ok"

        # é€ä¿¡ãŒå¿…è¦ãªã‚¢ãƒ©ãƒ¼ãƒˆã‚’åˆ¤å®šï¼ˆé‡è¤‡é˜²æ­¢ï¼‰
        send_80 = usage_pct >= 80 and alert_80pct_sent_at is None
        send_100 = usage_pct >= 100 and alert_100pct_sent_at is None

        if not send_80 and not send_100:
            logger.info(
                "[CostAlert] Usage %.1f%% â€” alerts already sent this month, skipping",
                usage_pct,
            )
            return "already_sent"

        time_str = jst_now.strftime("%Y-%m-%d %H:%M JST")
        sent_any = False

        # 80%ã‚¢ãƒ©ãƒ¼ãƒˆï¼ˆäºˆç®—è­¦å‘Šï¼‰â€” 100%æœªæº€ã®å ´åˆã®ã¿é€ä¿¡ï¼ˆ100%è¶…éæ™‚ã¯ä¸‹ã®é‡å¤§ã‚¢ãƒ©ãƒ¼ãƒˆã§å¯¾å¿œï¼‰
        if send_80 and usage_pct < 100:
            message = (
                f"[info][title]âš ï¸ äºˆç®—è­¦å‘Š â€” ä»Šæœˆã®AIã‚³ã‚¹ãƒˆ[/title]"
                f"ä½¿ç”¨ç‡: {usage_pct:.1f}%\n"
                f"ä»Šæœˆã®ã‚³ã‚¹ãƒˆ: Â¥{total_cost:,.0f}\n"
                f"æœˆé–“äºˆç®—: Â¥{budget:,.0f}\n"
                f"å¯¾è±¡æœˆ: {year_month}\n"
                f"æ¤œçŸ¥æ™‚åˆ»: {time_str}[/info]"
            )
            await send_chatwork_message(alert_room_id, message)

            def _update_80():
                with pool.connect() as conn:
                    conn.execute(
                        sa_text("""
                            UPDATE ai_monthly_cost_summary
                               SET alert_80pct_sent_at = NOW()
                             WHERE organization_id = :org_id
                               AND year_month = :year_month
                        """),
                        {"org_id": org_id, "year_month": year_month},
                    )
                    conn.commit()

            await asyncio.to_thread(_update_80)
            logger.info(
                "[CostAlert] 80%% alert sent: %.1f%% (Â¥%,.0f / Â¥%,.0f)",
                usage_pct, total_cost, budget,
            )
            sent_any = True

        # 100%ã‚¢ãƒ©ãƒ¼ãƒˆï¼ˆäºˆç®—è¶…éï¼‰
        if send_100:
            message = (
                f"[info][title]ğŸš¨ äºˆç®—è¶…é â€” ä»Šæœˆã®AIã‚³ã‚¹ãƒˆ[/title]"
                f"ä½¿ç”¨ç‡: {usage_pct:.1f}%\n"
                f"ä»Šæœˆã®ã‚³ã‚¹ãƒˆ: Â¥{total_cost:,.0f}\n"
                f"æœˆé–“äºˆç®—: Â¥{budget:,.0f}\n"
                f"å¯¾è±¡æœˆ: {year_month}\n"
                f"æ¤œçŸ¥æ™‚åˆ»: {time_str}[/info]"
            )
            await send_chatwork_message(alert_room_id, message)

            def _update_100():
                with pool.connect() as conn:
                    conn.execute(
                        sa_text("""
                            UPDATE ai_monthly_cost_summary
                               SET alert_80pct_sent_at = COALESCE(alert_80pct_sent_at, NOW()),
                                   alert_100pct_sent_at = NOW()
                             WHERE organization_id = :org_id
                               AND year_month = :year_month
                        """),
                        {"org_id": org_id, "year_month": year_month},
                    )
                    conn.commit()

            await asyncio.to_thread(_update_100)
            logger.info(
                "[CostAlert] 100%% alert sent: %.1f%% (Â¥%,.0f / Â¥%,.0f)",
                usage_pct, total_cost, budget,
            )
            sent_any = True

        return "sent" if sent_any else "already_sent"

    except Exception as e:
        logger.warning("[CostAlert] Failed (non-critical): %s", type(e).__name__)
        return "error"


async def run_proactive_monitor():
    """èƒ½å‹•çš„ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã‚’å®Ÿè¡Œ"""
    from lib.brain.proactive import create_proactive_monitor

    pool = get_sync_pool()
    if not pool:
        logger.error("[ProactiveMonitor] No database pool available")
        return {"status": "error", "message": "No database pool"}

    # CLAUDE.mdé‰„å‰‡1b: è„³ã‚’ä½œæˆã—ã¦ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç”Ÿæˆã«ä½¿ç”¨
    brain = await create_brain_for_proactive(pool)

    # ãƒ¢ãƒ‹ã‚¿ãƒ¼ä½œæˆï¼ˆè„³çµŒç”±ã§ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç”Ÿæˆï¼‰
    monitor = create_proactive_monitor(
        pool=pool,
        send_message_func=send_chatwork_message,
        dry_run=PROACTIVE_DRY_RUN,
        brain=brain,  # CLAUDE.mdé‰„å‰‡1bæº–æ‹ 
    )

    # å®Ÿè¡Œ
    logger.info(f"[ProactiveMonitor] Starting check (dry_run={PROACTIVE_DRY_RUN})")
    results = await monitor.check_and_act()

    # Phase 2-B: æ—¥æ¬¡ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆï¼ˆJST 9:00å°ã®ã¿ï¼‰
    daily_log_result = await _try_generate_daily_log(pool)

    # Phase 2-D: æœˆæ¬¡äºˆç®—ã‚¢ãƒ©ãƒ¼ãƒˆï¼ˆJST 9:00å°ã®ã¿ï¼‰
    cost_alert_result = await _try_cost_budget_alert(pool)

    # Phase 2F: çµæœã‹ã‚‰ã®å­¦ç¿’ â€” ãƒãƒƒãƒå‡¦ç†
    outcome_batch_result = await _try_outcome_learning_batch()

    # çµ±è¨ˆ
    total_users = len(results)
    total_triggers = sum(len(r.triggers_found) for r in results)
    total_actions = sum(len(r.actions_taken) for r in results)
    successful_actions = sum(
        len([a for a in r.actions_taken if a.success])
        for r in results
    )

    summary = {
        "status": "success",
        "timestamp": datetime.now().isoformat(),
        "dry_run": PROACTIVE_DRY_RUN,
        "brain_used": brain is not None,  # CLAUDE.mdé‰„å‰‡1bæº–æ‹ çŠ¶æ³
        "daily_log": daily_log_result,
        "cost_alert": cost_alert_result,
        "outcome_learning": outcome_batch_result,
        "users_checked": total_users,
        "triggers_found": total_triggers,
        "actions_taken": total_actions,
        "successful_actions": successful_actions,
    }

    logger.info(f"[ProactiveMonitor] Complete: {summary}")
    return summary


@app.route("/", methods=["POST", "GET"])
def proactive_monitor():
    """
    Cloud Run ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ

    HTTP ãƒˆãƒªã‚¬ãƒ¼ï¼ˆCloud Schedulerã‹ã‚‰å‘¼ã³å‡ºã—ï¼‰
    """
    logger.info("[ProactiveMonitor] Function triggered")

    # Feature Flag ãƒã‚§ãƒƒã‚¯
    if not USE_PROACTIVE_MONITOR:
        logger.info("[ProactiveMonitor] Feature flag is disabled, skipping")
        return {
            "status": "skipped",
            "reason": "USE_PROACTIVE_MONITOR is disabled",
        }, 200

    try:
        # éåŒæœŸå‡¦ç†ã‚’å®Ÿè¡Œ
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        result = loop.run_until_complete(run_proactive_monitor())
        loop.close()

        return result, 200

    except Exception as e:
        logger.error(f"[ProactiveMonitor] Error: {e}", exc_info=True)
        return {
            "status": "error",
            "message": type(e).__name__,
        }, 500


# Cloud Schedulerã‹ã‚‰ã®å‘¼ã³å‡ºã—ç”¨ï¼ˆPub/Sub push subscriptionçµŒç”±ï¼‰
@app.route("/scheduled", methods=["POST"])
def proactive_monitor_scheduled():
    """
    Cloud Scheduler ã‹ã‚‰ã® Pub/Sub push subscription ç”¨

    Cloud Run ã§ã¯ Cloud Event ã§ã¯ãªã HTTP POST ã§å—ã‘å–ã‚‹
    """
    logger.info("[ProactiveMonitor] Scheduled trigger received")

    # Feature Flag ãƒã‚§ãƒƒã‚¯
    if not USE_PROACTIVE_MONITOR:
        logger.info("[ProactiveMonitor] Feature flag is disabled, skipping")
        return jsonify({"status": "skipped"}), 200

    try:
        # éåŒæœŸå‡¦ç†ã‚’å®Ÿè¡Œ
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        result = loop.run_until_complete(run_proactive_monitor())
        loop.close()

        logger.info(f"[ProactiveMonitor] Scheduled execution complete: {result}")
        return jsonify(result), 200

    except Exception as e:
        logger.error(f"[ProactiveMonitor] Scheduled execution error: {e}", exc_info=True)
        return jsonify({"status": "error", "message": type(e).__name__}), 500
