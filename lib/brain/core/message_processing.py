# lib/brain/core/message_processing.py
"""
SoulkunBrain ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

process_messageï¼ˆãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆï¼‰ã¨
_process_with_llm_brainï¼ˆLLM Brainå‡¦ç†ãƒ•ãƒ­ãƒ¼ï¼‰ã€
_synthesize_knowledge_answerï¼ˆãƒŠãƒ¬ãƒƒã‚¸å›ç­”åˆæˆï¼‰ã‚’å«ã‚€ã€‚
"""

import logging
import time
from datetime import datetime
from typing import Optional, Dict, Any

from lib.brain.models import (
    BrainContext,
    BrainResponse,
    HandlerResult,
    StateType,
)

from lib.brain.constants import (
    CANCEL_MESSAGE,
    ERROR_MESSAGE,
    SAVE_DECISION_LOGS,
)

from lib.brain.exceptions import BrainError

from lib.feature_flags import is_llm_brain_enabled

# Langfuseãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°
from lib.brain.langfuse_integration import (
    observe,
    update_current_trace,
    flush as langfuse_flush,
)

logger = logging.getLogger(__name__)


class MessageProcessingMixin:
    """SoulkunBrainãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‡¦ç†é–¢é€£ãƒ¡ã‚½ãƒƒãƒ‰ã‚’æä¾›ã™ã‚‹Mixin"""

    # =========================================================================
    # ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ
    # =========================================================================

    @observe(name="brain.process_message", capture_input=False, capture_output=False)
    async def process_message(
        self,
        message: str,
        room_id: str,
        account_id: str,
        sender_name: str,
    ) -> BrainResponse:
        """
        ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‡¦ç†ã—ã¦å¿œç­”ã‚’è¿”ã™

        ã“ã‚ŒãŒè„³ã®å”¯ä¸€ã®ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆã€‚
        å…¨ã¦ã®å…¥åŠ›ã¯ã“ã“ã‚’é€šã‚‹ã€‚

        Args:
            message: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            room_id: ChatWorkãƒ«ãƒ¼ãƒ ID
            account_id: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¢ã‚«ã‚¦ãƒ³ãƒˆID
            sender_name: é€ä¿¡è€…å

        Returns:
            BrainResponse: å‡¦ç†çµæœ
        """
        start_time = time.time()

        # Langfuseãƒˆãƒ¬ãƒ¼ã‚¹: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ»ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ã‚’è¨­å®š
        # CLAUDE.md 3-2 #8 / 9-4æº–æ‹ : PIIã‚’ãƒã‚¹ã‚­ãƒ³ã‚°ã—ã¦é€ä¿¡
        _masked_preview, _ = self.mask_pii(message[:50])
        update_current_trace(
            user_id=account_id,
            session_id=room_id,
            input={"message_preview": _masked_preview},
            tags=["brain", "process_message"],
        )

        # Phase 2E: åˆå›å‘¼ã³å‡ºã—æ™‚ã«æ°¸ç¶šåŒ–æ¸ˆã¿æ”¹å–„ã‚’å¾©å…ƒ
        if not self._initialized:
            self._initialized = True
            try:
                loaded = await self.learning_loop.load_persisted_improvements()
                if loaded > 0:
                    self._sync_learning_to_decision()
                    logger.info("[Phase2E] Loaded %d persisted improvements", loaded)
            except Exception as e:
                logger.warning("[Phase2E] Init load failed: %s", type(e).__name__)

        try:
            logger.debug("[DIAG] process_message START t=0.000s")
            logger.info(
                f"ğŸ§  Brain processing: room={room_id}, user={sender_name}, "
                f"message={message[:50]}..."
            )

            _flag = is_llm_brain_enabled()
            _brain_obj = self.llm_brain is not None
            llm_brain_enabled = _flag and _brain_obj
            logger.info(
                "ğŸ§  [DIAG] routing: flag=%s, brain_obj=%s, result=%s",
                _flag, "SET" if _brain_obj else "NONE", llm_brain_enabled,
            )

            # 1. è¨˜æ†¶å±¤: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå–å¾—ï¼ˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚‚æ¸¡ã—ã¦é–¢é€£çŸ¥è­˜ã‚’æ¤œç´¢ï¼‰
            if llm_brain_enabled:
                # LLM Brainãƒ‘ã‚¹ã§ã¯ContextBuilderãŒå¿…è¦æƒ…å ±ã‚’å–å¾—ã™ã‚‹ãŸã‚ã€
                # ã“ã“ã§ã¯æœ€å°ã®ãƒ¡ã‚¿æƒ…å ±ã®ã¿ä½œæˆã—ã¦DBã‚¯ã‚¨ãƒªã‚’é¿ã‘ã‚‹
                context = BrainContext(
                    organization_id=self.org_id,
                    room_id=room_id,
                    sender_name=sender_name,
                    sender_account_id=account_id,
                    timestamp=datetime.now(),
                )
            else:
                t0 = time.time()
                context = await self._get_context(
                    room_id=room_id,
                    user_id=account_id,
                    sender_name=sender_name,
                    message=message,
                )
                logger.debug("[DIAG] _get_context DONE t=%.3fs (took %.3fs)", time.time()-start_time, time.time()-t0)

            # 1.5 Phase 2D: CEOæ•™ãˆå‡¦ç†
            # CEOã‹ã‚‰ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãªã‚‰æ•™ãˆã‚’æŠ½å‡ºï¼ˆéåŒæœŸã§å®Ÿè¡Œï¼‰
            if self.memory_manager.is_ceo_user(account_id):
                self._fire_and_forget(
                    self.memory_manager.process_ceo_message_safely(
                        message, room_id, account_id, sender_name
                    )
                )

            # é–¢é€£ã™ã‚‹CEOæ•™ãˆã‚’ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«è¿½åŠ 
            if not llm_brain_enabled:
                t0 = time.time()
                ceo_context = await self.memory_manager.get_ceo_teachings_context(
                    message, account_id
                )
                if ceo_context:
                    context.ceo_teachings = ceo_context
                logger.debug("[DIAG] ceo_teachings DONE t=%.3fs (took %.3fs)", time.time()-start_time, time.time()-t0)

            # =========================================================
            # v10.50.0: LLM Brain ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°
            # Feature Flag `ENABLE_LLM_BRAIN` ãŒæœ‰åŠ¹ãªå ´åˆã€LLMè„³ã§å‡¦ç†
            # =========================================================
            if llm_brain_enabled:
                logger.debug("[DIAG] routing to LLM Brain t=%.3fs", time.time()-start_time)
                return await self._process_with_llm_brain(
                    message=message,
                    room_id=room_id,
                    account_id=account_id,
                    sender_name=sender_name,
                    context=context,
                    start_time=start_time,
                )

            # =========================================================
            # ä»¥ä¸‹ã¯å¾“æ¥ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒãƒ³ã‚°æ–¹å¼ï¼ˆLLM Brainç„¡åŠ¹æ™‚ï¼‰
            # =========================================================

            # 2. çŠ¶æ…‹ãƒã‚§ãƒƒã‚¯: ãƒãƒ«ãƒã‚¹ãƒ†ãƒƒãƒ—ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¸­ï¼Ÿ
            current_state = await self._get_current_state(room_id, account_id)

            # 2.1 ã‚­ãƒ£ãƒ³ã‚»ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼Ÿ
            if self._is_cancel_request(message) and current_state and current_state.is_active:
                await self._clear_state(room_id, account_id, "user_cancel")
                return BrainResponse(
                    message=CANCEL_MESSAGE,
                    action_taken="cancel_session",
                    success=True,
                    state_changed=True,
                    new_state="normal",
                    total_time_ms=self._elapsed_ms(start_time),
                )

            # 2.2 ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¸­ãªã‚‰ã€ãã®ãƒ•ãƒ­ãƒ¼ã‚’ç¶™ç¶šï¼ˆsession_orchestratorã«å§”è­²ï¼‰
            if current_state and current_state.is_active:
                return await self.session_orchestrator.continue_session(
                    message=message,
                    state=current_state,
                    context=context,
                    room_id=room_id,
                    account_id=account_id,
                    sender_name=sender_name,
                    start_time=start_time,
                )

            # 2.5 Ultimate Brain: æ€è€ƒé€£é–ã§äº‹å‰åˆ†æ
            thought_chain = None
            if self.use_chain_of_thought:
                thought_chain = self._analyze_with_thought_chain(
                    message=message,
                    context={
                        "state": current_state.state_type.value if current_state else "normal",
                        "topic": getattr(context, "topic", None),
                    }
                )
                # Phase 1-C: CoTãƒ­ã‚°ã®PIIãƒã‚¹ã‚­ãƒ³ã‚°ï¼ˆCLAUDE.md 8-4æº–æ‹ ï¼‰
                sanitized_intent, _ = self.mask_pii(str(thought_chain.final_intent))
                logger.info(
                    f"ğŸ”— Chain-of-Thought: input_type={thought_chain.input_type.value}, "
                    f"intent={sanitized_intent}, "
                    f"confidence={thought_chain.confidence:.2f}"
                )

            # 3. ç†è§£å±¤: æ„å›³ã‚’æ¨è«–ï¼ˆæ€è€ƒé€£é–ã®çµæœã‚’è€ƒæ…®ï¼‰
            understanding = await self._understand(
                message, context, thought_chain=thought_chain
            )

            # 4. åˆ¤æ–­å±¤: ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ±ºå®š
            decision = await self._decide(understanding, context)

            # v10.46.0: è¦³æ¸¬ãƒ­ã‚° - æ„å›³åˆ¤å®šï¼ˆè„³ãŒçµ±ä¸€ç®¡ç†ï¼‰
            self.observability.log_intent(
                intent=understanding.intent,
                route=decision.action,
                confidence=decision.confidence,
                account_id=account_id,
                raw_message=message,
            )

            # 4.1 ç¢ºèªãŒå¿…è¦ï¼Ÿ
            if decision.needs_confirmation:
                # ç¢ºèªçŠ¶æ…‹ã«é·ç§»
                await self._transition_to_state(
                    room_id=room_id,
                    user_id=account_id,
                    state_type=StateType.CONFIRMATION,
                    data={
                        "pending_action": decision.action,
                        "pending_params": decision.params,
                        "confirmation_options": decision.confirmation_options,
                        "confirmation_question": decision.confirmation_question,
                    },
                    timeout_minutes=5,
                )
                return BrainResponse(
                    message=decision.confirmation_question or "ç¢ºèªã•ã›ã¦ã»ã—ã„ã‚¦ãƒ«ğŸº",
                    action_taken="request_confirmation",
                    success=True,
                    awaiting_confirmation=True,
                    state_changed=True,
                    new_state="confirmation",
                    debug_info={
                        "pending_action": decision.action,
                        "confidence": decision.confidence,
                    },
                    total_time_ms=self._elapsed_ms(start_time),
                )

            # 5. å®Ÿè¡Œå±¤: ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ
            result = await self._execute(
                decision=decision,
                context=context,
                room_id=room_id,
                account_id=account_id,
                sender_name=sender_name,
            )

            # 5.5 Ultimate Brain: è‡ªå·±æ‰¹åˆ¤ã§å›ç­”å“è³ªã‚’ãƒã‚§ãƒƒã‚¯
            final_message = result.message
            critique_applied = False
            if self.use_self_critique and result.message:
                refined = self._critique_and_refine_response(
                    response=result.message,
                    original_message=message,
                    context={
                        "expected_topic": getattr(context, "topic", None),
                        "previous_response": getattr(context, "last_ai_response", None),
                    }
                )
                if refined.refinement_applied:
                    final_message = refined.refined
                    critique_applied = True
                    logger.info(
                        f"âœ¨ Self-Critique: {len(refined.improvements)} improvements applied, "
                        f"time={refined.refinement_time_ms:.1f}ms"
                    )

            # resultã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æ›´æ–°
            if critique_applied:
                result = HandlerResult(
                    success=result.success,
                    message=final_message,
                    data=result.data,
                    suggestions=result.suggestions,
                    update_state=result.update_state,
                )

            # v10.46.0: è¦³æ¸¬ãƒ­ã‚° - å®Ÿè¡Œçµæœï¼ˆè„³ãŒçµ±ä¸€ç®¡ç†ï¼‰
            self.observability.log_execution(
                action=decision.action,
                success=result.success,
                account_id=account_id,
                execution_time_ms=self._elapsed_ms(start_time),
                error_code=result.data.get("error_code") if result.data and not result.success else None,
            )

            # 5.8 Phase 2F: çµæœã‹ã‚‰ã®å­¦ç¿’ â€” ã‚¢ã‚¯ã‚·ãƒ§ãƒ³è¨˜éŒ²ï¼ˆfire-and-forgetï¼‰
            if getattr(self, '_trackable_actions', None) and decision.action in self._trackable_actions:
                self._fire_and_forget(
                    self._record_outcome_event(
                        action=decision.action,
                        target_account_id=account_id,
                        target_room_id=room_id,
                        action_params=decision.params,
                        context_snapshot={"intent": understanding.intent},
                    )
                )

            # 6. è¨˜æ†¶æ›´æ–°ï¼ˆéåŒæœŸã§å®Ÿè¡Œã€ã‚¨ãƒ©ãƒ¼ã¯ç„¡è¦–ï¼‰
            self._fire_and_forget(
                self.memory_manager.update_memory_safely(
                    message, result, context, room_id, account_id, sender_name
                )
            )

            # 7. åˆ¤æ–­ãƒ­ã‚°è¨˜éŒ²ï¼ˆéåŒæœŸã§å®Ÿè¡Œï¼‰
            if SAVE_DECISION_LOGS:
                self._fire_and_forget(
                    self.memory_manager.log_decision_safely(
                        message, understanding, decision, result, room_id, account_id
                    )
                )

            # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’æ§‹ç¯‰
            debug_info = {
                "understanding": {
                    "intent": understanding.intent,
                    "confidence": understanding.intent_confidence,
                },
                "decision": {
                    "action": decision.action,
                    "confidence": decision.confidence,
                },
            }

            # æ€è€ƒé€£é–ã®æƒ…å ±ã‚’è¿½åŠ 
            if thought_chain:
                debug_info["thought_chain"] = {
                    "input_type": thought_chain.input_type.value,
                    "final_intent": thought_chain.final_intent,
                    "confidence": thought_chain.confidence,
                    "analysis_time_ms": thought_chain.analysis_time_ms,
                }

            # è‡ªå·±æ‰¹åˆ¤ã®æƒ…å ±ã‚’è¿½åŠ 
            if critique_applied:
                debug_info["self_critique"] = {
                    "applied": True,
                    "improvements_count": len(refined.improvements) if refined else 0,
                }

            # v10.56.15: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ä¸è¶³æ™‚ã®çŠ¶æ…‹ä¿å­˜
            # update_stateãŒã‚ã‚‹å ´åˆã€çŠ¶æ…‹ã‚’DBã«ä¿å­˜ã—ã¦æ¬¡ã®å…¥åŠ›ã§æ–‡è„ˆã‚’ç¶­æŒ
            if result.update_state:
                try:
                    # ã‚¿ã‚¹ã‚¯ä½œæˆã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ä¸è¶³ã¯ TASK_PENDING çŠ¶æ…‹ã¨ã—ã¦ä¿å­˜
                    if decision.action == "chatwork_task_create":
                        # v10.56.16: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åã‚’registry.pyã¨çµ±ä¸€
                        # LLM/Handlerå…±é€š: task_body, assigned_to, limit_date, limit_time
                        params = decision.params or {}
                        task_data = {
                            "task_body": params.get("task_body", ""),
                            "assigned_to": params.get("assigned_to", ""),
                            "limit_date": params.get("limit_date", ""),
                            "limit_time": params.get("limit_time", ""),
                            "missing_items": ["task_body"] if not params.get("task_body") else [],
                            "sender_name": sender_name,
                        }

                        # PostgreSQLçŠ¶æ…‹ã‚’ä¿å­˜
                        await self._transition_to_state(
                            room_id=room_id,
                            user_id=account_id,
                            state_type=StateType.TASK_PENDING,
                            data={
                                "pending_action": decision.action,
                                "pending_params": params,
                                "task_data": task_data,  # Handlerå½¢å¼ã®ãƒ‡ãƒ¼ã‚¿ã‚‚ä¿å­˜
                                "reason": result.update_state.get("reason", "parameter_missing"),
                            },
                            timeout_minutes=10,
                        )

                        # Firestoreã«ã‚‚ä¿å­˜ï¼ˆhandle_pending_task_followupäº’æ›ï¼‰
                        try:
                            from services.task_actions import save_pending_task
                            save_pending_task(room_id, account_id, task_data)
                            logger.info(f"ğŸ“‹ TASK_PENDINGçŠ¶æ…‹ä¿å­˜ï¼ˆPG+Firestoreï¼‰: room={room_id}")
                        except ImportError:
                            logger.info(f"ğŸ“‹ TASK_PENDINGçŠ¶æ…‹ä¿å­˜ï¼ˆPGã®ã¿ï¼‰: room={room_id}")
                    else:
                        # ãã®ä»–ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã¯ CONFIRMATION çŠ¶æ…‹ã¨ã—ã¦ä¿å­˜
                        state_type_str = result.update_state.get("state_type", "confirmation")
                        state_type = StateType(state_type_str) if state_type_str in [e.value for e in StateType] else StateType.CONFIRMATION
                        await self._transition_to_state(
                            room_id=room_id,
                            user_id=account_id,
                            state_type=state_type,
                            data={
                                "pending_action": decision.action,
                                "pending_params": decision.params,
                                "reason": result.update_state.get("reason"),
                            },
                            timeout_minutes=5,
                        )
                except Exception as e:
                    logger.warning(f"çŠ¶æ…‹ä¿å­˜å¤±æ•—ï¼ˆå‡¦ç†ã¯ç¶™ç¶šï¼‰: {e}")

            return BrainResponse(
                message=result.message,
                action_taken=decision.action,
                action_params=decision.params,
                success=result.success,
                suggestions=result.suggestions,
                state_changed=result.update_state is not None,
                debug_info=debug_info,
                total_time_ms=self._elapsed_ms(start_time),
            )

        except BrainError as e:
            logger.error(f"Brain error: {e.to_dict()}")
            return BrainResponse(
                message=ERROR_MESSAGE,
                action_taken="error",
                success=False,
                debug_info={"error": e.to_dict()},
                total_time_ms=self._elapsed_ms(start_time),
            )
        except Exception as e:
            logger.exception(f"Unexpected error in brain: {type(e).__name__}")
            return BrainResponse(
                message=ERROR_MESSAGE,
                action_taken="error",
                success=False,
                debug_info={"error": type(e).__name__},
                total_time_ms=self._elapsed_ms(start_time),
            )
        finally:
            # Cloud Functions: ãƒªã‚¯ã‚¨ã‚¹ãƒˆçµ‚äº†å‰ã«Langfuseãƒˆãƒ¬ãƒ¼ã‚¹ã‚’ç¢ºå®Ÿã«é€ä¿¡
            langfuse_flush()

    # =========================================================================
    # v10.50.0 â†’ v11.0 Phase 3: LangGraph Brainå‡¦ç†
    # æ—§ _process_with_llm_brain() ã‚’ StateGraph ã«åˆ†è§£
    # è¨­è¨ˆæ›¸: docs/25_llm_native_brain_architecture.md
    # =========================================================================

    @observe(name="brain.llm_brain_flow", capture_input=False, capture_output=False)
    async def _process_with_llm_brain(
        self,
        message: str,
        room_id: str,
        account_id: str,
        sender_name: str,
        context: "BrainContext",
        start_time: float,
    ) -> BrainResponse:
        """
        LLM Brainï¼ˆClaude Opus 4.5ï¼‰ã§ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‡¦ç†

        Phase 3: LangGraph StateGraph ã«ã‚ˆã‚‹å‡¦ç†ã€‚
        å„ã‚¹ãƒ†ãƒƒãƒ—ã¯ lib/brain/graph/nodes/ ã«åˆ†é›¢ã€‚

        ã€ã‚°ãƒ©ãƒ•ãƒ•ãƒ­ãƒ¼ã€‘
        state_check â†’ build_context â†’ llm_inference â†’ guardian_check
            â†’ (block|confirm|text_only|execute) â†’ [synthesize] â†’ response

        Args:
            message: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            room_id: ChatWorkãƒ«ãƒ¼ãƒ ID
            account_id: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¢ã‚«ã‚¦ãƒ³ãƒˆID
            sender_name: é€ä¿¡è€…å
            context: æ—¢ã«å–å¾—æ¸ˆã¿ã®BrainContext
            start_time: å‡¦ç†é–‹å§‹æ™‚åˆ»

        Returns:
            BrainResponse: å‡¦ç†çµæœ
        """
        try:
            # Nullå®‰å…¨ãƒã‚§ãƒƒã‚¯
            if self.llm_context_builder is None:
                raise BrainError("LLM context builder is not initialized")
            if self.llm_brain is None:
                raise BrainError("LLM brain is not initialized")
            if self.llm_guardian is None:
                raise BrainError("LLM guardian is not initialized")
            if self.llm_state_manager is None:
                raise BrainError("LLM state manager is not initialized")

            logger.debug("[DIAG] _process_with_llm_brain START t=%.3fs", time.time()-start_time)

            # é…å»¶åˆæœŸåŒ–: ãƒ†ã‚¹ãƒˆç­‰ã§llm_brainãŒå¾Œã‹ã‚‰ã‚»ãƒƒãƒˆã•ã‚ŒãŸå ´åˆã«å¯¾å¿œ
            if self._brain_graph is None:
                self._init_brain_graph()
            if self._brain_graph is None:
                raise BrainError("Brain graph is not initialized")

            # LangGraphã®åˆæœŸçŠ¶æ…‹ã‚’æ§‹ç¯‰
            initial_state = {
                "message": message,
                "room_id": room_id,
                "account_id": account_id,
                "sender_name": sender_name,
                "start_time": start_time,
                "organization_id": self.org_id,
                "context": context,
            }

            # ã‚°ãƒ©ãƒ•ã‚’å®Ÿè¡Œ
            logger.debug("[DIAG] graph.ainvoke START t=%.3fs", time.time()-start_time)
            final_state = await self._brain_graph.ainvoke(initial_state)
            logger.debug("[DIAG] graph.ainvoke DONE t=%.3fs", time.time()-start_time)

            # ã‚°ãƒ©ãƒ•ãŒç”Ÿæˆã—ãŸãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¿”ã™
            response = final_state.get("response")
            if response is not None:
                return response

            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒè¨­å®šã•ã‚Œã¦ã„ãªã„å ´åˆï¼ˆé€šå¸¸ã¯ç™ºç”Ÿã—ãªã„ï¼‰
            logger.warning("ğŸ§  Graph completed without response")
            return BrainResponse(
                message="ãŠæ‰‹ä¼ã„ã§ãã‚‹ã“ã¨ã¯ã‚ã‚Šã¾ã™ã‹ã‚¦ãƒ«ï¼ŸğŸº",
                action_taken="graph_no_response",
                success=True,
                total_time_ms=self._elapsed_ms(start_time),
            )

        except Exception as e:
            logger.exception(f"LLM Brain error: {type(e).__name__}")

            logger.warning("ğŸ§  LLM Brain failed, no fallback available in this version")
            return BrainResponse(
                message="ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã‚¦ãƒ«ã€ã†ã¾ãå‡¦ç†ã§ãã¾ã›ã‚“ã§ã—ãŸã‚¦ãƒ«ğŸº",
                action_taken="llm_brain_error",
                success=False,
                debug_info={"error": type(e).__name__},
                total_time_ms=self._elapsed_ms(start_time),
            )

    async def _synthesize_knowledge_answer(
        self,
        search_data: Dict[str, Any],
        original_query: str,
    ) -> Optional[str]:
        """
        Brainå±¤ã§ãƒŠãƒ¬ãƒƒã‚¸æ¤œç´¢çµæœã‹ã‚‰å›ç­”ã‚’åˆæˆã™ã‚‹ï¼ˆPhase 3.5ï¼‰

        CLAUDE.md Â§1æº–æ‹ : å…¨å‡ºåŠ›ã¯è„³ã‚’é€šã‚‹ã€‚ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã¯ãƒ‡ãƒ¼ã‚¿å–å¾—ã®ã¿ã€
        å›ç­”ç”Ÿæˆã¯Brainï¼ˆLLM Brainï¼‰ãŒæ‹…å½“ã™ã‚‹ã€‚

        Args:
            search_data: ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ãŒè¿”ã—ãŸæ¤œç´¢ãƒ‡ãƒ¼ã‚¿
            original_query: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…ƒã®è³ªå•

        Returns:
            åˆæˆã•ã‚ŒãŸå›ç­”ãƒ†ã‚­ã‚¹ãƒˆã€ã¾ãŸã¯Noneï¼ˆã‚¨ãƒ©ãƒ¼æ™‚ï¼‰
        """
        if self.llm_brain is None:
            logger.warning("LLM Brain not available for knowledge synthesis")
            return None

        formatted_context = search_data.get("formatted_context", "")
        # ãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™ã‚’è€ƒæ…®ã—ã¦ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ‡ã‚Šè©°ã‚ï¼ˆç´„1000ãƒˆãƒ¼ã‚¯ãƒ³ç›¸å½“ï¼‰
        MAX_CONTEXT_CHARS = 4000
        if len(formatted_context) > MAX_CONTEXT_CHARS:
            formatted_context = formatted_context[:MAX_CONTEXT_CHARS] + "\n...(ä»¥ä¸‹çœç•¥)"
        source = search_data.get("source", "unknown")
        confidence = search_data.get("confidence", 0)
        source_note = search_data.get("source_note", "")

        system_prompt = f"""ã‚ãªãŸã¯ã€Œã‚½ã‚¦ãƒ«ãã‚“ã€ã§ã™ã€‚ä¼šç¤¾ã®çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã‹ã‚‰æƒ…å ±ã‚’å‚ç…§ã—ã¦å›ç­”ã—ã¾ã™ã€‚

ã€é‡è¦ãªãƒ«ãƒ¼ãƒ«ã€‘
1. æä¾›ã•ã‚ŒãŸå‚è€ƒæƒ…å ±ã«åŸºã¥ã„ã¦å›ç­”ã—ã¦ãã ã•ã„
2. æƒ…å ±æºã‚’æ˜ç¤ºã—ã¦ãã ã•ã„ï¼ˆä¾‹ï¼šã€Œå°±æ¥­è¦å‰‡ã«ã‚ˆã‚‹ã¨...ã€ã€Œç¤¾å†…ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ã§ã¯...ã€ï¼‰
3. å‚è€ƒæƒ…å ±ã«ãªã„å†…å®¹ã¯æ¨æ¸¬ã›ãšã€ã€Œãã®ç‚¹ã¯ç¢ºèªã§ãã¾ã›ã‚“ã§ã—ãŸã€ã¨ä¼ãˆã¦ãã ã•ã„
4. ã‚½ã‚¦ãƒ«ãã‚“ã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã‚’ä¿ã£ã¦ãã ã•ã„ï¼ˆèªå°¾ï¼šã€œã‚¦ãƒ«ã€æ™‚ã€…ğŸºã‚’ä½¿ã†ï¼‰
5. ç°¡æ½”ã«ã€ã‚ã‹ã‚Šã‚„ã™ãå›ç­”ã—ã¦ãã ã•ã„

ã€å‚è€ƒæƒ…å ±ã®å‡ºå…¸ã€‘
æ¤œç´¢æ–¹æ³•: {source}ï¼ˆ{"æ—§ã‚·ã‚¹ãƒ†ãƒ " if source == "legacy" else "Phase 3 Pineconeæ¤œç´¢"}ï¼‰
ä¿¡é ¼åº¦: {confidence:.2f}

ã€å‚è€ƒæƒ…å ±ã€‘
{formatted_context}
"""

        try:
            answer = await self.llm_brain.synthesize_text(
                system_prompt=system_prompt,
                user_message=f"è³ªå•: {original_query}",
            )

            if answer and source_note:
                answer += source_note

            return answer

        except Exception as e:
            logger.error(f"Knowledge synthesis error: {type(e).__name__}", exc_info=True)
            return None
