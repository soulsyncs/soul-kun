# lib/brain/dashboard.py
"""
Brain Observability ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£

è¨­è¨ˆæ›¸: docs/25_llm_native_brain_architecture.md ã‚»ã‚¯ã‚·ãƒ§ãƒ³15.2

ã€æ©Ÿèƒ½ã€‘
- æ—¥æ¬¡ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®å–å¾—
- ã‚¢ãƒ©ãƒ¼ãƒˆã®å–å¾—
- ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰æ–‡å­—åˆ—ç”Ÿæˆ
- ã‚³ã‚¹ãƒˆåˆ†æ

Author: Claude Opus 4.5
Created: 2026-01-31
"""

from dataclasses import dataclass, field
from datetime import datetime, date, timedelta
from decimal import Decimal
from typing import Optional, List, Dict, Any
import logging

logger = logging.getLogger(__name__)


# ç›£è¦–é–¾å€¤ï¼ˆè¨­è¨ˆæ›¸15.1æº–æ‹ ï¼‰
DEFAULT_THRESHOLDS = {
    "response_time_warning_ms": 3000,     # æ—©æœŸè­¦å‘Š: 3ç§’
    "response_time_critical_ms": 10000,   # è­¦å‘Š: 10ç§’
    "error_rate_warning": 0.03,           # æ—©æœŸè­¦å‘Š: 3%
    "error_rate_critical": 0.05,          # è­¦å‘Š: 5%
    "confirm_rate_info": 0.30,            # æƒ…å ±: 30%
    "block_rate_warning": 0.10,           # è­¦å‘Š: 10%
    "daily_cost_warning": 5000.0,         # è­¦å‘Š: 5,000å††
    "daily_cost_critical": 10000.0,       # è­¦å‘Š: 10,000å††
}


@dataclass
class DashboardMetrics:
    """ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ç”¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹"""
    organization_id: str
    metric_date: date

    # ä¼šè©±çµ±è¨ˆ
    total_conversations: int = 0
    unique_users: int = 0

    # å¿œç­”æ™‚é–“
    avg_response_time_ms: Optional[int] = None
    p50_response_time_ms: Optional[int] = None
    p95_response_time_ms: Optional[int] = None
    p99_response_time_ms: Optional[int] = None
    max_response_time_ms: Optional[int] = None

    # ç¢ºä¿¡åº¦
    avg_confidence: Optional[Decimal] = None
    min_confidence: Optional[Decimal] = None

    # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³åˆ†å¸ƒ
    tool_call_count: int = 0
    text_response_count: int = 0
    clarification_count: int = 0

    # Guardianåˆ¤å®šåˆ†å¸ƒ
    allow_count: int = 0
    confirm_count: int = 0
    block_count: int = 0

    # å®Ÿè¡Œçµæœ
    success_count: int = 0
    error_count: int = 0

    # ã‚³ã‚¹ãƒˆ
    total_input_tokens: int = 0
    total_output_tokens: int = 0
    total_cost_yen: Decimal = Decimal("0")

    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
    slow_request_count: int = 0

    @property
    def error_rate(self) -> float:
        """ã‚¨ãƒ©ãƒ¼ç‡ã‚’è¨ˆç®—"""
        if self.total_conversations == 0:
            return 0.0
        return (self.error_count / self.total_conversations) * 100

    @property
    def confirm_rate(self) -> float:
        """ç¢ºèªãƒ¢ãƒ¼ãƒ‰ç‡ã‚’è¨ˆç®—"""
        if self.total_conversations == 0:
            return 0.0
        return (self.confirm_count / self.total_conversations) * 100

    @property
    def block_rate(self) -> float:
        """ãƒ–ãƒ­ãƒƒã‚¯ç‡ã‚’è¨ˆç®—"""
        if self.total_conversations == 0:
            return 0.0
        return (self.block_count / self.total_conversations) * 100

    @property
    def avg_cost_per_conversation(self) -> Decimal:
        """ä¼šè©±ã‚ãŸã‚Šã®å¹³å‡ã‚³ã‚¹ãƒˆ"""
        if self.total_conversations == 0:
            return Decimal("0")
        return self.total_cost_yen / self.total_conversations

    def check_alerts(self, thresholds: Optional[Dict] = None) -> List[Dict[str, Any]]:
        """
        ã‚¢ãƒ©ãƒ¼ãƒˆæ¡ä»¶ã‚’ãƒã‚§ãƒƒã‚¯

        Returns:
            ã‚¢ãƒ©ãƒ¼ãƒˆã®ãƒªã‚¹ãƒˆ
        """
        if thresholds is None:
            thresholds = DEFAULT_THRESHOLDS

        alerts = []

        # å¿œç­”æ™‚é–“ãƒã‚§ãƒƒã‚¯
        if self.avg_response_time_ms:
            if self.avg_response_time_ms > thresholds["response_time_critical_ms"]:
                alerts.append({
                    "category": "response_time",
                    "level": "warning",
                    "message": f"å¹³å‡å¿œç­”æ™‚é–“ãŒ{self.avg_response_time_ms}msã§ã™ï¼ˆé–¾å€¤: {thresholds['response_time_critical_ms']}msï¼‰",
                    "value": self.avg_response_time_ms,
                    "threshold": thresholds["response_time_critical_ms"],
                })
            elif self.avg_response_time_ms > thresholds["response_time_warning_ms"]:
                alerts.append({
                    "category": "response_time",
                    "level": "info",
                    "message": f"å¹³å‡å¿œç­”æ™‚é–“ãŒ{self.avg_response_time_ms}msã§ã™ï¼ˆæ—©æœŸè­¦å‘Š: {thresholds['response_time_warning_ms']}msï¼‰",
                    "value": self.avg_response_time_ms,
                    "threshold": thresholds["response_time_warning_ms"],
                })

        # ã‚¨ãƒ©ãƒ¼ç‡ãƒã‚§ãƒƒã‚¯
        error_rate_decimal = self.error_rate / 100
        if error_rate_decimal > thresholds["error_rate_critical"]:
            alerts.append({
                "category": "error_rate",
                "level": "warning",
                "message": f"ã‚¨ãƒ©ãƒ¼ç‡ãŒ{self.error_rate:.1f}%ã§ã™ï¼ˆé–¾å€¤: {thresholds['error_rate_critical']*100}%ï¼‰",
                "value": self.error_rate,
                "threshold": thresholds["error_rate_critical"] * 100,
            })
        elif error_rate_decimal > thresholds["error_rate_warning"]:
            alerts.append({
                "category": "error_rate",
                "level": "info",
                "message": f"ã‚¨ãƒ©ãƒ¼ç‡ãŒ{self.error_rate:.1f}%ã§ã™ï¼ˆæ—©æœŸè­¦å‘Š: {thresholds['error_rate_warning']*100}%ï¼‰",
                "value": self.error_rate,
                "threshold": thresholds["error_rate_warning"] * 100,
            })

        # ç¢ºèªãƒ¢ãƒ¼ãƒ‰ç‡ãƒã‚§ãƒƒã‚¯
        confirm_rate_decimal = self.confirm_rate / 100
        if confirm_rate_decimal > thresholds["confirm_rate_info"]:
            alerts.append({
                "category": "confirm_rate",
                "level": "info",
                "message": f"ç¢ºèªãƒ¢ãƒ¼ãƒ‰ç‡ãŒ{self.confirm_rate:.1f}%ã§ã™ï¼ˆé–¾å€¤: {thresholds['confirm_rate_info']*100}%ï¼‰",
                "value": self.confirm_rate,
                "threshold": thresholds["confirm_rate_info"] * 100,
            })

        # ãƒ–ãƒ­ãƒƒã‚¯ç‡ãƒã‚§ãƒƒã‚¯
        block_rate_decimal = self.block_rate / 100
        if block_rate_decimal > thresholds["block_rate_warning"]:
            alerts.append({
                "category": "block_rate",
                "level": "warning",
                "message": f"ãƒ–ãƒ­ãƒƒã‚¯ç‡ãŒ{self.block_rate:.1f}%ã§ã™ï¼ˆé–¾å€¤: {thresholds['block_rate_warning']*100}%ï¼‰",
                "value": self.block_rate,
                "threshold": thresholds["block_rate_warning"] * 100,
            })

        # ã‚³ã‚¹ãƒˆãƒã‚§ãƒƒã‚¯
        if self.total_cost_yen > Decimal(str(thresholds["daily_cost_critical"])):
            alerts.append({
                "category": "daily_cost",
                "level": "critical",
                "message": f"æ—¥æ¬¡ã‚³ã‚¹ãƒˆãŒ{self.total_cost_yen:,.0f}å††ã§ã™ï¼ˆé–¾å€¤: {thresholds['daily_cost_critical']:,.0f}å††ï¼‰",
                "value": float(self.total_cost_yen),
                "threshold": thresholds["daily_cost_critical"],
            })
        elif self.total_cost_yen > Decimal(str(thresholds["daily_cost_warning"])):
            alerts.append({
                "category": "daily_cost",
                "level": "warning",
                "message": f"æ—¥æ¬¡ã‚³ã‚¹ãƒˆãŒ{self.total_cost_yen:,.0f}å††ã§ã™ï¼ˆé–¾å€¤: {thresholds['daily_cost_warning']:,.0f}å††ï¼‰",
                "value": float(self.total_cost_yen),
                "threshold": thresholds["daily_cost_warning"],
            })

        return alerts

    def to_dashboard_string(self) -> str:
        """
        ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰è¡¨ç¤ºç”¨ã®æ–‡å­—åˆ—ã‚’ç”Ÿæˆ

        è¨­è¨ˆæ›¸15.2ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«æº–æ‹ 
        """
        lines = [
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”",
            "  ã‚½ã‚¦ãƒ«ãã‚“è„³ãƒ¢ãƒ‹ã‚¿ãƒ¼",
            f"  {self.metric_date} ãƒ¬ãƒãƒ¼ãƒˆ",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”",
            "",
            "ğŸ“Š ä»Šæ—¥ã®çµ±è¨ˆ",
            f"  ç·ä¼šè©±æ•°:     {self.total_conversations:,}",
            f"  ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒ¦ãƒ¼ã‚¶ãƒ¼: {self.unique_users:,}",
        ]

        if self.avg_response_time_ms:
            lines.append(f"  å¹³å‡å¿œç­”æ™‚é–“: {self.avg_response_time_ms / 1000:.1f}ç§’")

        if self.avg_confidence:
            lines.append(f"  ç¢ºä¿¡åº¦å¹³å‡:   {self.avg_confidence}")

        lines.extend([
            "",
            "ğŸ›¡ï¸ Guardianåˆ¤å®š",
            f"  è¨±å¯(allow):  {self.allow_count:,} ({self.allow_count / max(self.total_conversations, 1) * 100:.1f}%)",
            f"  ç¢ºèª(confirm): {self.confirm_count:,} ({self.confirm_rate:.1f}%)",
            f"  æ‹’å¦(block):  {self.block_count:,} ({self.block_rate:.1f}%)",
            "",
            "ğŸ’° ã‚³ã‚¹ãƒˆ",
            f"  æœ¬æ—¥ã‚³ã‚¹ãƒˆ:   Â¥{self.total_cost_yen:,.0f}",
            f"  å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³: {self.total_input_tokens:,}",
            f"  å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³: {self.total_output_tokens:,}",
        ])

        if self.total_conversations > 0:
            lines.append(f"  ä¼šè©±ã‚ãŸã‚Š:   Â¥{self.avg_cost_per_conversation:.2f}")

        # ã‚¢ãƒ©ãƒ¼ãƒˆ
        alerts = self.check_alerts()
        if alerts:
            lines.extend([
                "",
                "âš ï¸ ã‚¢ãƒ©ãƒ¼ãƒˆ",
            ])
            for alert in alerts:
                level_icon = {
                    "critical": "ğŸ”´",
                    "warning": "ğŸŸ¡",
                    "info": "ğŸ”µ",
                }.get(alert["level"], "âšª")
                lines.append(f"  {level_icon} [{alert['level'].upper()}] {alert['message']}")

        lines.extend([
            "",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”",
        ])

        return "\n".join(lines)


class BrainDashboard:
    """
    Brain Observability ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¹

    DBæ¥ç¶šã‚’ä½¿ç”¨ã—ã¦ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’å–å¾—ã—ã€ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚’ç”Ÿæˆ
    """

    def __init__(self, pool: Optional[Any] = None):
        """
        Args:
            pool: asyncpg connection pool (asyncpg.Pool or compatible)
        """
        self.pool = pool

    async def get_daily_metrics(
        self,
        organization_id: str,
        target_date: Optional[date] = None
    ) -> DashboardMetrics:
        """
        æŒ‡å®šæ—¥ã®æ—¥æ¬¡ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’å–å¾—

        Args:
            organization_id: çµ„ç¹”ID
            target_date: å¯¾è±¡æ—¥ï¼ˆçœç•¥æ™‚ã¯ä»Šæ—¥ï¼‰

        Returns:
            DashboardMetrics
        """
        if target_date is None:
            target_date = date.today()

        if self.pool is None:
            # ãƒ—ãƒ¼ãƒ«ãŒãªã„å ´åˆã¯ç©ºã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¿”ã™
            return DashboardMetrics(
                organization_id=organization_id,
                metric_date=target_date,
            )

        try:
            async with self.pool.acquire() as conn:
                # ã¾ãšé›†è¨ˆæ¸ˆã¿ãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰å–å¾—ã‚’è©¦ã¿ã‚‹
                row = await conn.fetchrow("""
                SELECT
                    total_conversations,
                    unique_users,
                    avg_response_time_ms,
                    p50_response_time_ms,
                    p95_response_time_ms,
                    p99_response_time_ms,
                    max_response_time_ms,
                    avg_confidence,
                    min_confidence,
                    tool_call_count,
                    text_response_count,
                    clarification_count,
                    allow_count,
                    confirm_count,
                    block_count,
                    success_count,
                    error_count,
                    total_input_tokens,
                    total_output_tokens,
                    total_cost_yen,
                    slow_request_count
                FROM brain_daily_metrics
                WHERE organization_id = $1 AND metric_date = $2
                """, organization_id, target_date)

                if row:
                    return DashboardMetrics(
                        organization_id=organization_id,
                        metric_date=target_date,
                        total_conversations=row['total_conversations'] or 0,
                        unique_users=row['unique_users'] or 0,
                        avg_response_time_ms=row['avg_response_time_ms'],
                        p50_response_time_ms=row['p50_response_time_ms'],
                        p95_response_time_ms=row['p95_response_time_ms'],
                        p99_response_time_ms=row['p99_response_time_ms'],
                        max_response_time_ms=row['max_response_time_ms'],
                        avg_confidence=row['avg_confidence'],
                        min_confidence=row['min_confidence'],
                        tool_call_count=row['tool_call_count'] or 0,
                        text_response_count=row['text_response_count'] or 0,
                        clarification_count=row['clarification_count'] or 0,
                        allow_count=row['allow_count'] or 0,
                        confirm_count=row['confirm_count'] or 0,
                        block_count=row['block_count'] or 0,
                        success_count=row['success_count'] or 0,
                        error_count=row['error_count'] or 0,
                        total_input_tokens=row['total_input_tokens'] or 0,
                        total_output_tokens=row['total_output_tokens'] or 0,
                        total_cost_yen=row['total_cost_yen'] or Decimal("0"),
                        slow_request_count=row['slow_request_count'] or 0,
                    )

                # é›†è¨ˆãƒ†ãƒ¼ãƒ–ãƒ«ã«ãªã„å ´åˆã¯ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é›†è¨ˆ
                row = await conn.fetchrow("""
                    SELECT
                    COUNT(*) AS total_conversations,
                    COUNT(DISTINCT user_id) AS unique_users,
                    AVG(total_response_time_ms)::INTEGER AS avg_response_time_ms,
                    PERCENTILE_CONT(0.50) WITHIN GROUP (ORDER BY total_response_time_ms)::INTEGER AS p50_response_time_ms,
                    PERCENTILE_CONT(0.95) WITHIN GROUP (ORDER BY total_response_time_ms)::INTEGER AS p95_response_time_ms,
                    PERCENTILE_CONT(0.99) WITHIN GROUP (ORDER BY total_response_time_ms)::INTEGER AS p99_response_time_ms,
                    MAX(total_response_time_ms) AS max_response_time_ms,
                    AVG(confidence_overall)::DECIMAL(3,2) AS avg_confidence,
                    MIN(confidence_overall)::DECIMAL(3,2) AS min_confidence,
                    COUNT(*) FILTER (WHERE output_type = 'tool_call') AS tool_call_count,
                    COUNT(*) FILTER (WHERE output_type = 'text_response') AS text_response_count,
                    COUNT(*) FILTER (WHERE output_type = 'clarification_needed') AS clarification_count,
                    COUNT(*) FILTER (WHERE guardian_action = 'allow') AS allow_count,
                    COUNT(*) FILTER (WHERE guardian_action = 'confirm') AS confirm_count,
                    COUNT(*) FILTER (WHERE guardian_action = 'block') AS block_count,
                    COUNT(*) FILTER (WHERE execution_success = TRUE) AS success_count,
                    COUNT(*) FILTER (WHERE execution_success = FALSE) AS error_count,
                    COALESCE(SUM(input_tokens), 0)::BIGINT AS total_input_tokens,
                    COALESCE(SUM(output_tokens), 0)::BIGINT AS total_output_tokens,
                    COALESCE(SUM(estimated_cost_yen), 0)::DECIMAL(12,2) AS total_cost_yen,
                    COUNT(*) FILTER (WHERE total_response_time_ms > 10000) AS slow_request_count
                    FROM brain_observability_logs
                    WHERE organization_id = $1
                      AND DATE(created_at) = $2
                      AND environment = 'production'
                """, organization_id, target_date)

                return DashboardMetrics(
                    organization_id=organization_id,
                    metric_date=target_date,
                    total_conversations=row['total_conversations'] or 0,
                    unique_users=row['unique_users'] or 0,
                    avg_response_time_ms=row['avg_response_time_ms'],
                    p50_response_time_ms=row['p50_response_time_ms'],
                    p95_response_time_ms=row['p95_response_time_ms'],
                    p99_response_time_ms=row['p99_response_time_ms'],
                    max_response_time_ms=row['max_response_time_ms'],
                    avg_confidence=row['avg_confidence'],
                    min_confidence=row['min_confidence'],
                    tool_call_count=row['tool_call_count'] or 0,
                    text_response_count=row['text_response_count'] or 0,
                    clarification_count=row['clarification_count'] or 0,
                    allow_count=row['allow_count'] or 0,
                    confirm_count=row['confirm_count'] or 0,
                    block_count=row['block_count'] or 0,
                    success_count=row['success_count'] or 0,
                    error_count=row['error_count'] or 0,
                    total_input_tokens=row['total_input_tokens'] or 0,
                    total_output_tokens=row['total_output_tokens'] or 0,
                    total_cost_yen=row['total_cost_yen'] or Decimal("0"),
                    slow_request_count=row['slow_request_count'] or 0,
                )
        except Exception as e:
            logger.error(f"Failed to get daily metrics for {organization_id}: {type(e).__name__}")
            return DashboardMetrics(
                organization_id=organization_id,
                metric_date=target_date,
            )

    async def get_weekly_summary(
        self,
        organization_id: str,
        end_date: Optional[date] = None
    ) -> Dict[str, Any]:
        """
        é€±æ¬¡ã‚µãƒãƒªãƒ¼ã‚’å–å¾—

        Args:
            organization_id: çµ„ç¹”ID
            end_date: çµ‚äº†æ—¥ï¼ˆçœç•¥æ™‚ã¯ä»Šæ—¥ï¼‰

        Returns:
            é€±æ¬¡ã‚µãƒãƒªãƒ¼ã®è¾æ›¸
        """
        if end_date is None:
            end_date = date.today()

        start_date = end_date - timedelta(days=6)

        if self.pool is None:
            return {
                "organization_id": organization_id,
                "start_date": str(start_date),
                "end_date": str(end_date),
                "error": "No database pool available",
            }

        try:
            async with self.pool.acquire() as conn:
                row = await conn.fetchrow("""
                    SELECT
                        SUM(total_conversations) AS total_conversations,
                        SUM(unique_users) AS total_users,
                        AVG(avg_response_time_ms)::INTEGER AS avg_response_time_ms,
                        SUM(error_count)::DECIMAL / NULLIF(SUM(total_conversations), 0) * 100 AS avg_error_rate,
                        SUM(confirm_count)::DECIMAL / NULLIF(SUM(total_conversations), 0) * 100 AS avg_confirm_rate,
                        SUM(block_count)::DECIMAL / NULLIF(SUM(total_conversations), 0) * 100 AS avg_block_rate,
                        SUM(total_cost_yen) AS total_cost_yen,
                        COUNT(*) AS days_with_data
                    FROM brain_daily_metrics
                    WHERE organization_id = $1
                      AND metric_date BETWEEN $2 AND $3
                """, organization_id, start_date, end_date)

                return {
                    "organization_id": organization_id,
                    "start_date": str(start_date),
                    "end_date": str(end_date),
                    "total_conversations": row['total_conversations'] or 0,
                    "total_users": row['total_users'] or 0,
                    "avg_response_time_ms": row['avg_response_time_ms'],
                    "avg_error_rate": float(row['avg_error_rate']) if row['avg_error_rate'] else 0,
                    "avg_confirm_rate": float(row['avg_confirm_rate']) if row['avg_confirm_rate'] else 0,
                    "avg_block_rate": float(row['avg_block_rate']) if row['avg_block_rate'] else 0,
                    "total_cost_yen": float(row['total_cost_yen']) if row['total_cost_yen'] else 0,
                    "days_with_data": row['days_with_data'] or 0,
                }
        except Exception as e:
            logger.error(f"Failed to get weekly summary for {organization_id}: {type(e).__name__}")
            return {
                "organization_id": organization_id,
                "start_date": str(start_date),
                "end_date": str(end_date),
                "error": type(e).__name__,
            }

    async def get_monthly_cost(
        self,
        organization_id: str,
        year: int,
        month: int
    ) -> Dict[str, Any]:
        """
        æœˆæ¬¡ã‚³ã‚¹ãƒˆã‚’å–å¾—

        Args:
            organization_id: çµ„ç¹”ID
            year: å¹´
            month: æœˆ

        Returns:
            æœˆæ¬¡ã‚³ã‚¹ãƒˆã®è¾æ›¸
        """
        if self.pool is None:
            return {
                "organization_id": organization_id,
                "year": year,
                "month": month,
                "error": "No database pool available",
            }

        try:
            async with self.pool.acquire() as conn:
                row = await conn.fetchrow("""
                    SELECT
                        SUM(total_conversations) AS total_conversations,
                        SUM(total_input_tokens) AS total_input_tokens,
                        SUM(total_output_tokens) AS total_output_tokens,
                        SUM(total_cost_yen) AS total_cost_yen
                    FROM brain_daily_metrics
                    WHERE organization_id = $1
                      AND EXTRACT(YEAR FROM metric_date) = $2
                      AND EXTRACT(MONTH FROM metric_date) = $3
                """, organization_id, year, month)

                total_conversations = row['total_conversations'] or 0
                total_cost = row['total_cost_yen'] or Decimal("0")

                return {
                    "organization_id": organization_id,
                    "year": year,
                    "month": month,
                    "total_conversations": total_conversations,
                    "total_input_tokens": row['total_input_tokens'] or 0,
                    "total_output_tokens": row['total_output_tokens'] or 0,
                    "total_cost_yen": float(total_cost),
                    "avg_cost_per_conversation": float(total_cost / total_conversations) if total_conversations > 0 else 0,
                }
        except Exception as e:
            logger.error(f"Failed to get monthly cost for {organization_id}: {type(e).__name__}")
            return {
                "organization_id": organization_id,
                "year": year,
                "month": month,
                "error": type(e).__name__,
            }


def create_dashboard(pool: Optional[Any] = None) -> BrainDashboard:
    """
    ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ

    Args:
        pool: asyncpg connection pool

    Returns:
        BrainDashboard
    """
    return BrainDashboard(pool=pool)
