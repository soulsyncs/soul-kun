# lib/brain/core.py
"""
ã‚½ã‚¦ãƒ«ãã‚“ã®è„³ - ã‚³ã‚¢ã‚¯ãƒ©ã‚¹

ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã«ã¯ã€è„³ã®ä¸­å¤®å‡¦ç†è£…ç½®ï¼ˆSoulkunBrainï¼‰ã‚’å®šç¾©ã—ã¾ã™ã€‚
å…¨ã¦ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã¯ã€ã“ã®ã‚¯ãƒ©ã‚¹ã®process_message()ãƒ¡ã‚½ãƒƒãƒ‰ã‚’é€šã˜ã¦å‡¦ç†ã•ã‚Œã¾ã™ã€‚

è¨­è¨ˆæ›¸: docs/13_brain_architecture.md

ã€7ã¤ã®é‰„å‰‡ã€‘
1. å…¨ã¦ã®å…¥åŠ›ã¯è„³ã‚’é€šã‚‹ï¼ˆãƒã‚¤ãƒ‘ã‚¹ãƒ«ãƒ¼ãƒˆç¦æ­¢ï¼‰
2. è„³ã¯å…¨ã¦ã®è¨˜æ†¶ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã‚‹
3. è„³ãŒåˆ¤æ–­ã—ã€æ©Ÿèƒ½ã¯å®Ÿè¡Œã™ã‚‹ã ã‘
4. æ©Ÿèƒ½æ‹¡å¼µã—ã¦ã‚‚è„³ã®æ§‹é€ ã¯å¤‰ã‚ã‚‰ãªã„
5. ç¢ºèªã¯è„³ã®è²¬å‹™
6. çŠ¶æ…‹ç®¡ç†ã¯è„³ãŒçµ±ä¸€ç®¡ç†
7. é€Ÿåº¦ã‚ˆã‚Šæ­£ç¢ºæ€§ã‚’å„ªå…ˆ
"""

import asyncio
import logging
import time
from datetime import datetime, timedelta
from typing import Optional, Dict, Any, List, Callable, Tuple, Union

from sqlalchemy import text

from lib.brain.models import (
    BrainContext,
    BrainResponse,
    UnderstandingResult,
    DecisionResult,
    HandlerResult,
    ConversationState,
    ConfirmationRequest,
    ActionCandidate,
    StateType,
    ConfidenceLevel,
    ConversationMessage,
    # Phase 2D: CEO Learning
    CEOTeachingContext,
    CEOTeaching,
    # Phase 2K: Proactive Messageï¼ˆé‰„å‰‡1bæº–æ‹ ï¼‰
    ProactiveMessageResult,
    ProactiveMessageTone,
    # v10.54: çµ±ä¸€ç‰ˆãƒ‰ãƒ¡ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ï¼ˆSoT: lib/brain/models.pyï¼‰
    PersonInfo,
    TaskInfo,
    GoalInfo,
    InsightInfo,
    # v10.54.4: ä¼šè©±è¦ç´„ãƒ»å—œå¥½ãƒ‡ãƒ¼ã‚¿ãƒ»çŸ¥è­˜ãƒãƒ£ãƒ³ã‚¯
    SummaryData,
    PreferenceData,
    KnowledgeChunk,
)

from lib.brain.constants import (
    CANCEL_KEYWORDS,
    CONFIRMATION_THRESHOLD,
    AUTO_EXECUTE_THRESHOLD,
    SESSION_TIMEOUT_MINUTES,
    DANGEROUS_ACTIONS,
    CANCEL_MESSAGE,
    ERROR_MESSAGE,
    UNDERSTANDING_TIMEOUT_SECONDS,
    DECISION_TIMEOUT_SECONDS,
    EXECUTION_TIMEOUT_SECONDS,
    SAVE_DECISION_LOGS,
)

from lib.brain.exceptions import (
    BrainError,
    UnderstandingError,
    DecisionError,
    ExecutionError,
    StateError,
    MemoryAccessError,
    HandlerNotFoundError,
    HandlerTimeoutError,
)
from lib.brain.memory_flush import AutoMemoryFlusher
from lib.brain.hybrid_search import HybridSearcher
from lib.brain.memory_sanitizer import mask_pii
from lib.brain.state_manager import BrainStateManager
from lib.brain.memory_access import (
    BrainMemoryAccess,
    ConversationMessage as MemoryConversationMessage,
    ConversationSummaryData,
    UserPreferenceData,
    # PersonInfo, TaskInfo, GoalInfo ã¯ models.py ã‹ã‚‰ import æ¸ˆã¿ï¼ˆSoTï¼‰
    KnowledgeInfo,
    InsightInfo as MemoryInsightInfo,  # models.py ã® InsightInfo ã¨åŒºåˆ¥
)
from lib.brain.understanding import BrainUnderstanding
from lib.brain.decision import BrainDecision
from lib.brain.execution import BrainExecution
from lib.brain.learning import BrainLearning
from lib.brain.learning_loop import create_learning_loop
from lib.brain.memory_manager import BrainMemoryManager
from lib.brain.session_orchestrator import SessionOrchestrator
from lib.brain.authorization_gate import AuthorizationGate, AuthorizationResult

# Ultimate Brain - Phase 1: Chain-of-Thought & Self-Critique
from lib.brain.chain_of_thought import ChainOfThought, create_chain_of_thought
from lib.brain.self_critique import SelfCritique, create_self_critique

# Phase 2D: CEO Learning & Guardian
from lib.brain.ceo_learning import (
    CEOLearningService,
    CEO_ACCOUNT_IDS,
)
from lib.brain.guardian import (
    GuardianService,
    GuardianActionResult,
    GuardianActionType,
)

# v10.42.0 P3: Value Authority Layer
from lib.brain.value_authority import (
    ValueAuthority,
    ValueAuthorityResult,
    ValueDecision,
    create_value_authority,
)

# v10.43.0 P4: Memory Authority Layer
from lib.brain.memory_authority import (
    MemoryAuthority,
    MemoryAuthorityResult,
    MemoryDecision,
    create_memory_authority,
)

# v10.43.1 P4: Memory Authority Observation Logger
from lib.brain.memory_authority_logger import (
    get_memory_authority_logger,
)
from lib.brain.ceo_teaching_repository import CEOTeachingRepository

# Phase 2L: ExecutionExcellenceï¼ˆå®Ÿè¡ŒåŠ›å¼·åŒ–ï¼‰
from lib.brain.execution_excellence import (
    ExecutionExcellence,
    create_execution_excellence,
    is_execution_excellence_enabled,
    FEATURE_FLAG_EXECUTION_EXCELLENCE,
)
from lib.feature_flags import is_execution_excellence_enabled as ff_execution_excellence_enabled
from lib.feature_flags import is_llm_brain_enabled

# v10.50.0: LLM Brainï¼ˆLLMå¸¸é§å‹è„³ - 25ç« ï¼‰
from lib.brain.tool_converter import get_tools_for_llm
from lib.brain.context_builder import ContextBuilder
from lib.brain.deep_understanding.emotion_reader import create_emotion_reader
from lib.brain.llm_brain import LLMBrain, LLMBrainResult
from lib.brain.guardian_layer import GuardianLayer, GuardianAction
from lib.brain.state_manager import LLMStateManager, LLMSessionMode, LLMPendingAction

# v10.46.0: è¦³æ¸¬æ©Ÿèƒ½ï¼ˆObservability Layerï¼‰
from lib.brain.observability import (
    BrainObservability,
    ContextType,
    create_observability,
)

logger = logging.getLogger(__name__)


# =============================================================================
# å¢ƒç•Œå‹æ¤œè¨¼ãƒ˜ãƒ«ãƒ‘ãƒ¼ï¼ˆLLMå‡ºåŠ›ãƒ»APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®å‹å´©ã‚Œæ¤œå‡ºï¼‰
# =============================================================================


def _validate_llm_result_type(llm_result: Any, location: str) -> bool:
    """
    LLMBrainResultã®å‹ã‚’æ¤œè¨¼ã™ã‚‹

    Args:
        llm_result: æ¤œè¨¼å¯¾è±¡ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        location: æ¤œè¨¼ç®‡æ‰€ï¼ˆãƒ­ã‚°å‡ºåŠ›ç”¨ï¼‰

    Returns:
        bool: æ¤œè¨¼æˆåŠŸãªã‚‰True

    Raises:
        TypeError: å‹ãŒä¸æ­£ãªå ´åˆ
    """
    from lib.brain.llm_brain import LLMBrainResult, ToolCall, ConfidenceScores

    if not isinstance(llm_result, LLMBrainResult):
        logger.error(
            f"[å¢ƒç•Œå‹æ¤œè¨¼ã‚¨ãƒ©ãƒ¼] {location}: "
            f"LLMBrainResult expected, got {type(llm_result).__name__}"
        )
        raise TypeError(
            f"LLMBrainResult expected at {location}, got {type(llm_result).__name__}"
        )

    # confidenceã®å‹æ¤œè¨¼ï¼ˆã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‹æ•°å€¤ã‹ï¼‰
    if llm_result.confidence is not None:
        if not isinstance(llm_result.confidence, ConfidenceScores):
            logger.warning(
                f"[å¢ƒç•Œå‹æ¤œè¨¼è­¦å‘Š] {location}: "
                f"confidence is not ConfidenceScores: {type(llm_result.confidence).__name__}"
            )

    # tool_callsã®å‹æ¤œè¨¼
    if llm_result.tool_calls is not None:
        if not isinstance(llm_result.tool_calls, list):
            logger.error(
                f"[å¢ƒç•Œå‹æ¤œè¨¼ã‚¨ãƒ©ãƒ¼] {location}: "
                f"tool_calls should be list, got {type(llm_result.tool_calls).__name__}"
            )
            raise TypeError(
                f"tool_calls should be list at {location}, got {type(llm_result.tool_calls).__name__}"
            )
        for i, tc in enumerate(llm_result.tool_calls):
            if not isinstance(tc, ToolCall):
                logger.error(
                    f"[å¢ƒç•Œå‹æ¤œè¨¼ã‚¨ãƒ©ãƒ¼] {location}: "
                    f"tool_calls[{i}] is not ToolCall: {type(tc).__name__}"
                )
                raise TypeError(
                    f"tool_calls[{i}] should be ToolCall at {location}, got {type(tc).__name__}"
                )

    return True


def _extract_confidence_value(raw_confidence: Any, location: str) -> float:
    """
    confidenceã‹ã‚‰æ•°å€¤ã‚’å®‰å…¨ã«æŠ½å‡ºã™ã‚‹

    LLMã®å‡ºåŠ›ã‚„APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã§confidenceãŒä»¥ä¸‹ã®å½¢å¼ã§æ¥ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹:
    - ConfidenceScoresã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼ˆ.overallå±æ€§ã‚’æŒã¤ï¼‰
    - æ•°å€¤ï¼ˆint, floatï¼‰
    - è¾æ›¸ï¼ˆ{"overall": 0.8}ï¼‰
    - None

    Args:
        raw_confidence: ç”Ÿã®confidenceå€¤
        location: æŠ½å‡ºç®‡æ‰€ï¼ˆãƒ­ã‚°å‡ºåŠ›ç”¨ï¼‰

    Returns:
        float: ç¢ºä¿¡åº¦ï¼ˆ0.0ã€œ1.0ï¼‰
    """
    from lib.brain.llm_brain import ConfidenceScores

    if raw_confidence is None:
        logger.debug(f"[å¢ƒç•Œå‹æ¤œè¨¼] {location}: confidence is None, using default 0.0")
        return 0.0

    # ConfidenceScoresã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
    if isinstance(raw_confidence, ConfidenceScores):
        return float(raw_confidence.overall)

    # hasattr ã§overallå±æ€§ã‚’æŒã¤ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼ˆãƒ€ãƒƒã‚¯ã‚¿ã‚¤ãƒ”ãƒ³ã‚°ï¼‰
    if hasattr(raw_confidence, 'overall'):
        overall = raw_confidence.overall
        if isinstance(overall, (int, float)):
            return float(overall)
        else:
            logger.warning(
                f"[å¢ƒç•Œå‹æ¤œè¨¼è­¦å‘Š] {location}: "
                f"confidence.overall is not numeric: {type(overall).__name__}"
            )
            return 0.0

    # æ•°å€¤
    if isinstance(raw_confidence, (int, float)):
        return float(raw_confidence)

    # è¾æ›¸
    if isinstance(raw_confidence, dict) and 'overall' in raw_confidence:
        overall = raw_confidence['overall']
        if isinstance(overall, (int, float)):
            return float(overall)
        else:
            logger.warning(
                f"[å¢ƒç•Œå‹æ¤œè¨¼è­¦å‘Š] {location}: "
                f"confidence['overall'] is not numeric: {type(overall).__name__}"
            )
            return 0.0

    # äºˆæœŸã—ãªã„å‹
    logger.error(
        f"[å¢ƒç•Œå‹æ¤œè¨¼ã‚¨ãƒ©ãƒ¼] {location}: "
        f"unexpected confidence type: {type(raw_confidence).__name__}, value={raw_confidence}"
    )
    return 0.0


def _safe_confidence_to_dict(raw_confidence: Any, location: str) -> Dict[str, Any]:
    """
    confidenceã‚’è¾æ›¸å½¢å¼ã«å®‰å…¨ã«å¤‰æ›ã™ã‚‹

    Args:
        raw_confidence: ç”Ÿã®confidenceå€¤
        location: å¤‰æ›ç®‡æ‰€ï¼ˆãƒ­ã‚°å‡ºåŠ›ç”¨ï¼‰

    Returns:
        Dict: ç¢ºä¿¡åº¦ã®è¾æ›¸å½¢å¼
    """
    from lib.brain.llm_brain import ConfidenceScores

    if raw_confidence is None:
        return {"overall": 0.0, "intent": 0.0, "parameters": 0.0}

    # ConfidenceScoresã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼ˆto_dictãƒ¡ã‚½ãƒƒãƒ‰ã‚’æŒã¤ï¼‰
    if isinstance(raw_confidence, ConfidenceScores):
        result: Dict[str, Any] = raw_confidence.to_dict()
        return result

    # to_dictãƒ¡ã‚½ãƒƒãƒ‰ã‚’æŒã¤ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼ˆãƒ€ãƒƒã‚¯ã‚¿ã‚¤ãƒ”ãƒ³ã‚°ï¼‰
    if hasattr(raw_confidence, 'to_dict') and callable(raw_confidence.to_dict):
        try:
            duck_result: Dict[str, Any] = raw_confidence.to_dict()
            return duck_result
        except Exception as e:
            logger.warning(
                f"[å¢ƒç•Œå‹æ¤œè¨¼è­¦å‘Š] {location}: "
                f"to_dict() failed: {type(e).__name__}"
            )
            return {"overall": _extract_confidence_value(raw_confidence, location)}

    # æ•°å€¤
    if isinstance(raw_confidence, (int, float)):
        return {"overall": float(raw_confidence)}

    # è¾æ›¸ï¼ˆãã®ã¾ã¾è¿”ã™ï¼‰
    if isinstance(raw_confidence, dict):
        return raw_confidence

    # äºˆæœŸã—ãªã„å‹
    logger.warning(
        f"[å¢ƒç•Œå‹æ¤œè¨¼è­¦å‘Š] {location}: "
        f"unexpected confidence type for dict conversion: {type(raw_confidence).__name__}"
    )
    return {"overall": 0.0}


class SoulkunBrain:
    """
    ã‚½ã‚¦ãƒ«ãã‚“ã®è„³ï¼ˆä¸­å¤®å‡¦ç†è£…ç½®ï¼‰

    å…¨ã¦ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‚’å—ã‘å–ã‚Šã€è¨˜æ†¶ã‚’å‚ç…§ã—ã€æ„å›³ã‚’ç†è§£ã—ã€
    é©åˆ‡ãªæ©Ÿèƒ½ã‚’é¸æŠã—ã¦å®Ÿè¡Œã™ã‚‹ã€‚

    ä½¿ç”¨ä¾‹:
        brain = SoulkunBrain(pool=db_pool, org_id="org_soulsyncs")
        response = await brain.process_message(
            message="è‡ªåˆ†ã®ã‚¿ã‚¹ã‚¯æ•™ãˆã¦",
            room_id="123456",
            account_id="7890",
            sender_name="èŠåœ°"
        )
    """

    def __init__(
        self,
        pool,
        org_id: str,
        handlers: Optional[Dict[str, Callable]] = None,
        capabilities: Optional[Dict[str, Dict]] = None,
        get_ai_response_func: Optional[Callable] = None,
        firestore_db=None,
    ):
        """
        Args:
            pool: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒ—ãƒ¼ãƒ«
            org_id: çµ„ç¹”ID
            handlers: ã‚¢ã‚¯ã‚·ãƒ§ãƒ³å â†’ ãƒãƒ³ãƒ‰ãƒ©ãƒ¼é–¢æ•°ã®ãƒãƒƒãƒ”ãƒ³ã‚°
            capabilities: SYSTEM_CAPABILITIESï¼ˆæ©Ÿèƒ½ã‚«ã‚¿ãƒ­ã‚°ï¼‰
            get_ai_response_func: AIå¿œç­”ç”Ÿæˆé–¢æ•°
            firestore_db: Firestore ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¼ˆä¼šè©±å±¥æ­´ç”¨ï¼‰
        """
        self.pool = pool
        self.org_id = org_id
        self.handlers = handlers or {}
        self.capabilities = capabilities or {}
        self.get_ai_response = get_ai_response_func
        self.firestore_db = firestore_db

        # Phase 1-A: è‡ªå‹•ãƒ¡ãƒ¢ãƒªãƒ•ãƒ©ãƒƒã‚·ãƒ¥
        memory_flusher = AutoMemoryFlusher(
            pool=pool,
            org_id=org_id,
            ai_client=get_ai_response_func,
        )

        # Phase 1-B: ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ï¼ˆPinecone/Embeddingã¯å¾Œã‹ã‚‰è¨­å®šå¯èƒ½ï¼‰
        hybrid_searcher = HybridSearcher(
            pool=pool,
            org_id=org_id,
        )

        # Phase 1-C: PIIãƒã‚¹ã‚­ãƒ³ã‚°é–¢æ•°ï¼ˆãƒ­ã‚°å‡ºåŠ›æ™‚ã«ä½¿ç”¨ï¼‰
        self.mask_pii = mask_pii

        # è¨˜æ†¶ã‚¢ã‚¯ã‚»ã‚¹å±¤ã®åˆæœŸåŒ–
        self.memory_access = BrainMemoryAccess(
            pool=pool,
            org_id=org_id,
            firestore_db=firestore_db,
            memory_flusher=memory_flusher,
            hybrid_searcher=hybrid_searcher,
        )

        # çŠ¶æ…‹ç®¡ç†å±¤ã®åˆæœŸåŒ–
        self.state_manager = BrainStateManager(
            pool=pool,
            org_id=org_id,
        )

        # ç†è§£å±¤ã®åˆæœŸåŒ–
        self.understanding = BrainUnderstanding(
            get_ai_response_func=get_ai_response_func,
            org_id=org_id,
            use_llm=True,  # LLMã‚’ä½¿ç”¨ï¼ˆæ›–æ˜§è¡¨ç¾ãŒã‚ã‚‹å ´åˆï¼‰
        )

        # åˆ¤æ–­å±¤ã®åˆæœŸåŒ–
        self.decision = BrainDecision(
            capabilities=capabilities,
            get_ai_response_func=get_ai_response_func,
            org_id=org_id,
            use_llm=False,  # ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹åˆ¤æ–­ï¼ˆé«˜é€Ÿï¼‰
        )

        # å®Ÿè¡Œå±¤ã®åˆæœŸåŒ–
        self.execution = BrainExecution(
            handlers=handlers,
            get_ai_response_func=get_ai_response_func,
            org_id=org_id,
            enable_suggestions=True,
            enable_retry=True,
        )

        # å­¦ç¿’å±¤ã®åˆæœŸåŒ–
        self.learning = BrainLearning(
            pool=pool,
            org_id=org_id,
            firestore_db=firestore_db,
            enable_logging=True,
            enable_learning=True,
        )

        # Phase 2E: å­¦ç¿’ãƒ«ãƒ¼ãƒ—ã®åˆæœŸåŒ–ï¼ˆãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯â†’åˆ¤æ–­æ”¹å–„ï¼‰
        self.learning_loop = create_learning_loop(
            pool=pool,
            organization_id=org_id,
        )

        # Phase 2D: CEO Learningå±¤ã®åˆæœŸåŒ–ï¼ˆmemory_manageråˆæœŸåŒ–å¾Œã«å‚ç…§ï¼‰
        self.ceo_teaching_repo = CEOTeachingRepository(
            pool=pool,
            organization_id=org_id,
        )
        self.ceo_learning = CEOLearningService(
            pool=pool,
            organization_id=org_id,
            llm_caller=get_ai_response_func,
        )
        self.guardian = GuardianService(
            pool=pool,
            organization_id=org_id,
            llm_caller=get_ai_response_func,
        )

        # è¨˜æ†¶ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã®åˆæœŸåŒ–ï¼ˆå­¦ç¿’ãƒ»CEO Learningçµ±æ‹¬ï¼‰
        self.memory_manager = BrainMemoryManager(
            learning=self.learning,
            ceo_learning=self.ceo_learning,
            organization_id=org_id,
        )

        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼ã®åˆæœŸåŒ–ï¼ˆãƒãƒ«ãƒã‚¹ãƒ†ãƒƒãƒ—ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†ï¼‰
        # æ³¨: _understand, _decide, _executeç­‰ã®ãƒ¡ã‚½ãƒƒãƒ‰ã¯å¾Œã§å®šç¾©ã•ã‚Œã‚‹ãŒã€
        # Pythonã§ã¯å‘¼ã³å‡ºã—æ™‚ã«è§£æ±ºã•ã‚Œã‚‹ã®ã§å•é¡Œãªã—
        self.session_orchestrator = SessionOrchestrator(
            handlers=self.handlers,  # v10.54.4: selfã‚’ä½¿ã£ã¦Noneã§ã¯ãªã„ã“ã¨ã‚’ä¿è¨¼
            state_manager=self.state_manager,
            understanding_func=self._understand,
            decision_func=self._decide,
            execution_func=self._execute,
            is_cancel_func=self._is_cancel_request,
            elapsed_ms_func=self._elapsed_ms,
        )

        # Ultimate Brain - Phase 1
        # æ€è€ƒé€£é–ã‚¨ãƒ³ã‚¸ãƒ³
        self.chain_of_thought = ChainOfThought(llm_client=None)

        # è‡ªå·±æ‰¹åˆ¤ã‚¨ãƒ³ã‚¸ãƒ³
        self.self_critique = SelfCritique(llm_client=None)

        # Ultimate Brainè¨­å®š
        self.use_chain_of_thought = True  # æ€è€ƒé€£é–ã‚’ä½¿ç”¨
        self.use_self_critique = True      # è‡ªå·±æ‰¹åˆ¤ã‚’ä½¿ç”¨

        # Phase 2L: ExecutionExcellenceï¼ˆå®Ÿè¡ŒåŠ›å¼·åŒ–ï¼‰
        self.execution_excellence: Optional[ExecutionExcellence] = None
        self._init_execution_excellence()

        # èªå¯ã‚²ãƒ¼ãƒˆã®åˆæœŸåŒ–ï¼ˆæ¨©é™ãƒã‚§ãƒƒã‚¯çµ±æ‹¬ï¼‰
        self.authorization_gate = AuthorizationGate(
            guardian=self.guardian,
            execution_excellence=self.execution_excellence,
            organization_id=org_id,
        )

        # Phase 2F: Outcome Learningï¼ˆçµæœã‹ã‚‰ã®å­¦ç¿’ï¼‰
        from lib.brain.outcome_learning import create_outcome_learning, TRACKABLE_ACTIONS
        self._trackable_actions = TRACKABLE_ACTIONS
        self.outcome_learning = create_outcome_learning(org_id)

        # v10.46.0: è¦³æ¸¬æ©Ÿèƒ½ï¼ˆObservability Layerï¼‰
        self.observability = create_observability(
            org_id=org_id,
            enable_cloud_logging=True,
            enable_persistence=True,
            pool=pool,
        )

        # v10.50.0: LLM Brainï¼ˆLLMå¸¸é§å‹è„³ - 25ç« ï¼‰
        self.llm_brain: Optional[LLMBrain] = None
        self.llm_guardian: Optional[GuardianLayer] = None
        self.llm_state_manager: Optional[LLMStateManager] = None
        self.llm_context_builder: Optional[ContextBuilder] = None
        self._init_llm_brain()

        # å†…éƒ¨çŠ¶æ…‹
        self._initialized = False

        # v10.74.0: fire-and-forgetã‚¿ã‚¹ã‚¯è¿½è·¡ï¼ˆã‚¿ã‚¹ã‚¯æ¶ˆæ»…é˜²æ­¢ï¼‰
        self._background_tasks: set = set()

        logger.debug(f"SoulkunBrain initialized: "
                    f"chain_of_thought={self.use_chain_of_thought}, "
                    f"self_critique={self.use_self_critique}, "
                    f"execution_excellence={self.execution_excellence is not None}")

    # =========================================================================
    # v10.74.0: fire-and-forgetã‚¿ã‚¹ã‚¯å®‰å…¨ç®¡ç†
    # =========================================================================

    def _fire_and_forget(self, coro) -> None:
        """create_taskã®å®‰å…¨ãƒ©ãƒƒãƒ‘ãƒ¼: å‚ç…§ä¿æŒ+ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°"""
        task = asyncio.create_task(coro)
        self._background_tasks.add(task)
        task.add_done_callback(self._background_tasks.discard)
        task.add_done_callback(self._log_background_error)

    @staticmethod
    def _log_background_error(task: asyncio.Task) -> None:
        if not task.cancelled() and task.exception():
            logger.warning("Background task failed: %s", type(task.exception()).__name__)

    # =========================================================================
    # Phase 2E: å­¦ç¿’ãƒ‡ãƒ¼ã‚¿åŒæœŸ
    # =========================================================================

    def _sync_learning_to_decision(self) -> None:
        """LearningLoopã®å­¦ç¿’æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’Decision/Guardianã«åŒæœŸ"""
        try:
            self.decision.set_learned_adjustments(
                score_adjustments=self.learning_loop._applied_weight_adjustments,
                exceptions=self.learning_loop.get_learned_exceptions(),
            )
            if self.llm_guardian:
                self.llm_guardian.set_learned_rules(
                    self.learning_loop.get_learned_rules()
                )
        except Exception as e:
            logger.warning("[Phase2E] Sync to decision failed: %s", type(e).__name__)

    # =========================================================================
    # ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ
    # =========================================================================

    async def process_message(
        self,
        message: str,
        room_id: str,
        account_id: str,
        sender_name: str,
    ) -> BrainResponse:
        """
        ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‡¦ç†ã—ã¦å¿œç­”ã‚’è¿”ã™

        ã“ã‚ŒãŒè„³ã®å”¯ä¸€ã®ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆã€‚
        å…¨ã¦ã®å…¥åŠ›ã¯ã“ã“ã‚’é€šã‚‹ã€‚

        Args:
            message: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            room_id: ChatWorkãƒ«ãƒ¼ãƒ ID
            account_id: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¢ã‚«ã‚¦ãƒ³ãƒˆID
            sender_name: é€ä¿¡è€…å

        Returns:
            BrainResponse: å‡¦ç†çµæœ
        """
        start_time = time.time()

        # Phase 2E: åˆå›å‘¼ã³å‡ºã—æ™‚ã«æ°¸ç¶šåŒ–æ¸ˆã¿æ”¹å–„ã‚’å¾©å…ƒ
        if not self._initialized:
            self._initialized = True
            try:
                loaded = await self.learning_loop.load_persisted_improvements()
                if loaded > 0:
                    self._sync_learning_to_decision()
                    logger.info("[Phase2E] Loaded %d persisted improvements", loaded)
            except Exception as e:
                logger.warning("[Phase2E] Init load failed: %s", type(e).__name__)

        try:
            logger.info(
                f"ğŸ§  Brain processing: room={room_id}, user={sender_name}, "
                f"message={message[:50]}..."
            )

            # 1. è¨˜æ†¶å±¤: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå–å¾—ï¼ˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚‚æ¸¡ã—ã¦é–¢é€£çŸ¥è­˜ã‚’æ¤œç´¢ï¼‰
            context = await self._get_context(
                room_id=room_id,
                user_id=account_id,
                sender_name=sender_name,
                message=message,
            )

            # 1.5 Phase 2D: CEOæ•™ãˆå‡¦ç†
            # CEOã‹ã‚‰ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãªã‚‰æ•™ãˆã‚’æŠ½å‡ºï¼ˆéåŒæœŸã§å®Ÿè¡Œï¼‰
            if self.memory_manager.is_ceo_user(account_id):
                self._fire_and_forget(
                    self.memory_manager.process_ceo_message_safely(
                        message, room_id, account_id, sender_name
                    )
                )

            # é–¢é€£ã™ã‚‹CEOæ•™ãˆã‚’ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«è¿½åŠ 
            ceo_context = await self.memory_manager.get_ceo_teachings_context(
                message, account_id
            )
            if ceo_context:
                context.ceo_teachings = ceo_context

            # =========================================================
            # v10.50.0: LLM Brain ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°
            # Feature Flag `ENABLE_LLM_BRAIN` ãŒæœ‰åŠ¹ãªå ´åˆã€LLMè„³ã§å‡¦ç†
            # =========================================================
            if is_llm_brain_enabled() and self.llm_brain is not None:
                logger.info("ğŸ§  Routing to LLM Brain (Claude Opus 4.5)")
                return await self._process_with_llm_brain(
                    message=message,
                    room_id=room_id,
                    account_id=account_id,
                    sender_name=sender_name,
                    context=context,
                    start_time=start_time,
                )

            # =========================================================
            # ä»¥ä¸‹ã¯å¾“æ¥ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒãƒ³ã‚°æ–¹å¼ï¼ˆLLM Brainç„¡åŠ¹æ™‚ï¼‰
            # =========================================================

            # 2. çŠ¶æ…‹ãƒã‚§ãƒƒã‚¯: ãƒãƒ«ãƒã‚¹ãƒ†ãƒƒãƒ—ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¸­ï¼Ÿ
            current_state = await self._get_current_state(room_id, account_id)

            # 2.1 ã‚­ãƒ£ãƒ³ã‚»ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼Ÿ
            if self._is_cancel_request(message) and current_state and current_state.is_active:
                await self._clear_state(room_id, account_id, "user_cancel")
                return BrainResponse(
                    message=CANCEL_MESSAGE,
                    action_taken="cancel_session",
                    success=True,
                    state_changed=True,
                    new_state="normal",
                    total_time_ms=self._elapsed_ms(start_time),
                )

            # 2.2 ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¸­ãªã‚‰ã€ãã®ãƒ•ãƒ­ãƒ¼ã‚’ç¶™ç¶šï¼ˆsession_orchestratorã«å§”è­²ï¼‰
            if current_state and current_state.is_active:
                return await self.session_orchestrator.continue_session(
                    message=message,
                    state=current_state,
                    context=context,
                    room_id=room_id,
                    account_id=account_id,
                    sender_name=sender_name,
                    start_time=start_time,
                )

            # 2.5 Ultimate Brain: æ€è€ƒé€£é–ã§äº‹å‰åˆ†æ
            thought_chain = None
            if self.use_chain_of_thought:
                thought_chain = self._analyze_with_thought_chain(
                    message=message,
                    context={
                        "state": current_state.state_type.value if current_state else "normal",
                        "topic": getattr(context, "topic", None),
                    }
                )
                # Phase 1-C: CoTãƒ­ã‚°ã®PIIãƒã‚¹ã‚­ãƒ³ã‚°ï¼ˆCLAUDE.md 8-4æº–æ‹ ï¼‰
                sanitized_intent, _ = self.mask_pii(str(thought_chain.final_intent))
                logger.info(
                    f"ğŸ”— Chain-of-Thought: input_type={thought_chain.input_type.value}, "
                    f"intent={sanitized_intent}, "
                    f"confidence={thought_chain.confidence:.2f}"
                )

            # 3. ç†è§£å±¤: æ„å›³ã‚’æ¨è«–ï¼ˆæ€è€ƒé€£é–ã®çµæœã‚’è€ƒæ…®ï¼‰
            understanding = await self._understand(
                message, context, thought_chain=thought_chain
            )

            # 4. åˆ¤æ–­å±¤: ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ±ºå®š
            decision = await self._decide(understanding, context)

            # v10.46.0: è¦³æ¸¬ãƒ­ã‚° - æ„å›³åˆ¤å®šï¼ˆè„³ãŒçµ±ä¸€ç®¡ç†ï¼‰
            self.observability.log_intent(
                intent=understanding.intent,
                route=decision.action,
                confidence=decision.confidence,
                account_id=account_id,
                raw_message=message,
            )

            # 4.1 ç¢ºèªãŒå¿…è¦ï¼Ÿ
            if decision.needs_confirmation:
                # ç¢ºèªçŠ¶æ…‹ã«é·ç§»
                await self._transition_to_state(
                    room_id=room_id,
                    user_id=account_id,
                    state_type=StateType.CONFIRMATION,
                    data={
                        "pending_action": decision.action,
                        "pending_params": decision.params,
                        "confirmation_options": decision.confirmation_options,
                        "confirmation_question": decision.confirmation_question,
                    },
                    timeout_minutes=5,
                )
                return BrainResponse(
                    message=decision.confirmation_question or "ç¢ºèªã•ã›ã¦ã»ã—ã„ã‚¦ãƒ«ğŸº",
                    action_taken="request_confirmation",
                    success=True,
                    awaiting_confirmation=True,
                    state_changed=True,
                    new_state="confirmation",
                    debug_info={
                        "pending_action": decision.action,
                        "confidence": decision.confidence,
                    },
                    total_time_ms=self._elapsed_ms(start_time),
                )

            # 5. å®Ÿè¡Œå±¤: ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ
            result = await self._execute(
                decision=decision,
                context=context,
                room_id=room_id,
                account_id=account_id,
                sender_name=sender_name,
            )

            # 5.5 Ultimate Brain: è‡ªå·±æ‰¹åˆ¤ã§å›ç­”å“è³ªã‚’ãƒã‚§ãƒƒã‚¯
            final_message = result.message
            critique_applied = False
            if self.use_self_critique and result.message:
                refined = self._critique_and_refine_response(
                    response=result.message,
                    original_message=message,
                    context={
                        "expected_topic": getattr(context, "topic", None),
                        "previous_response": getattr(context, "last_ai_response", None),
                    }
                )
                if refined.refinement_applied:
                    final_message = refined.refined
                    critique_applied = True
                    logger.info(
                        f"âœ¨ Self-Critique: {len(refined.improvements)} improvements applied, "
                        f"time={refined.refinement_time_ms:.1f}ms"
                    )

            # resultã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æ›´æ–°
            if critique_applied:
                result = HandlerResult(
                    success=result.success,
                    message=final_message,
                    data=result.data,
                    suggestions=result.suggestions,
                    update_state=result.update_state,
                )

            # v10.46.0: è¦³æ¸¬ãƒ­ã‚° - å®Ÿè¡Œçµæœï¼ˆè„³ãŒçµ±ä¸€ç®¡ç†ï¼‰
            self.observability.log_execution(
                action=decision.action,
                success=result.success,
                account_id=account_id,
                execution_time_ms=self._elapsed_ms(start_time),
                error_code=result.data.get("error_code") if result.data and not result.success else None,
            )

            # 5.8 Phase 2F: çµæœã‹ã‚‰ã®å­¦ç¿’ â€” ã‚¢ã‚¯ã‚·ãƒ§ãƒ³è¨˜éŒ²ï¼ˆfire-and-forgetï¼‰
            if getattr(self, '_trackable_actions', None) and decision.action in self._trackable_actions:
                self._fire_and_forget(
                    self._record_outcome_event(
                        action=decision.action,
                        target_account_id=account_id,
                        target_room_id=room_id,
                        action_params=decision.params,
                        context_snapshot={"intent": understanding.intent},
                    )
                )

            # 6. è¨˜æ†¶æ›´æ–°ï¼ˆéåŒæœŸã§å®Ÿè¡Œã€ã‚¨ãƒ©ãƒ¼ã¯ç„¡è¦–ï¼‰
            self._fire_and_forget(
                self.memory_manager.update_memory_safely(
                    message, result, context, room_id, account_id, sender_name
                )
            )

            # 7. åˆ¤æ–­ãƒ­ã‚°è¨˜éŒ²ï¼ˆéåŒæœŸã§å®Ÿè¡Œï¼‰
            if SAVE_DECISION_LOGS:
                self._fire_and_forget(
                    self.memory_manager.log_decision_safely(
                        message, understanding, decision, result, room_id, account_id
                    )
                )

            # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’æ§‹ç¯‰
            debug_info = {
                "understanding": {
                    "intent": understanding.intent,
                    "confidence": understanding.intent_confidence,
                },
                "decision": {
                    "action": decision.action,
                    "confidence": decision.confidence,
                },
            }

            # æ€è€ƒé€£é–ã®æƒ…å ±ã‚’è¿½åŠ 
            if thought_chain:
                debug_info["thought_chain"] = {
                    "input_type": thought_chain.input_type.value,
                    "final_intent": thought_chain.final_intent,
                    "confidence": thought_chain.confidence,
                    "analysis_time_ms": thought_chain.analysis_time_ms,
                }

            # è‡ªå·±æ‰¹åˆ¤ã®æƒ…å ±ã‚’è¿½åŠ 
            if critique_applied:
                debug_info["self_critique"] = {
                    "applied": True,
                    "improvements_count": len(refined.improvements) if refined else 0,
                }

            return BrainResponse(
                message=result.message,
                action_taken=decision.action,
                action_params=decision.params,
                success=result.success,
                suggestions=result.suggestions,
                state_changed=result.update_state is not None,
                debug_info=debug_info,
                total_time_ms=self._elapsed_ms(start_time),
            )

        except BrainError as e:
            logger.error(f"Brain error: {e.to_dict()}")
            return BrainResponse(
                message=ERROR_MESSAGE,
                action_taken="error",
                success=False,
                debug_info={"error": e.to_dict()},
                total_time_ms=self._elapsed_ms(start_time),
            )
        except Exception as e:
            logger.exception(f"Unexpected error in brain: {type(e).__name__}")
            return BrainResponse(
                message=ERROR_MESSAGE,
                action_taken="error",
                success=False,
                debug_info={"error": type(e).__name__},
                total_time_ms=self._elapsed_ms(start_time),
            )

    # =========================================================================
    # èƒ½å‹•çš„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç”Ÿæˆï¼ˆCLAUDE.mdé‰„å‰‡1bæº–æ‹ ï¼‰
    # =========================================================================

    async def generate_proactive_message(
        self,
        trigger_type: str,
        trigger_details: Dict[str, Any],
        user_id: str,
        organization_id: str,
        room_id: Optional[str] = None,
        account_id: Optional[str] = None,
    ) -> "ProactiveMessageResult":
        """
        èƒ½å‹•çš„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç”Ÿæˆã™ã‚‹ï¼ˆè„³çµŒç”±ï¼‰

        CLAUDE.mdé‰„å‰‡1b: èƒ½å‹•çš„å‡ºåŠ›ã‚‚è„³ãŒç”Ÿæˆ
        ã‚·ã‚¹ãƒ†ãƒ ãŒè‡ªç™ºçš„ã«é€ã‚‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚‚è„³ãŒåˆ¤æ–­ãƒ»ç”Ÿæˆã™ã‚‹ã€‚

        ã€å‡¦ç†ãƒ•ãƒ­ãƒ¼ã€‘
        1. è¨˜æ†¶å±¤: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå–å¾—
           - éå»ã®ä¼šè©±å±¥æ­´
           - ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¥½ã¿ãƒ»æ€§æ ¼
           - æœ€è¿‘ã®æ„Ÿæƒ…å‚¾å‘

        2. ç†è§£å±¤: ãƒˆãƒªã‚¬ãƒ¼çŠ¶æ³ã®ç†è§£
           - ãªãœã“ã®ãƒˆãƒªã‚¬ãƒ¼ãŒç™ºç«ã—ãŸã‹
           - ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã¨ã£ã¦ã©ã†ã„ã†çŠ¶æ³ã‹

        3. åˆ¤æ–­å±¤: é€ä¿¡åˆ¤æ–­
           - ä»Šã“ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã§é€ã‚‹ã¹ãã‹
           - ã©ã®ã‚ˆã†ãªãƒˆãƒ¼ãƒ³ã§é€ã‚‹ã¹ãã‹

        4. ç”Ÿæˆå±¤: ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç”Ÿæˆ
           - ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¥½ã¿ã«åˆã‚ã›ãŸè¨€è‘‰é£ã„
           - çŠ¶æ³ã«å¿œã˜ãŸå†…å®¹
           - ã‚½ã‚¦ãƒ«ãã‚“ã‚‰ã—ã„è¡¨ç¾

        Args:
            trigger_type: ãƒˆãƒªã‚¬ãƒ¼ã‚¿ã‚¤ãƒ—ï¼ˆgoal_abandoned, task_overloadç­‰ï¼‰
            trigger_details: ãƒˆãƒªã‚¬ãƒ¼ã®è©³ç´°æƒ…å ±
            user_id: ãƒ¦ãƒ¼ã‚¶ãƒ¼ID
            organization_id: çµ„ç¹”ID
            room_id: ChatWorkãƒ«ãƒ¼ãƒ IDï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            account_id: ChatWorkã‚¢ã‚«ã‚¦ãƒ³ãƒˆIDï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

        Returns:
            ProactiveMessageResult: ç”Ÿæˆçµæœ
        """
        from lib.brain.models import ProactiveMessageResult, ProactiveMessageTone

        try:
            logger.info(
                f"ğŸ§  Brain generating proactive message: "
                f"trigger={trigger_type}, user={user_id}"
            )

            # 1. è¨˜æ†¶å±¤: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå–å¾—
            context_used: Dict[str, Any] = {}

            # ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ã‚’å–å¾—
            user_info = None
            try:
                if self.memory_access:
                    # person_idã§ç›´æ¥æ¤œç´¢ã‚’è©¦ã¿ã‚‹
                    user_info_list = await self.memory_access.get_person_info(
                        limit=1, person_id=user_id,
                    )
                    if not user_info_list:
                        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å…¨å“¡å–å¾—ã—ã¦åå‰ã‚ã‚Šã®æœ€åˆã®äººç‰©ã‚’ä½¿ç”¨
                        user_info_list = await self.memory_access.get_person_info(limit=10)
                    if user_info_list:
                        for person in user_info_list:
                            if hasattr(person, 'name') and person.name:
                                user_info = person
                                context_used["user_name"] = person.name
                                context_used["user_department"] = getattr(person, 'department', '')
                                break
            except Exception as e:
                logger.warning(f"Failed to get user info: {type(e).__name__}")

            # æœ€è¿‘ã®ä¼šè©±å±¥æ­´ã‚’å–å¾—
            # v10.54.4: get_conversation_historyã¯æœªå®Ÿè£…ã®ãŸã‚ã€get_recent_conversationã‚’ä½¿ç”¨
            recent_conversations = []
            try:
                if self.memory_access and room_id:
                    all_conversations = await self.memory_access.get_recent_conversation(
                        room_id=room_id,
                        user_id=user_id,
                    )
                    recent_conversations = all_conversations[:5]  # æœ€å¤§5ä»¶ã«åˆ¶é™
                    context_used["recent_conversations_count"] = len(recent_conversations)
            except Exception as e:
                logger.warning(f"Failed to get conversation history: {type(e).__name__}")

            # 2. ç†è§£å±¤: ãƒˆãƒªã‚¬ãƒ¼çŠ¶æ³ã®ç†è§£
            trigger_context = self._understand_trigger_context(
                trigger_type=trigger_type,
                trigger_details=trigger_details,
                user_info=user_info,
            )
            context_used["trigger_context"] = trigger_context

            # 3. åˆ¤æ–­å±¤: é€ä¿¡åˆ¤æ–­
            should_send, send_reason, tone = self._decide_proactive_action(
                trigger_type=trigger_type,
                trigger_details=trigger_details,
                recent_conversations=recent_conversations,
                user_info=user_info,
            )

            if not should_send:
                logger.info(f"ğŸ§  Brain decided not to send: {send_reason}")
                return ProactiveMessageResult(
                    should_send=False,
                    reason=send_reason,
                    confidence=0.8,
                    context_used=context_used,
                )

            # 4. ç”Ÿæˆå±¤: ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç”Ÿæˆ
            message = await self._generate_proactive_message_content(
                trigger_type=trigger_type,
                trigger_details=trigger_details,
                tone=tone,
                user_info=user_info,
                recent_conversations=recent_conversations,
            )

            logger.info(f"ğŸ§  Brain generated proactive message: {message[:50]}...")

            return ProactiveMessageResult(
                should_send=True,
                message=message,
                reason=send_reason,
                confidence=0.85,
                tone=tone,
                context_used=context_used,
            )

        except Exception as e:
            logger.error(f"Error generating proactive message: {type(e).__name__}")
            return ProactiveMessageResult(
                should_send=False,
                reason=f"Error: {type(e).__name__}",
                confidence=0.0,
                debug_info={"error": type(e).__name__},
            )

    def _understand_trigger_context(
        self,
        trigger_type: str,
        trigger_details: Dict[str, Any],
        user_info: Optional[Any] = None,
    ) -> str:
        """ãƒˆãƒªã‚¬ãƒ¼ã®çŠ¶æ³ã‚’ç†è§£ã™ã‚‹"""
        trigger_contexts = {
            "goal_abandoned": "ç›®æ¨™ãŒ{days}æ—¥é–“æ›´æ–°ã•ã‚Œã¦ã„ãªã„ã€‚é€²æ—ç¢ºèªãŒå¿…è¦ã€‚",
            "task_overload": "ã‚¿ã‚¹ã‚¯ãŒ{count}ä»¶æºœã¾ã£ã¦ã„ã‚‹ã€‚ã‚µãƒãƒ¼ãƒˆãŒå¿…è¦ã‹ã‚‚ã—ã‚Œãªã„ã€‚",
            "emotion_decline": "ãƒã‚¬ãƒ†ã‚£ãƒ–ãªæ„Ÿæƒ…ãŒç¶šã„ã¦ã„ã‚‹ã€‚æ°—é£ã„ãŒå¿…è¦ã€‚",
            "goal_achieved": "ç›®æ¨™ã‚’é”æˆã—ãŸã€‚ãŠç¥ã„ã¨æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã¸ã®åŠ±ã¾ã—ã€‚",
            "task_completed_streak": "ã‚¿ã‚¹ã‚¯ã‚’{count}ä»¶é€£ç¶šã§å®Œäº†ã€‚åŠ±ã¾ã—ã¨ç§°è³›ã€‚",
            "long_absence": "{days}æ—¥é–“æ´»å‹•ãŒãªã„ã€‚ä¹…ã—ã¶ã‚Šã®å£°ã‹ã‘ã€‚",
        }

        template = trigger_contexts.get(trigger_type, "çŠ¶æ³ã‚’ç¢ºèªã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚")
        try:
            return template.format(**trigger_details)
        except KeyError:
            return template

    def _decide_proactive_action(
        self,
        trigger_type: str,
        trigger_details: Dict[str, Any],
        recent_conversations: List[Any],
        user_info: Optional[Any] = None,
    ) -> tuple:
        """é€ä¿¡åˆ¤æ–­ã‚’è¡Œã†"""
        from lib.brain.models import ProactiveMessageTone

        # ãƒˆãƒªã‚¬ãƒ¼ã‚¿ã‚¤ãƒ—ã”ã¨ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
        trigger_configs = {
            "goal_abandoned": (True, "ç›®æ¨™é€²æ—ã®ç¢ºèª", ProactiveMessageTone.SUPPORTIVE),
            "task_overload": (True, "ã‚¿ã‚¹ã‚¯éå¤šã®ã‚µãƒãƒ¼ãƒˆ", ProactiveMessageTone.SUPPORTIVE),
            "emotion_decline": (True, "æ„Ÿæƒ…çš„ãªã‚µãƒãƒ¼ãƒˆ", ProactiveMessageTone.CONCERNED),
            "goal_achieved": (True, "ç›®æ¨™é”æˆã®ãŠç¥ã„", ProactiveMessageTone.CELEBRATORY),
            "task_completed_streak": (True, "é€£ç¶šå®Œäº†ã®ç§°è³›", ProactiveMessageTone.ENCOURAGING),
            "long_absence": (True, "ä¹…ã—ã¶ã‚Šã®æŒ¨æ‹¶", ProactiveMessageTone.FRIENDLY),
        }

        config = trigger_configs.get(
            trigger_type,
            (True, "ä¸€èˆ¬çš„ãªãƒ•ã‚©ãƒ­ãƒ¼ã‚¢ãƒƒãƒ—", ProactiveMessageTone.FRIENDLY)
        )

        # æœ€è¿‘ã®ä¼šè©±ãŒãƒã‚¬ãƒ†ã‚£ãƒ–ãªå ´åˆã¯æ…é‡ã«
        if recent_conversations:
            # TODO Phase 2N-Advanced: ä¼šè©±å†…å®¹ã®ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆåˆ†æã§åˆ¤æ–­ã‚’èª¿æ•´
            pass

        return config

    async def _generate_proactive_message_content(
        self,
        trigger_type: str,
        trigger_details: Dict[str, Any],
        tone: "ProactiveMessageTone",
        user_info: Optional[Any] = None,
        recent_conversations: Optional[List[Any]] = None,
    ) -> str:
        """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å†…å®¹ã‚’ç”Ÿæˆã™ã‚‹"""
        from lib.brain.models import ProactiveMessageTone

        # ãƒ¦ãƒ¼ã‚¶ãƒ¼åã‚’å–å¾—
        user_name = ""
        if user_info and hasattr(user_info, "name"):
            user_name = f"{user_info.name}ã•ã‚“ã€"

        # ãƒˆãƒªã‚¬ãƒ¼ã‚¿ã‚¤ãƒ—ã”ã¨ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
        # ã‚½ã‚¦ãƒ«ãã‚“ã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ï¼ˆèªå°¾ã€Œã‚¦ãƒ«ã€ã€çµµæ–‡å­—ğŸºï¼‰ã‚’ç¶­æŒ
        message_templates = {
            "goal_abandoned": {
                ProactiveMessageTone.SUPPORTIVE: [
                    f"{user_name}ç›®æ¨™ã®é€²æ—ã¯ã©ã†ã§ã™ã‹ã‚¦ãƒ«ï¼ŸğŸº ä½•ã‹æ‰‹ä¼ãˆã‚‹ã“ã¨ãŒã‚ã‚Œã°è¨€ã£ã¦ãã ã•ã„ã­",
                    f"{user_name}ç›®æ¨™ã«ã¤ã„ã¦ã€æœ€è¿‘ã©ã‚“ãªæ„Ÿã˜ã§ã™ã‹ã‚¦ãƒ«ï¼ŸğŸº ä¸€ç·’ã«ç¢ºèªã—ã¦ã¿ã¾ã—ã‚‡ã†ã‹",
                ],
                ProactiveMessageTone.FRIENDLY: [
                    f"{user_name}ç›®æ¨™ã®ã“ã¨ã€ã¡ã‚‡ã£ã¨æ°—ã«ãªã£ã¦ã¾ã—ãŸã‚¦ãƒ«ğŸº èª¿å­ã¯ã©ã†ã§ã™ã‹ï¼Ÿ",
                ],
            },
            "task_overload": {
                ProactiveMessageTone.SUPPORTIVE: [
                    f"{user_name}ã‚¿ã‚¹ã‚¯ãŒãŸãã•ã‚“ã‚ã‚‹ã¿ãŸã„ã§ã™ã­ã‚¦ãƒ«ğŸº å„ªå…ˆé †ä½ã‚’ä¸€ç·’ã«æ•´ç†ã—ã¾ã—ã‚‡ã†ã‹ï¼Ÿ",
                    f"{user_name}ãŠä»•äº‹ãŒå¿™ã—ãã†ã§ã™ã­ã‚¦ãƒ«ğŸº ä½•ã‹ãŠæ‰‹ä¼ã„ã§ãã‚‹ã“ã¨ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ",
                ],
            },
            "emotion_decline": {
                ProactiveMessageTone.CONCERNED: [
                    f"{user_name}æœ€è¿‘ã©ã†ã§ã™ã‹ã‚¦ãƒ«ï¼ŸğŸº ä½•ã‹æ°—ã«ãªã‚‹ã“ã¨ãŒã‚ã‚Œã°èãã¾ã™ã‚ˆ",
                    f"{user_name}å°‘ã—å¿ƒé…ã—ã¦ã¾ã—ãŸã‚¦ãƒ«ğŸº å¤§ä¸ˆå¤«ã§ã™ã‹ï¼Ÿç„¡ç†ã—ãªã„ã§ãã ã•ã„ã­",
                ],
            },
            "goal_achieved": {
                ProactiveMessageTone.CELEBRATORY: [
                    f"{user_name}ãŠã‚ã§ã¨ã†ã”ã–ã„ã¾ã™ã‚¦ãƒ«ï¼ğŸ‰ğŸº ç›®æ¨™é”æˆã€ã™ã”ã„ã§ã™ã­ï¼æ¬¡ã¯ã©ã‚“ãªã“ã¨ã«æŒ‘æˆ¦ã—ã¾ã™ã‹ï¼Ÿ",
                    f"{user_name}ã‚„ã‚Šã¾ã—ãŸã­ã‚¦ãƒ«ï¼ğŸ‰ğŸº ç´ æ™´ã‚‰ã—ã„æˆæœã§ã™ï¼ã“ã®èª¿å­ã§é ‘å¼µã‚Šã¾ã—ã‚‡ã†ï¼",
                ],
            },
            "task_completed_streak": {
                ProactiveMessageTone.ENCOURAGING: [
                    f"{user_name}ã‚¿ã‚¹ã‚¯ã‚’ã©ã‚“ã©ã‚“ç‰‡ä»˜ã‘ã¦ã¾ã™ã­ã‚¦ãƒ«ï¼ğŸ‰ğŸº ã™ã”ã„èª¿å­ã§ã™ï¼",
                    f"{user_name}ã„ã„æ„Ÿã˜ã§ã‚¿ã‚¹ã‚¯ãŒé€²ã‚“ã§ã¾ã™ã­ã‚¦ãƒ«ï¼âœ¨ğŸº ã“ã®èª¿å­ã§ã™ï¼",
                ],
            },
            "long_absence": {
                ProactiveMessageTone.FRIENDLY: [
                    f"{user_name}ãŠä¹…ã—ã¶ã‚Šã§ã™ã‚¦ãƒ«ï¼ğŸº æœ€è¿‘ã©ã†ã—ã¦ã¾ã—ãŸã‹ï¼Ÿ",
                    f"{user_name}ã—ã°ã‚‰ãã§ã—ãŸã­ã‚¦ãƒ«ï¼ğŸº å…ƒæ°—ã«ã—ã¦ã¾ã—ãŸã‹ï¼Ÿ",
                ],
            },
        }

        # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’å–å¾—
        templates = message_templates.get(trigger_type, {})
        tone_templates = templates.get(tone, templates.get(ProactiveMessageTone.FRIENDLY, []))

        if not tone_templates:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            return f"{user_name}ä½•ã‹ãŠæ‰‹ä¼ã„ã§ãã‚‹ã“ã¨ã¯ã‚ã‚Šã¾ã™ã‹ã‚¦ãƒ«ï¼ŸğŸº"

        # ãƒ©ãƒ³ãƒ€ãƒ ã«é¸æŠ
        import random
        template = random.choice(tone_templates)

        # ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ã‚’ç½®æ›
        try:
            return template.format(**trigger_details)
        except KeyError:
            return template

    # =========================================================================
    # è¨˜æ†¶å±¤ï¼ˆBrainMemoryAccessçµŒç”±ï¼‰
    # =========================================================================

    async def _get_context(
        self,
        room_id: str,
        user_id: str,
        sender_name: str,
        message: Optional[str] = None,
    ) -> BrainContext:
        """
        è„³ãŒåˆ¤æ–­ã«å¿…è¦ãªå…¨ã¦ã®è¨˜æ†¶ã‚’å–å¾—

        BrainMemoryAccessã‚’ä½¿ç”¨ã—ã¦è¤‡æ•°ã®è¨˜æ†¶ã‚½ãƒ¼ã‚¹ã‹ã‚‰ä¸¦åˆ—ã§å–å¾—ã—ã€
        çµ±åˆã—ãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿”ã™ã€‚

        Args:
            room_id: ChatWorkãƒ«ãƒ¼ãƒ ID
            user_id: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¢ã‚«ã‚¦ãƒ³ãƒˆID
            sender_name: é€ä¿¡è€…å
            message: ç¾åœ¨ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼ˆé–¢é€£çŸ¥è­˜æ¤œç´¢ã«ä½¿ç”¨ï¼‰

        Returns:
            BrainContext: çµ±åˆã•ã‚ŒãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
        """
        context = BrainContext(
            organization_id=self.org_id,
            room_id=room_id,
            sender_name=sender_name,
            sender_account_id=user_id,
            timestamp=datetime.now(),
        )

        try:
            # BrainMemoryAccessã§å…¨ã¦ã®è¨˜æ†¶ã‚’ä¸¦åˆ—å–å¾—
            memory_context = await self.memory_access.get_all_context(
                room_id=room_id,
                user_id=user_id,
                sender_name=sender_name,
                message=message,
            )

            # çµæœã‚’BrainContextã«çµ±åˆ
            # ä¼šè©±å±¥æ­´ï¼ˆConversationMessageã«å¤‰æ›ï¼‰
            if memory_context.get("recent_conversation"):
                context.recent_conversation = [
                    ConversationMessage(
                        role=msg.role if hasattr(msg, 'role') else msg.get('role', 'user'),
                        content=msg.content if hasattr(msg, 'content') else msg.get('content', ''),
                        timestamp=msg.timestamp if hasattr(msg, 'timestamp') else msg.get('timestamp'),
                    )
                    for msg in memory_context["recent_conversation"]
                ]

            # ä¼šè©±è¦ç´„ï¼ˆv10.54.4: SummaryDataã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¨ã—ã¦ä»£å…¥ï¼‰
            if memory_context.get("conversation_summary"):
                summary = memory_context["conversation_summary"]
                context.conversation_summary = SummaryData(
                    summary=summary.summary_text if hasattr(summary, 'summary_text') else summary.get('summary_text', ''),
                    key_topics=summary.key_topics if hasattr(summary, 'key_topics') else summary.get('key_topics', []),
                    mentioned_persons=summary.mentioned_persons if hasattr(summary, 'mentioned_persons') else summary.get('mentioned_persons', []),
                    mentioned_tasks=summary.mentioned_tasks if hasattr(summary, 'mentioned_tasks') else summary.get('mentioned_tasks', []),
                    created_at=datetime.now(),
                )

            # ãƒ¦ãƒ¼ã‚¶ãƒ¼å—œå¥½ â€” UserPreferenceData/dictã®ä¸¡å½¢å¼ã‚’æ­£è¦åŒ–
            if memory_context.get("user_preferences"):
                keywords = {}
                for pref in memory_context["user_preferences"]:
                    if isinstance(pref, UserPreferenceData):
                        keywords[pref.preference_key] = str(pref.preference_value)
                    elif isinstance(pref, dict):
                        keywords[pref.get("preference_key", "")] = str(pref.get("preference_value", ""))
                context.user_preferences = PreferenceData(
                    response_style=None,
                    feature_usage={},
                    preferred_times=[],
                    custom_keywords=keywords,
                )

            # äººç‰©æƒ…å ±ï¼ˆv10.54: PersonInfoã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¨ã—ã¦ä»£å…¥ï¼‰
            if memory_context.get("person_info"):
                context.person_info = [
                    person if isinstance(person, PersonInfo) else PersonInfo(
                        name=person.name if hasattr(person, 'name') else person.get('name', ''),
                        attributes=person.attributes if hasattr(person, 'attributes') else person.get('attributes', {}),
                    )
                    for person in memory_context["person_info"]
                ]

            # ã‚¿ã‚¹ã‚¯æƒ…å ±ï¼ˆv10.54: TaskInfoã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¨ã—ã¦ä»£å…¥ï¼‰
            if memory_context.get("recent_tasks"):
                context.recent_tasks = [
                    task if isinstance(task, TaskInfo) else TaskInfo(
                        task_id=task.task_id if hasattr(task, 'task_id') else task.get('task_id', ''),
                        body=task.body if hasattr(task, 'body') else task.get('body', ''),
                        summary=task.summary if hasattr(task, 'summary') else task.get('summary'),
                        status=task.status if hasattr(task, 'status') else task.get('status', 'open'),
                        due_date=task.due_date if hasattr(task, 'due_date') else (task.limit_time if hasattr(task, 'limit_time') else task.get('limit_time') or task.get('due_date')),
                        is_overdue=task.is_overdue if hasattr(task, 'is_overdue') else task.get('is_overdue', False),
                    )
                    for task in memory_context["recent_tasks"]
                ]

            # ç›®æ¨™æƒ…å ±ï¼ˆv10.54: GoalInfoã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¨ã—ã¦ä»£å…¥ï¼‰
            if memory_context.get("active_goals"):
                context.active_goals = [
                    goal if isinstance(goal, GoalInfo) else GoalInfo(
                        goal_id=goal.goal_id if hasattr(goal, 'goal_id') else goal.get('goal_id', ''),
                        title=goal.title if hasattr(goal, 'title') else goal.get('title', ''),
                        why=goal.why if hasattr(goal, 'why') else goal.get('why'),
                        what=goal.what if hasattr(goal, 'what') else goal.get('what'),
                        how=goal.how if hasattr(goal, 'how') else goal.get('how'),
                        status=goal.status if hasattr(goal, 'status') else goal.get('status', 'active'),
                        progress=float(goal.progress if hasattr(goal, 'progress') else goal.get('progress', 0.0)),
                    )
                    for goal in memory_context["active_goals"]
                ]

            # ã‚¤ãƒ³ã‚µã‚¤ãƒˆï¼ˆv10.54.4: models.py InsightInfoã®æ­£ã—ã„ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’ä½¿ç”¨ï¼‰
            if memory_context.get("insights"):
                context.insights = [
                    insight if isinstance(insight, InsightInfo) else InsightInfo(
                        insight_id=str(insight.id if hasattr(insight, 'id') else insight.get('id', '')) if (hasattr(insight, 'id') or isinstance(insight, dict) and 'id' in insight) else '',
                        insight_type=insight.insight_type if hasattr(insight, 'insight_type') else insight.get('insight_type', ''),
                        title=insight.title if hasattr(insight, 'title') else insight.get('title', ''),
                        description=insight.description if hasattr(insight, 'description') else insight.get('description', ''),
                        severity=insight.importance if hasattr(insight, 'importance') else insight.get('importance', 'medium'),
                        created_at=insight.created_at if hasattr(insight, 'created_at') else datetime.now(),
                    )
                    for insight in memory_context["insights"]
                ]

            # é–¢é€£çŸ¥è­˜ï¼ˆv10.54.4: KnowledgeChunkã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¨ã—ã¦ä»£å…¥ï¼‰
            if memory_context.get("relevant_knowledge"):
                context.relevant_knowledge = [
                    knowledge if isinstance(knowledge, KnowledgeChunk) else KnowledgeChunk(
                        chunk_id=knowledge.keyword if hasattr(knowledge, 'keyword') else knowledge.get('keyword', ''),
                        content=knowledge.answer if hasattr(knowledge, 'answer') else knowledge.get('answer', ''),
                        source=knowledge.category if hasattr(knowledge, 'category') else knowledge.get('category', ''),
                        relevance_score=knowledge.relevance_score if hasattr(knowledge, 'relevance_score') else knowledge.get('relevance_score', 0.0),
                    )
                    for knowledge in memory_context["relevant_knowledge"]
                ]

            # Phase 2E: é©ç”¨å¯èƒ½ãªå­¦ç¿’ã‚’ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«è¿½åŠ 
            # asyncio.to_thread()ã§åŒæœŸDBå‘¼ã³å‡ºã—ã‚’ã‚ªãƒ•ãƒ­ãƒ¼ãƒ‰
            if self.learning.phase2e_learning:
                try:
                    def _fetch_learnings():
                        with self.pool.connect() as conn:
                            applicable = self.learning.phase2e_learning.find_applicable(
                                conn, message or "", None, user_id, room_id
                            )
                            if applicable:
                                additions = self.learning.phase2e_learning.build_context_additions(applicable)
                                return self.learning.phase2e_learning.build_prompt_instructions(additions)
                            return None
                    result = await asyncio.to_thread(_fetch_learnings)
                    if result:
                        context.phase2e_learnings = result
                except Exception as e:
                    logger.warning(f"Error fetching Phase 2E learnings: {type(e).__name__}")

            logger.debug(
                f"Context loaded: conversation={len(context.recent_conversation)}, "
                f"tasks={len(context.recent_tasks)}, goals={len(context.active_goals)}, "
                f"insights={len(context.insights)}"
            )

        except Exception as e:
            logger.warning(f"Error fetching context via BrainMemoryAccess: {type(e).__name__}")
            # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå–å¾—ã«å¤±æ•—ã—ã¦ã‚‚å‡¦ç†ã¯ç¶šè¡Œ

        return context

    async def _get_recent_conversation(
        self,
        room_id: str,
        user_id: str,
    ) -> List[ConversationMessage]:
        """ç›´è¿‘ã®ä¼šè©±ã‚’å–å¾—ï¼ˆBrainMemoryAccessçµŒç”±ï¼‰"""
        messages = await self.memory_access.get_recent_conversation(room_id, user_id)
        return [
            ConversationMessage(
                role=msg.role,
                content=msg.content,
                timestamp=msg.timestamp if msg.timestamp else datetime.now(),
            )
            for msg in messages
        ]

    async def _get_conversation_summary(self, user_id: str):
        """ä¼šè©±è¦ç´„ã‚’å–å¾—ï¼ˆBrainMemoryAccessçµŒç”±ï¼‰"""
        return await self.memory_access.get_conversation_summary(user_id)

    async def _get_user_preferences(self, user_id: str):
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼å—œå¥½ã‚’å–å¾—ï¼ˆBrainMemoryAccessçµŒç”±ï¼‰"""
        return await self.memory_access.get_user_preferences(user_id)

    async def _get_person_info(self) -> List[Any]:
        """äººç‰©æƒ…å ±ã‚’å–å¾—ï¼ˆBrainMemoryAccessçµŒç”±ï¼‰"""
        result: List[Any] = await self.memory_access.get_person_info()
        return result

    async def _get_recent_tasks(self, user_id: str) -> List[Any]:
        """ç›´è¿‘ã®ã‚¿ã‚¹ã‚¯ã‚’å–å¾—ï¼ˆBrainMemoryAccessçµŒç”±ï¼‰"""
        result: List[Any] = await self.memory_access.get_recent_tasks(user_id)
        return result

    async def _get_active_goals(self, user_id: str) -> List[Any]:
        """ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªç›®æ¨™ã‚’å–å¾—ï¼ˆBrainMemoryAccessçµŒç”±ï¼‰"""
        result: List[Any] = await self.memory_access.get_active_goals(user_id)
        return result

    async def _get_insights(self) -> List[Any]:
        """ã‚¤ãƒ³ã‚µã‚¤ãƒˆã‚’å–å¾—ï¼ˆBrainMemoryAccessçµŒç”±ï¼‰"""
        result: List[Any] = await self.memory_access.get_recent_insights()
        return result

    async def _get_relevant_knowledge(self, query: str) -> List[Any]:
        """é–¢é€£çŸ¥è­˜ã‚’å–å¾—ï¼ˆBrainMemoryAccessçµŒç”±ï¼‰"""
        result: List[Any] = await self.memory_access.get_relevant_knowledge(query)
        return result

    # =========================================================================
    # çŠ¶æ…‹ç®¡ç†å±¤
    # =========================================================================

    async def _get_current_state(
        self,
        room_id: str,
        user_id: str,
    ) -> Optional[ConversationState]:
        """
        ç¾åœ¨ã®çŠ¶æ…‹ã‚’å–å¾—ï¼ˆv10.40.1: ç¥çµŒæ¥ç¶šä¿®ç† - brain_conversation_statesã®ã¿å‚ç…§ï¼‰

        v10.40.1: goal_setting_sessionsã¸ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’å‰Šé™¤
        - goal_setting.py ãŒ brain_conversation_states ã‚’ä½¿ç”¨ã™ã‚‹ã‚ˆã†ã«æ›¸ãæ›ãˆã‚‰ã‚ŒãŸãŸã‚
        - å…¨ã¦ã®çŠ¶æ…‹ã¯ brain_conversation_states ã§ä¸€å…ƒç®¡ç†
        - æ—§ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆgoal_setting_sessionsï¼‰ã¯å‚ç…§ã—ãªã„

        ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¦ã„ã‚‹å ´åˆã¯è‡ªå‹•çš„ã«ã‚¯ãƒªã‚¢ã—ã¦Noneã‚’è¿”ã™ã€‚
        """
        # brain_conversation_statesã®ã¿ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆgoal_setting_sessionsã¯å‚ç…§ã—ãªã„ï¼‰
        return await self.state_manager.get_current_state(room_id, user_id)

    async def _get_current_state_with_user_org(
        self,
        room_id: str,
        user_id: str,
    ) -> Optional[ConversationState]:
        """
        ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®organization_idã‚’ä½¿ç”¨ã—ã¦çŠ¶æ…‹ã‚’å–å¾—ï¼ˆv10.56.6: ãƒãƒ«ãƒãƒ†ãƒŠãƒ³ãƒˆå¯¾å¿œï¼‰

        çŠ¶æ…‹ä¿å­˜æ™‚ã«ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®org_idã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹ãŸã‚ã€
        å–å¾—æ™‚ã‚‚åŒã˜org_idã‚’ä½¿ç”¨ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚

        Args:
            room_id: ChatWorkãƒ«ãƒ¼ãƒ ID
            user_id: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¢ã‚«ã‚¦ãƒ³ãƒˆID

        Returns:
            ConversationState: ç¾åœ¨ã®çŠ¶æ…‹ï¼ˆå­˜åœ¨ã—ãªã„å ´åˆã¯Noneï¼‰
        """
        try:
            from lib.brain.state_manager import BrainStateManager

            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®organization_idã‚’å–å¾—
            user_org_id = await self._get_user_organization_id(user_id)
            if not user_org_id:
                logger.debug("[çŠ¶æ…‹å–å¾—] ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®org_idå–å¾—å¤±æ•—")
                return None

            logger.debug("[çŠ¶æ…‹å–å¾—] ãƒ¦ãƒ¼ã‚¶ãƒ¼org_idä½¿ç”¨")

            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®org_idã§ä¸€æ™‚çš„ãªBrainStateManagerã‚’ä½œæˆ
            user_state_manager = BrainStateManager(pool=self.pool, org_id=user_org_id)
            return await user_state_manager.get_current_state(room_id, user_id)

        except Exception as e:
            logger.error(f"âŒ [çŠ¶æ…‹å–å¾—] ã‚¨ãƒ©ãƒ¼: {type(e).__name__}")
            return None

    async def _get_user_organization_id(self, user_id: str) -> Optional[str]:
        """
        ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®organization_idã‚’å–å¾—ï¼ˆv10.56.6: ãƒãƒ«ãƒãƒ†ãƒŠãƒ³ãƒˆå¯¾å¿œï¼‰

        Args:
            user_id: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¢ã‚«ã‚¦ãƒ³ãƒˆIDï¼ˆChatWork account_idï¼‰

        Returns:
            str: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®organization_idï¼ˆå–å¾—å¤±æ•—æ™‚ã¯Noneï¼‰
        """
        try:
            query = text("""
                SELECT organization_id FROM users
                WHERE chatwork_account_id = :account_id
                LIMIT 1
            """)

            def _sync():
                with self.pool.connect() as conn:
                    result = conn.execute(query, {"account_id": str(user_id)})
                    return result.fetchone()

            row = await asyncio.to_thread(_sync)

            if row and row[0]:
                return str(row[0])
            return None

        except Exception as e:
            logger.warning(f"âš ï¸ [org_idå–å¾—] ã‚¨ãƒ©ãƒ¼: {type(e).__name__}")
            return None

    async def _transition_to_state(
        self,
        room_id: str,
        user_id: str,
        state_type: StateType,
        step: Optional[str] = None,
        data: Optional[Dict] = None,
        reference_type: Optional[str] = None,
        reference_id: Optional[str] = None,
        timeout_minutes: int = SESSION_TIMEOUT_MINUTES,
    ) -> ConversationState:
        """
        çŠ¶æ…‹ã‚’é·ç§»

        BrainStateManagerã«å§”è­²ã—ã¦DBã«UPSERTã€‚
        """
        return await self.state_manager.transition_to(
            room_id=room_id,
            user_id=user_id,
            state_type=state_type,
            step=step,
            data=data,
            reference_type=reference_type,
            reference_id=reference_id,
            timeout_minutes=timeout_minutes,
        )

    async def _clear_state(
        self,
        room_id: str,
        user_id: str,
        reason: str = "user_cancel",
    ) -> None:
        """
        çŠ¶æ…‹ã‚’ã‚¯ãƒªã‚¢ï¼ˆé€šå¸¸çŠ¶æ…‹ã«æˆ»ã™ï¼‰

        BrainStateManagerã«å§”è­²ã—ã¦DBã‹ã‚‰å‰Šé™¤ã€‚
        """
        await self.state_manager.clear_state(room_id, user_id, reason)

    async def _update_state_step(
        self,
        room_id: str,
        user_id: str,
        new_step: str,
        additional_data: Optional[Dict] = None,
    ) -> ConversationState:
        """
        ç¾åœ¨ã®çŠ¶æ…‹å†…ã§ã‚¹ãƒ†ãƒƒãƒ—ã‚’é€²ã‚ã‚‹

        BrainStateManagerã«å§”è­²ã—ã¦DBã‚’æ›´æ–°ã€‚
        """
        return await self.state_manager.update_step(
            room_id=room_id,
            user_id=user_id,
            new_step=new_step,
            additional_data=additional_data,
        )

    # =========================================================================
    # ç†è§£å±¤
    # =========================================================================

    async def _understand(
        self,
        message: str,
        context: BrainContext,
        thought_chain=None,
    ) -> UnderstandingResult:
        """
        ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‹ã‚‰æ„å›³ã‚’æ¨è«–

        BrainUnderstandingã‚¯ãƒ©ã‚¹ã«å§”è­²ã€‚
        çœç•¥ã®è£œå®Œã€ä»£åè©è§£æ±ºã€æ›–æ˜§æ€§ã®è§£æ¶ˆã€æ„Ÿæƒ…ã®æ¤œå‡ºç­‰ã‚’è¡Œã†ã€‚

        v10.28.3: LLMç†è§£å±¤ã«å¼·åŒ–ï¼ˆPhase Då®Œäº†ï¼‰
        - LLMãƒ™ãƒ¼ã‚¹ã®æ„å›³æ¨è«–ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒãƒ³ã‚°ï¼‰
        - ä»£åè©è§£æ±º: ã€Œã‚ã‚Œã€ã€Œãã‚Œã€ã€Œã‚ã®äººã€â†’ å…·ä½“çš„ãªå¯¾è±¡
        - çœç•¥è£œå®Œ: ã€Œå®Œäº†ã«ã—ã¦ã€â†’ ç›´è¿‘ã®ã‚¿ã‚¹ã‚¯
        - æ„Ÿæƒ…æ¤œå‡º: ãƒã‚¸ãƒ†ã‚£ãƒ–/ãƒã‚¬ãƒ†ã‚£ãƒ–/ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«
        - ç·Šæ€¥åº¦æ¤œå‡º: ã€Œè‡³æ€¥ã€ã€Œæ€¥ã„ã§ã€ç­‰
        - ç¢ºèªãƒ¢ãƒ¼ãƒ‰: ç¢ºä¿¡åº¦0.7æœªæº€ã§ç™ºå‹•

        v10.34.0: Ultimate Brain Phase 1
        - thought_chain: æ€è€ƒé€£é–ã®çµæœï¼ˆã‚ã‚Œã°æ´»ç”¨ï¼‰
        """
        # æ€è€ƒé€£é–ã®çµæœãŒã‚ã‚‹å ´åˆã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«è¿½åŠ 
        if thought_chain:
            # æ€è€ƒé€£é–ã§ä½ç¢ºä¿¡åº¦ï¼ˆ<0.7ï¼‰ãªã‚‰ç¢ºèªãƒ¢ãƒ¼ãƒ‰ã‚’ä¿ƒã™
            if thought_chain.confidence < 0.7:
                logger.debug(
                    f"Thought chain suggests confirmation: "
                    f"confidence={thought_chain.confidence:.2f}"
                )

        return await self.understanding.understand(message, context)

    # =========================================================================
    # åˆ¤æ–­å±¤
    # =========================================================================

    async def _decide(
        self,
        understanding: UnderstandingResult,
        context: BrainContext,
    ) -> DecisionResult:
        """
        BrainDecisionã‚¯ãƒ©ã‚¹ã«å§”è­²ã€‚
        v10.28.4: åˆ¤æ–­å±¤ã«å¼·åŒ–ï¼ˆPhase Eå®Œäº†ï¼‰

        ç†è§£ã—ãŸæ„å›³ã«åŸºã¥ã„ã¦ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ±ºå®šã™ã‚‹ã€‚
        - SYSTEM_CAPABILITIESã‹ã‚‰é©åˆ‡ãªæ©Ÿèƒ½ã‚’é¸æŠ
        - ç¢ºä¿¡åº¦ãƒ»ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«ã«åŸºã¥ãç¢ºèªè¦å¦åˆ¤æ–­
        - MVVæ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
        - è¤‡æ•°ã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ¤œå‡º
        """
        return await self.decision.decide(understanding, context)

    # =========================================================================
    # Phase 2L: ExecutionExcellenceåˆæœŸåŒ–
    # =========================================================================

    def _init_execution_excellence(self) -> None:
        """
        ExecutionExcellenceï¼ˆå®Ÿè¡ŒåŠ›å¼·åŒ–ï¼‰ã‚’åˆæœŸåŒ–

        Phase 2L: è¤‡åˆã‚¿ã‚¹ã‚¯ã®è‡ªå‹•åˆ†è§£ãƒ»è¨ˆç”»ãƒ»å®Ÿè¡Œ

        Feature Flag `ENABLE_EXECUTION_EXCELLENCE` ãŒæœ‰åŠ¹ãªå ´åˆã®ã¿åˆæœŸåŒ–ã€‚
        """
        if not ff_execution_excellence_enabled():
            logger.info("ExecutionExcellence is disabled by feature flag")
            return

        try:
            self.execution_excellence = create_execution_excellence(
                handlers=self.handlers,
                capabilities=self.capabilities,
                pool=self.pool,
                org_id=self.org_id,
                llm_client=self.get_ai_response,
            )
            logger.info("ExecutionExcellence initialized successfully")
        except Exception as e:
            logger.warning(f"Failed to initialize ExecutionExcellence: {type(e).__name__}")
            self.execution_excellence = None

    def _init_llm_brain(self) -> None:
        """
        LLM Brainï¼ˆLLMå¸¸é§å‹è„³ï¼‰ã‚’åˆæœŸåŒ–

        v10.50.0: Claude Opus 4.5ã‚’ä½¿ç”¨ã—ãŸFunction Callingæ–¹å¼ã®è„³
        è¨­è¨ˆæ›¸: docs/25_llm_native_brain_architecture.md

        Feature Flag `ENABLE_LLM_BRAIN` ãŒæœ‰åŠ¹ãªå ´åˆã®ã¿åˆæœŸåŒ–ã€‚
        """
        if not is_llm_brain_enabled():
            logger.info("LLM Brain is disabled by feature flag")
            return

        try:
            # LLM Brain ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®åˆæœŸåŒ–
            self.llm_brain = LLMBrain()
            self.llm_guardian = GuardianLayer(
                ceo_teachings=[],  # CEOæ•™ãˆã¯å®Ÿè¡Œæ™‚ã«å–å¾—
            )
            self.llm_state_manager = LLMStateManager(
                brain_state_manager=self.state_manager,
            )
            self.emotion_reader = create_emotion_reader()
            self.llm_context_builder = ContextBuilder(
                pool=self.pool,
                memory_access=self.memory_access,
                state_manager=self.llm_state_manager,
                ceo_teaching_repository=self.ceo_teaching_repo,
                phase2e_learning=self.learning.phase2e_learning,
                outcome_learning=self.outcome_learning,
                emotion_reader=self.emotion_reader,
            )
            logger.info("ğŸ§  LLM Brain initialized successfully (Claude Opus 4.5)")
        except Exception as e:
            logger.warning(f"Failed to initialize LLM Brain: {type(e).__name__}")
            self.llm_brain = None
            self.llm_guardian = None
            self.llm_state_manager = None
            self.llm_context_builder = None

    # =========================================================================
    # å®Ÿè¡Œå±¤
    # =========================================================================

    async def _execute(
        self,
        decision: DecisionResult,
        context: BrainContext,
        room_id: str,
        account_id: str,
        sender_name: str,
    ) -> HandlerResult:
        """
        BrainExecutionã‚¯ãƒ©ã‚¹ã«å§”è­²ã€‚
        v10.47.0: authorization_gateã«æ¨©é™ãƒã‚§ãƒƒã‚¯ã‚’çµ±åˆ

        åˆ¤æ–­å±¤ã‹ã‚‰ã®æŒ‡ä»¤ã«åŸºã¥ã„ã¦ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚’å‘¼ã³å‡ºã—ã€çµæœã‚’çµ±åˆã™ã‚‹ã€‚
        """
        # =================================================================
        # æ¨©é™ãƒã‚§ãƒƒã‚¯ï¼ˆauthorization_gateã«å§”è­²ï¼‰
        # =================================================================
        auth_result = await self.authorization_gate.evaluate(
            decision=decision,
            context=context,
            room_id=room_id,
            account_id=account_id,
            sender_name=sender_name,
        )

        # ãƒ–ãƒ­ãƒƒã‚¯/ç¢ºèªãŒå¿…è¦ãªå ´åˆã¯æ—©æœŸãƒªã‚¿ãƒ¼ãƒ³
        if auth_result.blocked and auth_result.response:
            return auth_result.response

        # ExecutionExcellenceãŒä½¿ç”¨ã•ã‚ŒãŸå ´åˆ
        if auth_result.execution_excellence_used and auth_result.execution_excellence_result:
            ee_result = auth_result.execution_excellence_result
            suggestions_raw = getattr(ee_result, 'suggestions', None)
            return HandlerResult(
                success=ee_result.success,
                message=ee_result.message,
                suggestions=list(suggestions_raw) if suggestions_raw else [],
            )

        # =================================================================
        # å¾“æ¥ã®å®Ÿè¡Œãƒ•ãƒ­ãƒ¼
        # =================================================================
        result = await self.execution.execute(
            decision=decision,
            context=context,
            room_id=room_id,
            account_id=account_id,
            sender_name=sender_name,
        )
        return result.to_handler_result()

    # =========================================================================
    # Phase 2F: Outcome Learning
    # =========================================================================

    async def _record_outcome_event(
        self,
        action: str,
        target_account_id: str,
        target_room_id: str,
        action_params: Optional[Dict[str, Any]] = None,
        context_snapshot: Optional[Dict[str, Any]] = None,
    ) -> None:
        """Phase 2F: ã‚¢ã‚¯ã‚·ãƒ§ãƒ³çµæœã‚’éåŒæœŸã§è¨˜éŒ²ï¼ˆfire-and-forgetï¼‰

        Note: asyncio.to_thread()ã§åŒæœŸDBå‘¼ã³å‡ºã—ã‚’ã‚ªãƒ•ãƒ­ãƒ¼ãƒ‰ã—ã€
        ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ã‚’ãƒ–ãƒ­ãƒƒã‚¯ã—ãªã„ã€‚
        """
        try:
            # PIIä¿è­·: message/body/contentã‚­ãƒ¼ã‚’é™¤å¤–ã—ã¦ã‹ã‚‰DBä¿å­˜
            safe_params = {
                k: v for k, v in (action_params or {}).items()
                if k not in ("message", "body", "content", "text")
            } if action_params else None

            def _sync_record():
                with self.pool.connect() as conn:
                    self.outcome_learning.record_action(
                        conn=conn,
                        action=action,
                        target_account_id=target_account_id,
                        target_room_id=target_room_id,
                        action_params=safe_params,
                        context_snapshot=context_snapshot,
                    )
            await asyncio.to_thread(_sync_record)
        except Exception as e:
            logger.warning("Phase 2F outcome recording failed: %s", type(e).__name__)

    # =========================================================================
    # ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
    # =========================================================================

    def _is_cancel_request(self, message: str) -> bool:
        """ã‚­ãƒ£ãƒ³ã‚»ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‹ã©ã†ã‹ã‚’åˆ¤å®š"""
        normalized = message.strip().lower()
        return any(kw in normalized for kw in CANCEL_KEYWORDS)

    # =========================================================================
    # Ultimate Brain - Phase 1: æ€è€ƒé€£é– & è‡ªå·±æ‰¹åˆ¤
    # =========================================================================

    def _analyze_with_thought_chain(
        self,
        message: str,
        context: Optional[Dict[str, Any]] = None,
    ):
        """
        æ€è€ƒé€£é–ã§å…¥åŠ›ã‚’äº‹å‰åˆ†æ

        Args:
            message: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            context: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±

        Returns:
            ThoughtChain: æ€è€ƒé€£é–ã®çµæœ
        """
        try:
            return self.chain_of_thought.analyze(message, context)
        except Exception as e:
            logger.warning(f"Chain-of-thought analysis failed: {type(e).__name__}")
            # å¤±æ•—ã—ã¦ã‚‚Noneã‚’è¿”ã™ã ã‘ã§å‡¦ç†ã¯ç¶šè¡Œ
            return None

    def _critique_and_refine_response(
        self,
        response: str,
        original_message: str,
        context: Optional[Dict[str, Any]] = None,
    ):
        """
        è‡ªå·±æ‰¹åˆ¤ã§å›ç­”ã‚’è©•ä¾¡ãƒ»æ”¹å–„

        Args:
            response: ç”Ÿæˆã•ã‚ŒãŸå›ç­”
            original_message: å…ƒã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            context: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±

        Returns:
            RefinedResponse: æ”¹å–„ã•ã‚ŒãŸå›ç­”
        """
        try:
            return self.self_critique.evaluate_and_refine(
                response, original_message, context
            )
        except Exception as e:
            logger.warning(f"Self-critique failed: {type(e).__name__}")
            # å¤±æ•—ã—ãŸå ´åˆã¯å…ƒã®å›ç­”ã‚’ãã®ã¾ã¾è¿”ã™
            from lib.brain.self_critique import RefinedResponse
            return RefinedResponse(
                original=response,
                refined=response,
                improvements=[],
                refinement_applied=False,
                refinement_time_ms=0,
            )

    def _elapsed_ms(self, start_time: float) -> int:
        """çµŒéæ™‚é–“ã‚’ãƒŸãƒªç§’ã§å–å¾—"""
        return int((time.time() - start_time) * 1000)

    # =========================================================================
    # v10.50.0: LLM Brain å‡¦ç†ï¼ˆ25ç« : LLMå¸¸é§å‹è„³ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ï¼‰
    # =========================================================================

    async def _process_with_llm_brain(
        self,
        message: str,
        room_id: str,
        account_id: str,
        sender_name: str,
        context: BrainContext,
        start_time: float,
    ) -> BrainResponse:
        """
        LLM Brainï¼ˆClaude Opus 4.5ï¼‰ã§ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‡¦ç†

        è¨­è¨ˆæ›¸: docs/25_llm_native_brain_architecture.md

        ã€å‡¦ç†ãƒ•ãƒ­ãƒ¼ã€‘
        1. ContextBuilder: LLMã«æ¸¡ã™ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ§‹ç¯‰
        2. LLMBrain: Claude API + Function Callingã§æ„å›³ç†è§£ãƒ»Toolé¸æŠ
        3. GuardianLayer: LLMã®ææ¡ˆã‚’æ¤œè¨¼ï¼ˆALLOW/CONFIRM/BLOCK/MODIFYï¼‰
        4. Execution: Toolã‚’å®Ÿè¡Œ

        Args:
            message: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            room_id: ChatWorkãƒ«ãƒ¼ãƒ ID
            account_id: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¢ã‚«ã‚¦ãƒ³ãƒˆID
            sender_name: é€ä¿¡è€…å
            context: æ—¢ã«å–å¾—æ¸ˆã¿ã®BrainContext
            start_time: å‡¦ç†é–‹å§‹æ™‚åˆ»

        Returns:
            BrainResponse: å‡¦ç†çµæœ
        """
        try:
            # v10.54.4: Nullå®‰å…¨ãƒã‚§ãƒƒã‚¯ï¼ˆmypyå¯¾å¿œï¼‰
            if self.llm_context_builder is None:
                raise BrainError("LLM context builder is not initialized")
            if self.llm_brain is None:
                raise BrainError("LLM brain is not initialized")
            if self.llm_guardian is None:
                raise BrainError("LLM guardian is not initialized")
            if self.llm_state_manager is None:
                raise BrainError("LLM state manager is not initialized")

            logger.info(
                f"ğŸ§  LLM Brain processing: room={room_id}, user={sender_name}, "
                f"message={message[:50]}..."
            )

            # =================================================================
            # v10.56.6: LIST_CONTEXTå„ªå…ˆãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ï¼ˆãƒãƒ«ãƒãƒ†ãƒŠãƒ³ãƒˆå¯¾å¿œï¼‰
            # LIST_CONTEXTçŠ¶æ…‹ï¼ˆç›®æ¨™ä¸€è¦§è¡¨ç¤ºå¾Œã®æ–‡è„ˆä¿æŒï¼‰ãŒã‚ã‚‹å ´åˆã¯ã€
            # LLMå‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦ã‚»ãƒƒã‚·ãƒ§ãƒ³ç¶™ç¶šã¸ç›´æ¥ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã™ã‚‹ã€‚
            # ã“ã‚Œã«ã‚ˆã‚Šã€Œç›®æ¨™å…¨éƒ¨å‰Šé™¤ã—ã¦ã€â†’ã€ŒOKã€ãŒæ­£ã—ãå‡¦ç†ã•ã‚Œã‚‹ã€‚
            #
            # é‡è¦: çŠ¶æ…‹ä¿å­˜æ™‚ã«ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®org_idã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹ãŸã‚ã€
            # å–å¾—æ™‚ã‚‚åŒã˜org_idã‚’ä½¿ç”¨ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚
            # =================================================================
            current_state = await self._get_current_state_with_user_org(room_id, account_id)
            if current_state and current_state.is_active:
                if current_state.state_type == StateType.LIST_CONTEXT:
                    logger.debug(
                        f"ğŸ“‹ LIST_CONTEXTçŠ¶æ…‹æ¤œå‡º â†’ ã‚»ãƒƒã‚·ãƒ§ãƒ³ç¶™ç¶šã¸ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°: "
                        f"step={current_state.state_step}"
                    )
                    return await self.session_orchestrator.continue_session(
                        message=message,
                        state=current_state,
                        context=context,
                        room_id=room_id,
                        account_id=account_id,
                        sender_name=sender_name,
                        start_time=start_time,
                    )

            # 1. LLMã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ§‹ç¯‰
            # Phase 2E: _get_context()ã§å–å¾—æ¸ˆã¿ã®å­¦ç¿’ã‚’æ¸¡ã—ã¦é‡è¤‡ã‚¯ã‚¨ãƒªå›é¿
            llm_context = await self.llm_context_builder.build(
                user_id=account_id,
                room_id=room_id,
                organization_id=self.org_id,
                message=message,
                sender_name=sender_name,
                phase2e_learnings_prefetched=context.phase2e_learnings,
            )

            # 2. Toolã‚«ã‚¿ãƒ­ã‚°ã‚’å–å¾—ï¼ˆSYSTEM_CAPABILITIESã‹ã‚‰å¤‰æ›ï¼‰
            tools = get_tools_for_llm()

            # 3. LLM Brainã§å‡¦ç†
            llm_result: LLMBrainResult = await self.llm_brain.process(
                context=llm_context,
                message=message,
                tools=tools,
            )

            # =================================================================
            # å¢ƒç•Œå‹æ¤œè¨¼: LLMå‡ºåŠ›ã®å‹ãƒã‚§ãƒƒã‚¯
            # =================================================================
            _validate_llm_result_type(llm_result, "_process_with_llm_brain:llm_brain.process")

            # confidenceã‚’å®‰å…¨ã«æŠ½å‡ºï¼ˆã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ/æ•°å€¤ä¸¡å¯¾å¿œï¼‰
            confidence_value = _extract_confidence_value(
                llm_result.confidence,
                "_process_with_llm_brain:confidence"
            )

            logger.info(
                f"ğŸ§  LLM Brain result: tool_calls={len(llm_result.tool_calls or [])}, "
                f"has_text={llm_result.text_response is not None}, "
                f"confidence={confidence_value:.2f}"
            )

            # 4. Guardian Layerã§æ¤œè¨¼
            guardian_result = await self.llm_guardian.check(llm_result, llm_context)

            logger.info(
                f"ğŸ›¡ï¸ Guardian result: action={guardian_result.action.value}, "
                f"reason={guardian_result.reason[:50] if guardian_result.reason else 'N/A'}..."
            )

            # 5. Guardianã®åˆ¤æ–­ã«åŸºã¥ã„ã¦å‡¦ç†ã‚’åˆ†å²
            if guardian_result.action == GuardianAction.BLOCK:
                # ãƒ–ãƒ­ãƒƒã‚¯: å®Ÿè¡Œã—ãªã„
                block_message = guardian_result.blocked_reason or guardian_result.reason or "ãã®æ“ä½œã¯å®Ÿè¡Œã§ãã¾ã›ã‚“ã‚¦ãƒ«ğŸº"
                return BrainResponse(
                    message=block_message,
                    action_taken="guardian_block",
                    success=False,
                    debug_info={
                        "llm_brain": {
                            "tool_calls": [tc.to_dict() for tc in llm_result.tool_calls] if llm_result.tool_calls else [],
                            "confidence": _safe_confidence_to_dict(
                                llm_result.confidence,
                                "_process_with_llm_brain:BLOCK:debug_info"
                            ),
                            "reasoning": llm_result.reasoning[:200] if llm_result.reasoning else None,
                        },
                        "guardian": {
                            "action": guardian_result.action.value,
                            "reason": guardian_result.reason,
                        },
                    },
                    total_time_ms=self._elapsed_ms(start_time),
                )

            elif guardian_result.action == GuardianAction.CONFIRM:
                # ç¢ºèªãŒå¿…è¦: ç¢ºèªçŠ¶æ…‹ã«é·ç§»
                import uuid as uuid_mod
                tool_call = llm_result.tool_calls[0] if llm_result.tool_calls else None
                confirm_question = guardian_result.confirmation_question or guardian_result.reason or "ç¢ºèªã•ã›ã¦ã»ã—ã„ã‚¦ãƒ«ğŸº"
                # =================================================================
                # å¢ƒç•Œå‹æ¤œè¨¼: confidenceã‚’å®‰å…¨ã«æŠ½å‡º
                # =================================================================
                confirm_confidence_value = _extract_confidence_value(
                    llm_result.confidence,
                    "_process_with_llm_brain:CONFIRM:confidence"
                )
                pending_action = LLMPendingAction(
                    action_id=str(uuid_mod.uuid4()),
                    tool_name=tool_call.tool_name if tool_call else "",
                    parameters=tool_call.parameters if tool_call else {},
                    confirmation_question=confirm_question,
                    confirmation_type=guardian_result.risk_level or "ambiguous",
                    original_message=message,
                    original_reasoning=llm_result.reasoning or "",
                    confidence=confirm_confidence_value,
                )
                await self.llm_state_manager.set_pending_action(
                    user_id=account_id,
                    room_id=room_id,
                    pending_action=pending_action,
                )

                return BrainResponse(
                    message=confirm_question,
                    action_taken="request_confirmation",
                    success=True,
                    awaiting_confirmation=True,
                    state_changed=True,
                    new_state="llm_confirmation_pending",
                    debug_info={
                        "llm_brain": {
                            "tool_calls": [tc.to_dict() for tc in llm_result.tool_calls] if llm_result.tool_calls else [],
                            "confidence": _safe_confidence_to_dict(
                                llm_result.confidence,
                                "_process_with_llm_brain:CONFIRM:debug_info"
                            ),
                        },
                        "guardian": {
                            "action": guardian_result.action.value,
                            "reason": guardian_result.reason,
                        },
                    },
                    total_time_ms=self._elapsed_ms(start_time),
                )

            elif guardian_result.action == GuardianAction.MODIFY:
                # ä¿®æ­£ãŒå¿…è¦: GuardianãŒä¿®æ­£ã—ãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
                tool_calls_to_execute = llm_result.tool_calls
                # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä¿®æ­£ï¼ˆæœ€åˆã®Toolå‘¼ã³å‡ºã—ã®ã¿ï¼‰
                if tool_calls_to_execute and guardian_result.modified_params:
                    tool_calls_to_execute[0].parameters.update(guardian_result.modified_params)

            else:
                # ALLOW: ãã®ã¾ã¾å®Ÿè¡Œ
                tool_calls_to_execute = llm_result.tool_calls

            # 6. ãƒ†ã‚­ã‚¹ãƒˆå¿œç­”ã®ã¿ã®å ´åˆï¼ˆToolå‘¼ã³å‡ºã—ãªã—ï¼‰
            if not tool_calls_to_execute:
                return BrainResponse(
                    message=llm_result.text_response or "ãŠæ‰‹ä¼ã„ã§ãã‚‹ã“ã¨ã¯ã‚ã‚Šã¾ã™ã‹ã‚¦ãƒ«ï¼ŸğŸº",
                    action_taken="llm_text_response",
                    success=True,
                    debug_info={
                        "llm_brain": {
                            "confidence": _safe_confidence_to_dict(
                                llm_result.confidence,
                                "_process_with_llm_brain:text_response:debug_info"
                            ),
                            "reasoning": llm_result.reasoning[:200] if llm_result.reasoning else None,
                        },
                    },
                    total_time_ms=self._elapsed_ms(start_time),
                )

            # 7. Toolå®Ÿè¡Œï¼ˆæ—¢å­˜ã®executionå±¤ã‚’æ´»ç”¨ï¼‰
            # æœ€åˆã®Toolå‘¼ã³å‡ºã—ã‚’å®Ÿè¡Œï¼ˆè¤‡æ•°Toolã¯å°†æ¥å¯¾å¿œï¼‰
            tool_call = tool_calls_to_execute[0]

            # DecisionResultã‚’æ§‹ç¯‰ã—ã¦æ—¢å­˜ã®executionå±¤ã«æ¸¡ã™
            # =================================================================
            # å¢ƒç•Œå‹æ¤œè¨¼: confidenceã‚’å®‰å…¨ã«æŠ½å‡º
            # =================================================================
            decision_confidence = _extract_confidence_value(
                llm_result.confidence,
                "_process_with_llm_brain:DecisionResult:confidence"
            )
            decision = DecisionResult(
                action=tool_call.tool_name,
                params=tool_call.parameters,
                confidence=decision_confidence,
                needs_confirmation=False,  # Guardianã§æ—¢ã«ãƒã‚§ãƒƒã‚¯æ¸ˆã¿
            )

            result = await self._execute(
                decision=decision,
                context=context,
                room_id=room_id,
                account_id=account_id,
                sender_name=sender_name,
            )

            # v10.46.0: è¦³æ¸¬ãƒ­ã‚° - LLM Brainå®Ÿè¡Œçµæœ
            self.observability.log_execution(
                action=tool_call.tool_name,
                success=result.success,
                account_id=account_id,
                execution_time_ms=self._elapsed_ms(start_time),
                error_code=result.data.get("error_code") if result.data and not result.success else None,
            )

            # Phase 3.5: Brain-controlled knowledge answer synthesis
            # ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ãŒè¿”ã—ãŸæ¤œç´¢ãƒ‡ãƒ¼ã‚¿ã‚’Brainï¼ˆLLMï¼‰ã§å›ç­”ã«åˆæˆã™ã‚‹
            # CLAUDE.md Â§1: å…¨å‡ºåŠ›ã¯è„³ã‚’é€šã‚‹ã€‚ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã¯ãƒ‡ãƒ¼ã‚¿å–å¾—ã®ã¿ã€‚
            if (
                result.success
                and result.data
                and isinstance(result.data, dict)
                and result.data.get("needs_answer_synthesis")
                and self.llm_brain is not None
            ):
                synthesized = await self._synthesize_knowledge_answer(
                    search_data=result.data,
                    original_query=tool_call.parameters.get("query", ""),
                )
                if synthesized:
                    result = HandlerResult(
                        success=True,
                        message=synthesized,
                        data=result.data,
                    )
                else:
                    # åˆæˆå¤±æ•—æ™‚: æ¤œç´¢çµæœã‚’ãã®ã¾ã¾è¡¨ç¤º
                    fallback = result.data.get("formatted_context", "")
                    if fallback:
                        result = HandlerResult(
                            success=True,
                            message=f"æ¤œç´¢çµæœã‚’è¦‹ã¤ã‘ãŸã‚¦ãƒ«ï¼ğŸº\n\n{fallback}",
                            data=result.data,
                        )

            # è¨˜æ†¶æ›´æ–°ï¼ˆéåŒæœŸï¼‰
            self._fire_and_forget(
                self.memory_manager.update_memory_safely(
                    message, result, context, room_id, account_id, sender_name
                )
            )

            return BrainResponse(
                message=result.message,
                action_taken=tool_call.tool_name,
                action_params=tool_call.parameters,
                success=result.success,
                suggestions=result.suggestions,
                debug_info={
                    "llm_brain": {
                        "tool_calls": [tc.to_dict() for tc in tool_calls_to_execute],
                        "confidence": _safe_confidence_to_dict(
                            llm_result.confidence,
                            "_process_with_llm_brain:tool_execution:debug_info"
                        ),
                        "reasoning": llm_result.reasoning[:200] if llm_result.reasoning else None,
                    },
                    "guardian": {
                        "action": guardian_result.action.value,
                    },
                },
                total_time_ms=self._elapsed_ms(start_time),
            )

        except Exception as e:
            logger.exception(f"LLM Brain error: {type(e).__name__}")

            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å¾“æ¥ã®å‡¦ç†ã«æˆ»ã‚‹
            logger.warning("ğŸ§  LLM Brain failed, no fallback available in this version")
            return BrainResponse(
                message="ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã‚¦ãƒ«ã€ã†ã¾ãå‡¦ç†ã§ãã¾ã›ã‚“ã§ã—ãŸã‚¦ãƒ«ğŸº",
                action_taken="llm_brain_error",
                success=False,
                debug_info={"error": type(e).__name__},
                total_time_ms=self._elapsed_ms(start_time),
            )

    async def _synthesize_knowledge_answer(
        self,
        search_data: Dict[str, Any],
        original_query: str,
    ) -> Optional[str]:
        """
        Brainå±¤ã§ãƒŠãƒ¬ãƒƒã‚¸æ¤œç´¢çµæœã‹ã‚‰å›ç­”ã‚’åˆæˆã™ã‚‹ï¼ˆPhase 3.5ï¼‰

        CLAUDE.md Â§1æº–æ‹ : å…¨å‡ºåŠ›ã¯è„³ã‚’é€šã‚‹ã€‚ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã¯ãƒ‡ãƒ¼ã‚¿å–å¾—ã®ã¿ã€
        å›ç­”ç”Ÿæˆã¯Brainï¼ˆLLM Brainï¼‰ãŒæ‹…å½“ã™ã‚‹ã€‚

        Args:
            search_data: ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ãŒè¿”ã—ãŸæ¤œç´¢ãƒ‡ãƒ¼ã‚¿
            original_query: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…ƒã®è³ªå•

        Returns:
            åˆæˆã•ã‚ŒãŸå›ç­”ãƒ†ã‚­ã‚¹ãƒˆã€ã¾ãŸã¯Noneï¼ˆã‚¨ãƒ©ãƒ¼æ™‚ï¼‰
        """
        if self.llm_brain is None:
            logger.warning("LLM Brain not available for knowledge synthesis")
            return None

        formatted_context = search_data.get("formatted_context", "")
        # ãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™ã‚’è€ƒæ…®ã—ã¦ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ‡ã‚Šè©°ã‚ï¼ˆç´„1000ãƒˆãƒ¼ã‚¯ãƒ³ç›¸å½“ï¼‰
        MAX_CONTEXT_CHARS = 4000
        if len(formatted_context) > MAX_CONTEXT_CHARS:
            formatted_context = formatted_context[:MAX_CONTEXT_CHARS] + "\n...(ä»¥ä¸‹çœç•¥)"
        source = search_data.get("source", "unknown")
        confidence = search_data.get("confidence", 0)
        source_note = search_data.get("source_note", "")

        system_prompt = f"""ã‚ãªãŸã¯ã€Œã‚½ã‚¦ãƒ«ãã‚“ã€ã§ã™ã€‚ä¼šç¤¾ã®çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã‹ã‚‰æƒ…å ±ã‚’å‚ç…§ã—ã¦å›ç­”ã—ã¾ã™ã€‚

ã€é‡è¦ãªãƒ«ãƒ¼ãƒ«ã€‘
1. æä¾›ã•ã‚ŒãŸå‚è€ƒæƒ…å ±ã«åŸºã¥ã„ã¦å›ç­”ã—ã¦ãã ã•ã„
2. æƒ…å ±æºã‚’æ˜ç¤ºã—ã¦ãã ã•ã„ï¼ˆä¾‹ï¼šã€Œå°±æ¥­è¦å‰‡ã«ã‚ˆã‚‹ã¨...ã€ã€Œç¤¾å†…ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ã§ã¯...ã€ï¼‰
3. å‚è€ƒæƒ…å ±ã«ãªã„å†…å®¹ã¯æ¨æ¸¬ã›ãšã€ã€Œãã®ç‚¹ã¯ç¢ºèªã§ãã¾ã›ã‚“ã§ã—ãŸã€ã¨ä¼ãˆã¦ãã ã•ã„
4. ã‚½ã‚¦ãƒ«ãã‚“ã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã‚’ä¿ã£ã¦ãã ã•ã„ï¼ˆèªå°¾ï¼šã€œã‚¦ãƒ«ã€æ™‚ã€…ğŸºã‚’ä½¿ã†ï¼‰
5. ç°¡æ½”ã«ã€ã‚ã‹ã‚Šã‚„ã™ãå›ç­”ã—ã¦ãã ã•ã„

ã€å‚è€ƒæƒ…å ±ã®å‡ºå…¸ã€‘
æ¤œç´¢æ–¹æ³•: {source}ï¼ˆ{"æ—§ã‚·ã‚¹ãƒ†ãƒ " if source == "legacy" else "Phase 3 Pineconeæ¤œç´¢"}ï¼‰
ä¿¡é ¼åº¦: {confidence:.2f}

ã€å‚è€ƒæƒ…å ±ã€‘
{formatted_context}
"""

        try:
            answer = await self.llm_brain.synthesize_text(
                system_prompt=system_prompt,
                user_message=f"è³ªå•: {original_query}",
            )

            if answer and source_note:
                answer += source_note

            return answer

        except Exception as e:
            logger.error(f"Knowledge synthesis error: {type(e).__name__}", exc_info=True)
            return None

    def _parse_confirmation_response(
        self,
        message: str,
        options: List[str],
    ) -> Optional[Union[int, str]]:
        """
        ç¢ºèªå¿œç­”ã‚’ãƒ‘ãƒ¼ã‚¹ã™ã‚‹ï¼ˆsession_orchestratorã¸ã®å§”è­²ï¼‰

        Args:
            message: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¿œç­”ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            options: é¸æŠè‚¢ãƒªã‚¹ãƒˆ

        Returns:
            int: é¸æŠã•ã‚ŒãŸã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆ0å§‹ã¾ã‚Šï¼‰
            "cancel": ã‚­ãƒ£ãƒ³ã‚»ãƒ«
            None: è§£æä¸èƒ½
        """
        result: Union[int, str, None] = self.session_orchestrator._parse_confirmation_response(message, options)
        return result

    async def _handle_confirmation_response(
        self,
        message: str,
        state: ConversationState,
        context: BrainContext,
        room_id: str,
        account_id: str,
        sender_name: str,
        start_time: float,
    ) -> BrainResponse:
        """
        ç¢ºèªã¸ã®å¿œç­”ã‚’å‡¦ç†ï¼ˆsession_orchestratorã¸ã®å§”è­²ï¼‰

        Args:
            message: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¿œç­”ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            state: ç¾åœ¨ã®ä¼šè©±çŠ¶æ…‹
            context: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±
            room_id: ãƒ«ãƒ¼ãƒ ID
            account_id: ã‚¢ã‚«ã‚¦ãƒ³ãƒˆID
            sender_name: é€ä¿¡è€…å
            start_time: å‡¦ç†é–‹å§‹æ™‚åˆ»

        Returns:
            BrainResponse: å‡¦ç†çµæœ
        """
        return await self.session_orchestrator._handle_confirmation_response(
            message=message,
            state=state,
            context=context,
            room_id=room_id,
            account_id=account_id,
            sender_name=sender_name,
            start_time=start_time,
        )


# =============================================================================
# ãƒ•ã‚¡ã‚¯ãƒˆãƒªãƒ¼é–¢æ•°
# =============================================================================


def create_brain(
    pool,
    org_id: str,
    handlers: Optional[Dict[str, Callable]] = None,
    capabilities: Optional[Dict[str, Dict]] = None,
    get_ai_response_func: Optional[Callable] = None,
) -> SoulkunBrain:
    """
    SoulkunBrainã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ

    ä½¿ç”¨ä¾‹:
        brain = create_brain(
            pool=db_pool,
            org_id="org_soulsyncs",
            handlers=HANDLERS,
            capabilities=SYSTEM_CAPABILITIES,
        )
    """
    return SoulkunBrain(
        pool=pool,
        org_id=org_id,
        handlers=handlers,
        capabilities=capabilities,
        get_ai_response_func=get_ai_response_func,
    )
